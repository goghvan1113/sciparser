<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-30">30 Oct 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Le</forename><surname>Huang</surname></persName>
							<email>lehuang@bupt.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Hengzhi</forename><surname>Lan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zijun</forename><surname>Sun</surname></persName>
							<email>sunzijunbj@yunic.ai</email>
						</author>
						<author>
							<persName><forename type="first">Chuan</forename><surname>Shi</surname></persName>
							<email>shichuan@bupt.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Ting</forename><surname>Bai</surname></persName>
							<email>baiting@bupt.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Yunic.AI</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Emotional RAG: Enhancing Role-Playing Agents through Emotional Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-30">30 Oct 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">6FA67FEAC79A9AAB94779A052713BF3D</idno>
					<idno type="arXiv">arXiv:2410.23041v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-01-17T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Emotional RAG</term>
					<term>Role-playing agent</term>
					<term>Large language models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As LLMs exhibit a high degree of human-like capability, increasing attention has been paid to role-playing research areas in which responses generated by LLMs are expected to mimic human replies. This has promoted the exploration of roleplaying agents in various applications, such as chatbots that can engage in natural conversations with users and virtual assistants that can provide personalized support and guidance. The crucial factor in the role-playing task is the effective utilization of character memory, which stores characters' profiles, experiences, and historical dialogues. Retrieval Augmented Generation (RAG) technology is used to access the related memory to enhance the response generation of role-playing agents. Most existing studies retrieve related information based on the semantic similarity of memory to maintain characters' personalized traits, and few attempts have been made to incorporate the emotional factor in the retrieval argument generation (RAG) of LLMs. Inspired by the Mood-Dependent Memory theory, which indicates that people recall an event better if they somehow reinstate during recall the original emotion they experienced during learning, we propose a novel emotion-aware memory retrieval framework, termed Emotional RAG, which recalls the related memory with consideration of emotional state in role-playing agents. Specifically, we design two kinds of retrieval strategies, i.e., combination strategy and sequential strategy, to incorporate both memory semantic and emotional states during the retrieval process. Extensive experiments on three representative roleplaying datasets demonstrate that our Emotional RAG framework outperforms the method without considering the emotional factor in maintaining the personalities of role-playing agents. This provides evidence to further reinforce the Mood-Dependent Memory theory in psychology.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>As artificial intelligence increasingly emerges in the large language models (LLMs), LLMs exhibit a high degree of †Le Huang and Hengzhi Lan participated in the work during their internship at Company Yunic.AI. *Corresponding author.</p><p>human-like capability. Recent studies <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b8">[9]</ref> use LLMs as role-playing agents to mimic human replies, showing powerful abilities in maintaining the personalized traits of characters in their response generation process. Role-playing agents have been applied to various fields, such as customer service agents and tourist guide agents. They show great potential in commercial applications and attract increasing attention in the LLMs research area.</p><p>To maintain characters' personalized traits and abilities, the most important factor is their memory. Character agents make retrieval in their memory unit to access its historical data, such as user profiles, event experience, recent dialogues, and so on, providing rich personalized information for LLMs in the role-playing task. Retrieval Augmented Generation (RAG) technology is used to access the related memory to enhance the response generation of role-playing agents, termed Memory RAG. Different attempts have been made in existing studies <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b23">[24]</ref> by using different memory mechanisms in various LLM applications. For example, the Ebbinghaus forgetting curve has inspired the development of MemoryBank <ref type="bibr" target="#b9">[10]</ref>, facilitating the implementation of a more anthropomorphic memory scheme. Furthermore, drawing on Kahneman's Dualprocess theory <ref type="bibr" target="#b24">[25]</ref>, the MaLP framework <ref type="bibr" target="#b10">[11]</ref> introduces an innovative Dual-Process enhanced Memory mechanism that effectively fuses long-term and short-term memory.</p><p>Despite research demonstrating the effects of using memory in the above LLM applications, achieving greater human-like response of role-playing agents is still an open and largely unexplored research area. Inspired by cognitive research in psychology, we make an initial attempt to emulate human cognitive processes in the memory-recalling process. According to the Mood-Dependent Memory theory, which was proposed by psychologist Gordon H. Bower in 1981 <ref type="bibr" target="#b25">[26]</ref>: people recall an event better if they somehow reinstate and recall the original emotion they experienced during learning. Through the experiments in which happy or sad moods were induced in subjects by hypnotic suggestion to investigate the influence of emotions on memory and thinking, he pointed out that emotions are not only the selection of information recalled but also the manner in which memories are retrieved. This suggests that individuals are more likely to recall memory information that is emotionally congruent with their current emotional state.</p><p>Based on the Mood-Dependent Memory theory in psychology, we propose a novel emotion-aware memory retrieval framework, termed Emotional RAG, to augment the response generation process of role-playing agents. The retrieving of memory in Emotional RAG follows the moodcongruity criterion, which means both the semantic relevance and emotional state of recalled memory are considered in the retrieval process. Specifically, we design two kinds of flexible retrieval strategies, i.e., combination strategy and sequential strategy, to incorporate the memory semantic and emotional states in the RAG process. By using emotional RAG, roleplaying agents are able to display more human-like traits that enhance the interactive and attractive capabilities of LLMs. The contributions of our paper are summarized as follows:</p><p>• Inspired by Mood-Dependent Memory theory, we make an initial attempt to emulate human cognitive processes by incorporating mood-congruity effects in the memory recalling of role-playing agents. We comprehensively demonstrate the effectiveness of applying Bower's emotional memory theory in developing artificial intelligence applications, which further provides evidence to reinforce the Mood-Dependent Memory theory in psychology. • We propose a novel emotion-aware memory retrieval framework, termed Emotional RAG, which recalls the related memory based on both semantic relevance and emotion state in role-playing agents. Besides, flexible retrieval strategies, i.e., combination strategy and sequen-tial strategy, are proposed to fuse memory semantic and emotional states during the retrieval process. • We conduct extensive experiments on three representative role-playing datasets, i.e., InCharacter, CharacterEval, and Character-LLM, demonstrating that our Emotional RAG framework significantly outperforms the method without considering the emotional factor in maintaining the personality traits of role-playing agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHOD</head><p>In this section, we first introduce the overview architecture of our Emotional RAG role-playing framework and then give a detailed introduction to each component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview Architecture of Emotional RAG</head><p>The aim of role-playing agents is to mimic human responses in conversation generations. Agents are powered by LLMs, which have the ability to generate responses according to the context of the conversation. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, given the query that the agents need to respond to, the framework of our proposed Emotional RAG role-playing agent framework contains four components, i.e., query encoding component, memory construction component, the emotional retrieval component, and the response generation component. The utilization of each component is introduced as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Emotional RAG Framework</head><p>The definition of role-playing agents: given a specific role R and a user query q, the agents expect to be able to generate the answer to the question based on the role's knowledge background (contained in R) and the query-related memory fragments m. In the role-playing agent R, among all possible generated responses a ′ , the one with the highest probability is selected as the response a for q: a = argmax a ′ P (a ′ |R, m, q, θ),</p><p>(</p><formula xml:id="formula_0">)<label>1</label></formula><p>where θ is the parameters of the LLMs during the generation process. Our goal is to optimize the retrieval of m to generate the most human-like response a. The aim of role-playing agents is to generate answers that are most consistent with the characters' personality traits by retrieving the most related memories.</p><p>1) Query Encoding Component: In this component, both the semantic and emotional state of the query are needed to be encoded. The semantic vector semantic q of query is defined as:</p><formula xml:id="formula_1">semantic q = F(q),<label>(2)</label></formula><p>where F is the embedding function. In this paper, the widely used embedding model bge-base-zh-v1.5 developed by BAAI <ref type="bibr" target="#b26">[27]</ref> is used to capture the latent vector of the query, which is a 768-dimensional vector for each query.</p><p>For the emotional vector of query q, the emotional state emotion q of query q can be formalized as follows:</p><formula xml:id="formula_2">emotion q = G(q),<label>(3)</label></formula><p>where G represents the emotion modeling function, which takes query q as input and outputs its emotional vector. This process is accomplished through GPT-3.5, a large model with powerful language understanding capabilities. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, we carefully design an emotional prompt, including the task description, scores on defined emotional dimensions, scoring criteria, and output format. The output is an emotional vector of the query, which is an 8-dimensional vector containing 8 different emotional states, i.e., joy, acceptance, fear, surprise, sadness, disgust, anger, and anticipation. The 8 emotional states are defined according to the emotion circle in <ref type="bibr" target="#b27">[28]</ref>. The value of each dimension is an integer between 1 and 10, which measures the intensity of the emotional state.</p><p>2) The Memory Encoding Component: The memory unit stores conversation information of question-answer pairs. Given the memory unit M consisting of n memory fragments, denoted as M = {m 1 , m 2 , ..., m n }, we can compute the </p><formula xml:id="formula_3">semantic k m = F(m k ),<label>(4)</label></formula><p>where F is the semantic embedding function introduced in Eq. 2.</p><formula xml:id="formula_4">emotion k m = G(m k ),<label>(5)</label></formula><p>where G is the emotion embedding function introduced in Eq. 3.</p><p>After encoding the semantic and emotional vectors of query and memory, we conduct emotional retrieval in the next component.</p><p>3) Emotional Retrieval Component: We retrieve the memory fragments that are most similar to the user query from the memory unit of characters based on semantic similarity and emotional similarity.</p><p>To retrieve the memory fragments that are most semantically similar to the query, we utilize the Euclidean distance between their semantic embeddings. This metric effectively quantifies the semantic similarity of the query and the memory fragment, simulating humans' cognitive recall process. The similarity between the query q and the memory fragment m k can be calculated as follows:</p><formula xml:id="formula_5">score k semantic = E(semantic q , semantic k m ),<label>(6)</label></formula><p>where E is the similarity score function, which can be the Euclidean distance function or cosine distance function.</p><p>According to Bower's Mood-Dependent Memory theory <ref type="bibr" target="#b25">[26]</ref>: events that are consistent with the character's current emotion are easier to retrieve, we use the cosine distance between two emotion vectors to find emotionally consistent memory fragments, defined as:</p><formula xml:id="formula_6">score k emotional = 1 -C(emotion q , emotion k m ),<label>(7)</label></formula><p>where C is a function of the cosine similarity of two vectors.</p><p>The smaller the distance score k emotional is, the more similar the emotions contained in the query and the memory fragment.</p><p>After obtaining the distant scores of memory fragments, the final similar distant score of memory fragments is defined as:</p><formula xml:id="formula_7">score k f inal = M(score k semantic , score k emotional ), (<label>8</label></formula><formula xml:id="formula_8">)</formula><p>where M is the function that computes the final retrieval score. Two kinds of flexible retrieval strategies, i.e., combination strategy and sequential strategy, are proposed to fuse memory semantic and emotional states during the retrieval process.</p><p>• Combination strategy: this strategy considers the two similarities at the same time. We adopt two functions, i.e., add function (C-A) and multiple function (C-M), to compute the retrieval scores of memory fragments.</p><p>• Sequential strategy: it contains semantic first strategy (S-S) and emotional first strategy (S-E). In the semantic first strategy, the most similar memory fragments are retrieved based on their semantic scores and then reranked according to their emotional scores. Different order is conducted in the emotional first strategy. Finally, the top 10 memory fragments with the smallest distant scores (i.e., the highest similarity) are used for retrieval augmentation. The retrieved memory is not only semantically related to the query but also consistent with the emotional state in the query.</p><p>4) Response Generation Component: After obtaining the retrieved memory, we design a prompt template for LLMs to generate responses in role-playing agents. The prompt template is shown in Figure <ref type="figure" target="#fig_2">3</ref>. The query, role information, retrieved memory fragments, and task description are formatted in the template that is sent to LLMs. In summary, by incorporating the emotional factor into the RAG process in role-playing agents, the memory fragments retrieved in our framework are more aligned with the emotional state. This enables the role-playing agents to generate more human-like responses, thus enhancing the interaction quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENT</head><p>we conduct experiments on three public datasets to evaluate the role-playing capabilities of LLMs augmented with emotional memory. • InCharacter Dataset <ref type="bibr" target="#b28">[29]</ref>: this dataset contains 32 characters. The characters are sourced from ChatHaruhi <ref type="bibr" target="#b2">[3]</ref>, RoleLLM <ref type="bibr" target="#b4">[5]</ref> and C.AI <ref type="foot" target="#foot_0">1</ref> . Each character is associated with a memory unit that includes dialogues from notable scenes, with an average length of 337 entries. • CharacterEval Dataset <ref type="bibr" target="#b29">[30]</ref>: the dataset consists of 77 distinct characters with 4,564 question-answer pairs. These characters are collected from well-known Chinese films and television series, and the dialogue data is compiled from their respective scripts. We selected the top 31 popular characters. For each character, we extracted all the question-answer pairs to establish a memory unit, with an average size of 113 entries. • Character-LLM Dataset <ref type="bibr" target="#b0">[1]</ref>: the Character-LLM dataset contains 9 famous English characters, e.g., Beethoven, Hermione, etc. Their memory units come from scenebased dialogue completion (completed by GPT). We use 1,000 QA dialogues for each character. 2) Evaluation Metrics: We conducted evaluations using the Big Five Inventory (BFI) and MBTI evaluation to ascertain the accuracy of the character agent's personality traits. Details of each evaluation metric are introduced as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Settings</head><p>• Big Five Inventory (BFI) <ref type="bibr" target="#b30">[31]</ref>: The Big Five, also known as the Big Five personality trait theory, is a widely used psychological model that divides personality into five main dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.   The truth labels of characters on MBTI and BFI in three datasets are collected from a personality voting website <ref type="foot" target="#foot_2">3</ref> . In our model, the role-playing agent is required to respond to the open-ended psychological questionnaires that are designed for MBTI and BFI evaluations. Subsequently, all collected responses are analyzed using GPT-3.5, which provides the results on MBTI and BFI evaluations. The personality evaluation template on GPT-3.5 is shown in Fig. <ref type="figure" target="#fig_4">4</ref>. Following the evaluations in <ref type="bibr" target="#b28">[29]</ref>. The results from our role-playing agents are compared with the ground truth labels to determine the evaluation results on Accuracy, i.e., Acc (Dim) and Acc (Full), Mean Squared Error (MSE), and Mean Absolute Error (MAE) metrics. Acc(Dim) and Acc(Full) metrics show the prediction accuracy of personality type on each dimension and all the combinations respectively. MSE and MAE measure the error between the predicted value of the character's personality and the ground truth label. For the dataset InCharacter, we use BFI and MBTI for testing, while for the CharacterEval and Character-LLM datasets, only MBTI is used due to the difficulty in collecting the true BFI labels.</p><p>3) Compared Methods: We conduct experiments on different backbone LLMs, including two open-source models ChatGLM and Qwen and a closed-source model GPT. The details of each LLM are introduced as follows:</p><p>• ChatGLM <ref type="bibr" target="#b31">[32]</ref>: we use chatglm3-6b, which is a dialogue pre-training model jointly released by Zhipu AI and Tsinghua University.</p><p>• Qwen <ref type="bibr" target="#b32">[33]</ref>: the version in our experiments is Qwen1.5-72B-Chat-GPTQ-Int4, which is a model in the Qwen1.5 series with 72 billion parameters.</p><p>• GPT <ref type="bibr" target="#b33">[34]</ref>: we use gpt-3.5-turbo-0125, which is a largescale language model developed by OpenAI and is known for its efficient generation capabilities. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Main Results</head><p>We evaluate the performance of Emotional RAG and Ordinary RAG on three datasets, including InCharacter, Char-acterEval, and Character-LLM datasets. Ordinary RAG uses semantic similarity as the only retrieval criterion. The experimental results are shown in Table <ref type="table" target="#tab_2">II</ref> and Table <ref type="table" target="#tab_3">III</ref>, we have the following observations:</p><p>(1) In most cases, Emotional RAG achieves better results than the RAG method without considering the emotion factor. This indicates that incorporating emotional states helps the maintaining of personality traits in role-playing agents.   (2) Emotional RAG performs better in ChatGLM-6B and Qwen-72B than GPT-3.5. This phenomenon may be due to the fact that GPT-3.5 is more powerful in language understanding and captures richer semantic information. However, even in a powerful LLM like GPT-3.5, the emotional factor still plays an important role in maintaining personality traits.</p><p>(3) The improvements are more significant in ACC (Full) than ACC (Dim), showing that our method is more powerful in the overall evaluations of MBTI and BFI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental Analysis</head><p>1) RAG Strategy Analysis: we analyze the impact of different retrieval strategies in incorporating the emotional factor. As introduced in the Emotion Retrieval Component, four retrieval strategies, i.e., combination strategy, i.e., add function (C-A), multiple function (C-M), and sequential strategy, i.e., semantic first (S-S), emotional first (S-E), are proposed to fuse the semantic and emotional states of memory during the retrieval process. We present the experimental results on Qwen-72B in Figure <ref type="figure" target="#fig_6">5</ref>, we can see that (1) Emotional RAG variants with all retrieval strategies (except the C-A strategy in BFI evaluation) achieve better results in MBTI and BFI evaluations, showing the effectiveness of incorporating emotional states in roleplaying agents; (2) Different retrieval strategies are applicable to different evaluations. For example, in the BFI personality evaluation, the sequential strategy (S-S) performs the best, while in the MBTI task, the combination strategy (C-A) exhibits the best performance.</p><p>2) Case studies: to provide an intuitive demonstration of the influence by incorporating the emotional factor in roleplaying agents, we show two examples to illustrate the superiority of our Emotional RAG. Figure <ref type="figure" target="#fig_7">6</ref> shows memory fragments in the memory units with different emotional states. In the first case, two memory fragments are all related to the input query. our Emotional RAG retrieved more appropriate content when it came to mentioning being dumped by a girlfriend, so its responses showed empathy and understanding of the situation compared to Ordinary RAG, making the conversation more vivid and natural. In the second case, Emotional RAG retrieves a memory fragment that is consistent with the query's emotion, so the reply expresses excitement and anticipation about seeing the sea. Only considering the semantic similarity will lead to emotional inconsistency and make the response content somewhat unreasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Role-Playing Agents</head><p>Role-playing agents, also termed Role-Playing Conversational Agents (RPCAs), aim to emulate the conversation behaviors and patterns of specific characters via LLMs. Roleplaying agents show considerable promise and are poised to substantially advance the areas of gaming, literature, and creative industries <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref>. Currently, the implementation of role-playing agents can be categorized into two primary methodologies. The first strategy enhances the role-playing capabilities of LLMs through prompt engineering and generative enhancement techniques. This approach equips LLMs with character-specific data within the context, capitalizing on the advanced in-context learning capabilities of modern LLMs. For instance, ChatHaruhi <ref type="bibr" target="#b2">[3]</ref> developed a RAG (Retrieval-Augmented Generation) system that leverages historical dialogues from iconic scenes to facilitate learning from a limited number of examples, thus capturing the personality traits and linguistic styles of characters. Conversely, RoleLLM <ref type="bibr" target="#b4">[5]</ref> introduced RoleGPT, which uses role-based prompts for GPT models.</p><p>The other type of role-playing approach involves pretraining or fine-tuning LLMs with collected character data, thereby customizing LLMs for specific role-playing scenarios. In <ref type="bibr" target="#b3">[4]</ref>, dialogue and character data from the Harry Potter novels were utilized to train agents capable of generating responses that align accurately with the context of the scene and the inter-character relationships. Character-LLM <ref type="bibr" target="#b0">[1]</ref> developed scenarios using ChatGPT to create conversational data, subsequently training a language model with metaprompts and these conversations. This project implemented strategies to mitigate the creation of character discrepancies in the model training dataset, such as memory uploads and protective memory enhancements. RoleLLM <ref type="bibr" target="#b4">[5]</ref> employed GPT to formulate question-answer pairs based on scripts, presenting them in a triplet format consisting of the question, answer, and confidence level. Incorporating a confidence metric significantly enhanced the quality of the generated data. CharacterGLM <ref type="bibr" target="#b1">[2]</ref> trained an open-source character model using data from multiple characters. This approach embeds role-specific knowledge directly into the model's parameters.</p><p>While existing studies of role-playing agents consider the character profile, relationships, and attributes relevant to the dialogue, they often overlook a critical element-the emotional factor of the characters. Our emotional RAG framework is designed on the prompt engineering technique, in which the LLMs are not required to be pre-trained or fine-tuned in roleplaying agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Memory RAG in LLM Applications</head><p>In role-playing agents, memory is an important factor for characters to maintain their personality traits. Retrieval Augmented Generation (RAG) technology is widely used <ref type="bibr" target="#b34">[35]</ref> to access the related memory to enhance the generation of role-playing agents, termed Memory RAG. For example, an LLM-based automatic agent architecture proposed in <ref type="bibr" target="#b35">[36]</ref> contains four components: a profiling module, a memory module, a planning module, and an action module. Among these, the memory module is crucial for the design of the agent architecture. It takes charge of obtaining information from the environment and utilizes these recorded memories to enhance future actions. The memory module enables the agent to accumulate experiences, evolve autonomously, and act in a manner that is more consistent, rational, and efficient <ref type="bibr" target="#b13">[14]</ref>.</p><p>The research on memory design in various LLM applications can be summarized into two categories. The first is capturing and storing intermediate states from past model reasoning as memory content. These memories are then retrieved as needed to support the generation of current responses. For instance, MemTRM <ref type="bibr" target="#b36">[37]</ref> maintains past key-value pairs and employs the query vector of the current input to conduct Knearest neighbor searches, applying mixed attention to both the current input and the past memories. However, MemTRM encounters challenges with memory obsolescence during training. To address this, LongMEM <ref type="bibr" target="#b37">[38]</ref> separates the processes of memory storage and retrieval. This strategy is particularly tailored for open-source models and might necessitate adaptive training to effectively integrate the contents of the memory library. The second type of memory design scheme involves providing memory support via an external memory library. This external memory can take various forms, enhancing the system's ability to manage and retrieve information efficiently. One such implementation is MemoryBank <ref type="bibr" target="#b9">[10]</ref>, which stores past conversations, event summaries, and user characteristics in a vector library format. The use of vector similarity calculations significantly accelerates the memory retrieval process, allowing for rapid access to relevant past experiences and data. AI-town <ref type="bibr" target="#b11">[12]</ref> uses a linguistic approach by preserving memory in natural language. It introduces a reflection mechanism that under specific conditions, transforms straightforward observations into more abstract and higher-order reflections. This system considers three critical factors during the retrieval process: the relevance, recency, and importance of memory, ensuring that the most pertinent and contextual information is retrieved for use in ongoing interactions.</p><p>In LLM-based role-playing agents, the memory unit typically operates via the second method, incorporating external memory libraries to enhance character authenticity. For example, in ChatHaruhi, the character agent retrieves dialogue from iconic scenes to enrich character development and interactions. Despite a large amount of research on memory RAG technique, achieving greater human-like response is still an open and unexplored area. Inspired by cognitive research in psychology, we make an initial attempt to incorporate the emotional factor to emulate human cognitive processes in the memory-recalling process, making the response of LLMs more emotionally resonant and human-like.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this paper, we make an initial attempt to incorporate emotional memory to enhance the performance of role-playing agents. A novel emotional RAG framework with four retrieval strategies is proposed to make role-playing agents more emotional and human-like in conversations. Extensive experiments on various characters on three public datasets demonstrate the effectiveness of our method in maintaining the personality traits of characters. We believe that imbuing emotions into role-playing agents is a pivotal research direction. In our current study, we conduct emotional RAG on an intuitive memory mechanism. In future work, we will attempt to incorporate the emotional factor into more advanced memory organization and retrieval schemes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: The overview architecture of Emotional RAG framework. It contains four components: the query encoding component, the memory encoding component, the emotional retrieval component, and the response generation component. The emotional memory retrieved by Emotional RAG is sent to LLM, together with the character profile and query, to generate responses.</figDesc><graphic coords="2,100.37,50.54,411.26,197.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Emotion scoring prompt template in LLMs.</figDesc><graphic coords="3,321.84,50.54,231.34,222.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: An example of response generation prompt template in the CharacterEval dataset.</figDesc><graphic coords="4,71.68,448.53,205.63,170.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>• MBTI 2 :</head><label>2</label><figDesc>is a popular personality test based on the Myers-Briggs Type Indicator (MBTI) theory. It categorizes people's personality types into 16 different combinations. Each type is represented by four letters, corresponding to the following four dimensions: Extroversion (E) vs. Introversion (I), Sensing (S) vs. iNtuition (N), Thinking (T) vs. Feeling (F), Judging (J) vs. Perceiving (P). The evaluation of MBTI is a classification task of 16 types, while BFI predicts the values of five personality dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: An example of the prompt template for dimension Extroversion (E) vs. Introversion (I) in MBTI evaluation.</figDesc><graphic coords="5,334.69,285.51,205.62,245.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Different RAG strategies on BFI evaluation. (b) Different RAG strategies on MBTI evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: The evaluation results of different emotion strategies on the InCharacter dataset.</figDesc><graphic coords="6,74.67,258.58,462.66,148.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Two examples that Emotional RAG generates better results. We highlighted phrases containing emotions in INPUT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Response generation component: a prompt template with query information, character profiles, and retrieved emotional memory, is fed to role-playing agents to generate responses.</figDesc><table><row><cell>congruity memory to enhance the generation process of</cell></row><row><cell>LLMs.</cell></row><row><cell>• Query encoding component: both the semantic and emo-</cell></row><row><cell>tional state of the query are encoded as vectors in this</cell></row><row><cell>component.</cell></row><row><cell>• Memory encoding component: the memory unit stores</cell></row><row><cell>conversation information about characters. Similar to</cell></row><row><cell>query encoding, both the semantic and emotional state</cell></row><row><cell>of the memory are encoded.</cell></row><row><cell>• Emotional retrieval component: it mimics human memory</cell></row><row><cell>recalls in the memory unit and then provides mood-</cell></row></table><note><p>•</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Statistics of three datasets. We conducted experiments on three public role-playing datasets, namely InCharacter, CharacterEval, and Character-LLM. Their statistics are summarized in the TableI.</figDesc><table><row><cell>Datasets</cell><cell cols="2">Role Number Avg. Memory Size</cell></row><row><cell>InCharacter</cell><cell>32</cell><cell>337</cell></row><row><cell>CharacterEval</cell><cell>31</cell><cell>113</cell></row><row><cell>Character-LLM</cell><cell>9</cell><cell>1000</cell></row><row><cell>1) Datasets:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>Performance comparisons of BFI and MBTI evaluation on the InCharacter dataset. Our Emotional RAG achieves the better model performance, which is distinctly marked in bold font.</figDesc><table><row><cell>Agent Types</cell><cell>Methods</cell><cell cols="2">BFI Acc(Dim)↑ Acc(Full)↑</cell><cell>MSE↓</cell><cell cols="3">MBTI MAE↓ Acc(Dim)↑ Acc(Full)↑</cell><cell>MSE↓</cell><cell>MAE↓</cell></row><row><cell>ChatGLM-6B</cell><cell>Ordinary RAG Emotional RAG</cell><cell>0.6242 0.6369</cell><cell>0.1250 0.0938</cell><cell>0.1849 0.1720</cell><cell>0.3728 0.3625</cell><cell>0.6694 0.6694</cell><cell>0.2188 0.2812</cell><cell>0.1526 0.1539</cell><cell>0.3610 0.3655</cell></row><row><cell>Qwen-72B</cell><cell>Ordinary RAG Emotional RAG</cell><cell>0.6815 0.7261</cell><cell>0.0938 0.2500</cell><cell>0.1433 0.1269</cell><cell>0.3024 0.2878</cell><cell>0.7438 0.7934</cell><cell>0.3438 0.4688</cell><cell>0.1230 0.1156</cell><cell>0.2920 0.2900</cell></row><row><cell>GPT-3.5</cell><cell>Ordinary RAG Emotional RAG</cell><cell>0.7006 0.7006</cell><cell>0.1875 0.1875</cell><cell>0.1496 0.1475</cell><cell>0.3121 0.3082</cell><cell>0.7851 0.7851</cell><cell>0.5000 0.4375</cell><cell>0.1221 0.1236</cell><cell>0.2965 0.2927</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Performance comparisons of MBTI evaluation on CharacterEval and Character-LLM datasets.</figDesc><table><row><cell>Agent Types</cell><cell>Methods</cell><cell cols="3">CharacterEval Acc(Dim)↑ Acc(Full)↑ MSE↓</cell><cell cols="2">MAE↓ Acc(Dim)↑</cell><cell cols="2">Character-LLM MSE↓</cell><cell>MAE↓</cell></row><row><cell>ChatGLM-6B</cell><cell>Ordinary RAG Emotional RAG</cell><cell>0.5161 0.5887</cell><cell>0.0323 0.0645</cell><cell>0.1654 0.1665</cell><cell>0.3757 0.3736</cell><cell>0.5556 0.6944</cell><cell>0.1111 0.3333</cell><cell>0.1330 0.1125</cell><cell>0.3277 0.2987</cell></row><row><cell>Qwen-72B</cell><cell>Ordinary RAG Emotional RAG</cell><cell>0.5968 0.6210</cell><cell>0.0968 0.1290</cell><cell>0.1537 0.1627</cell><cell>0.3455 0.3536</cell><cell>0.6667 0.6944</cell><cell>0.1111 0.1111</cell><cell>0.1376 0.1361</cell><cell>0.3115 0.3036</cell></row><row><cell>GPT-3.5</cell><cell>Ordinary RAG Emotional RAG</cell><cell>0.5887 0.5806</cell><cell>0.0645 0.1290</cell><cell>0.1720 0.1560</cell><cell>0.3655 0.3477</cell><cell>0.6944 0.6944</cell><cell>0.2222 0.3333</cell><cell>0.1258 0.1140</cell><cell>0.2800 0.2689</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/kramcat/CharacterAI</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.16personalities.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://www.personality-database.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.10158</idno>
		<title level="m">Character-llm: A trainable agent for role-playing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Characterglm: Customizing chinese conversational ai characters with large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.16832</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Chatharuhi: Reviving anime character in reality via large language model</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09597</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Large language models meet harry potter: A bilingual dataset for aligning dialogue agents with characters</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.06869</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Que</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.00746</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">From persona to personalization: A survey on role-playing language agents</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.18231</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.12474</idno>
		<title level="m">Large language models are superpositions of all characters: Attaining arbitrary role-play via selfalignment</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Role-play with large language models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcdonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Reynolds</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.16367" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Larp: Language-agent role play for open-world games</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2312.17653" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Memorybank: Enhancing large language models with long-term memory</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="19" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Memory-augmented llm personalization with short-and long-term memory coordination</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.11696</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative agents: Interactive simulacra of human behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
		<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Humanoid agents: Platform for simulating human-like generative agents</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chiu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.05418" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A survey on the memory mechanism of large language model based agents</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.13501</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Overwijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bennett</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2302.03754" />
		<title level="m">Augmenting zero-shot dense retrievers with plug-in mixture-ofmemories</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Enhancing large language model with self-controlled memory framework</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2304.13343" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Finmem: A performance-enhanced llm trading agent with layered memory and character design</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Suchow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Khashanah</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2311.13743" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.17144" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Infllm: Training-free long-context extrapolation for llms with an efficient context memory</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2402.04617" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Memgpt: Towards llms as operating systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wooders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2310.08560" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Ret-llm: Towards a general read-write memory for large language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Modarressi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Imani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.14322" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Think before you act: Decision transformers with working memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.16338" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Thinkin-memory: Recalling and post-thinking enable llms with long-term memory</title>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2311.08719" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Voyager: An open-ended embodied agent with large language models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mandlekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2305.16291" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mood and memory</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Bower</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American psychologist</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">129</biblScope>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">C-pack: Packaged resources to advance general chinese embedding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Muennighoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A general psychoevolutionary theory of emotion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Plutchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theories of emotion</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="3" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Incharacter: Evaluating personality fidelity in role-playing agents through psychological interviews</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Charactereval: A chinese benchmark for role-playing conversational agent evaluation</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.01275</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Soto</surname></persName>
		</author>
		<ptr target="https://api.semanticscholar.org/CorpusID:149343234" />
		<title level="m">Paradigm shift to the integrative big five trait taxonomy: History, measurement, and conceptual issues</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Glm: General language model pretraining with autoregressive blank infilling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="320" to="335" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.16609</idno>
		<title level="m">Qwen technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27" to="730" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Chatdb: Augmenting llms with databases as their symbolic memory</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.03901</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey on large language model based autonomous agents</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Computer Science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">186345</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.08913</idno>
		<title level="m">Memorizing transformers</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Augmenting language models with long-term memory</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
