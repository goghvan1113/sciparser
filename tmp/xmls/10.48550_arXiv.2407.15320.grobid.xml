<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-01-07">7 Jan 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Liekang</forename><surname>Zeng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Shengyuan</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xiaoxi</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ju</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Jian</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Yang</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Sherman</forename><surname>Shen</surname></persName>
						</author>
						<title level="a" type="main">Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-01-07">7 Jan 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">5D389452E6F90732BB5DC0371DBFA908</idno>
					<idno type="arXiv">arXiv:2407.15320v2[cs.DC]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-01-20T06:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Edge computing</term>
					<term>edge intelligence</term>
					<term>graph learning</term>
					<term>artificial intelligence</term>
					<term>wireless communication</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent years have witnessed a thriving growth of computing facilities connected at the network edge, cultivating edge networks as a fundamental infrastructure for supporting miscellaneous intelligent services. Meanwhile, Artificial Intelligence (AI) frontiers have extrapolated to the graph domain and promoted Graph Intelligence (GI). Given the inherent relation between graphs and networks, the interdiscipline of graph learning and edge networks, i.e., Edge GI or EGI, has revealed a novel interplay between them -GI aids in optimizing edge networks, while edge networks facilitate GI model deployment. Driven by this delicate closed-loop, EGI is recognized as a promising solution to fully unleash the potential of edge computing power and is garnering growing attention. Nevertheless, research on EGI remains nascent, and there is a soaring demand within both the communications and AI communities for a dedicated venue to share recent advancements. To this end, this paper promotes the concept of EGI, explores its scope and core principles, and conducts a comprehensive survey concerning recent research efforts on this emerging field. Specifically, this paper introduces and discusses: 1) fundamentals of edge computing and graph learning, 2) emerging techniques centering on the closed loop between graph intelligence and edge networks, and 3) open challenges and research opportunities of future EGI. By bridging the gap across communication, networking, and graph learning areas, we believe that this survey can garner increased attention, foster meaningful discussions, and inspire further research ideas in EGI.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>E DGE networks are swiftly proliferating. By assem- bling progressively spreading computing facilities at the network edge, edge networks have hosted ever-increasing amounts of data, storage, and computing resources. They have become a fundamental infrastructure supporting miscellaneous applications like smart industrial manufacturing <ref type="bibr" target="#b7">[1]</ref>, <ref type="bibr" target="#b8">[2]</ref>, streaming video analytics <ref type="bibr" target="#b9">[3]</ref>, <ref type="bibr" target="#b10">[4]</ref>, and Internet of robotics and vehicles <ref type="bibr" target="#b11">[5]</ref>, <ref type="bibr" target="#b12">[6]</ref>, etc. As a complementary symmetry of the centralized core network, edge networks locate at the end of the Internet and encompass users in their physical vicinity, allowing for user-centric services with reduced response latency, improved resource efficiency, and enhanced privacy and Liekang Zeng was with Sun Yat-sen University and The Hong Kong University of Science and Technology (Guangzhou). Shengyuan Ye, Xu Chen, and Xiaoxi Zhang are with Sun Yat-sen University and the Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education. Ju Ren is with Tsinghua University. Jian Tang is with Midea Group. <ref type="bibr">Yang</ref> Yang is with the IoT Thrust and the Research Center for Digital World with Intelligent Things (DOIT) at the Hong Kong University of Science and Technology (Guangzhou), and also with Peng Cheng Laboratory, and also with Terminus Group. Xuemin (Sherman) Shen is with The University of Waterloo. Fig. <ref type="figure">1</ref>. Illustration of the interplay between GI and edge networks, where GI can be applied as a data-driven tool to optimize edge networks, and conversely, edge networks perform as digital infrastructure to support GI deployment. security. Benefited from these unique architectural superiorities, edge networks have been a vital experimentation arena for advanced communication techniques. They are practically favorable for emerging intelligence services with delay-sensitive, resource-demanding, and privacy-preserved requirements, and have been widely recognized as a promising prospect for bridging the last mile between Artificial Intelligence (AI) and human beings <ref type="bibr" target="#b13">[7]</ref>, <ref type="bibr" target="#b14">[8]</ref>.</p><p>Meanwhile, AI is also rapidly booming. To fully unleash the potential of big data in diverse forms, recent AI advances have extrapolated representation learning over massive data from Euclidean structure to graph topology, pushing Deep Learning (DL) frontiers to a new stream of models named Graph Neural Network (GNN) <ref type="bibr" target="#b15">[9]</ref>, <ref type="bibr" target="#b16">[10]</ref>. Different from traditional DNN (e.g., CNN, RNN) that typically applies 1D/2D convolutions, GNN introduces graph embedding techniques to digest information from graph relations <ref type="bibr" target="#b17">[11]</ref>, <ref type="bibr" target="#b18">[12]</ref>. Specifically, it applies neighbor aggregation on an input graph iteratively and captures hierarchical patterns through neural network operators from subgraphs of varying sizes. This enables GNNs to abstract and learn the properties of specific vertices, links, or the entire graph, and thus generalize to unobserved graphs. Leveraging such powerful expressiveness, learning with GNN, i.e., Graph Learning (GL), has exhibited superior graph analysis performance and empowers various graph-related tasks from node classification and link prediction to graph isomorphism and categorization <ref type="bibr" target="#b19">[13]</ref>, <ref type="bibr" target="#b20">[14]</ref>.</p><p>Given the remarkable success of Graph Intelligence (GI) and edge networks in their respective fields, the inherent connection between graphs and networks impels them to a confluence. As illustrated in Fig. <ref type="figure">1</ref>, GI provides a vast zoo of empirical learning models (e.g., convolutional and recurrent GNNs, graph autoencoders) as well as various learning paradigms like Transfer Learning (TL) and Reinforcement Learning (RL), allowing advanced learning ability from graph data. Symmetrically, edge networks generally comprise of a rich set of platforms including mobile devices, robots, vehicles, and edge nodes, which host miscellaneous graphbased applications such as traffic forecasting and network resource management. Their bidirectional interaction, where GI enhances and optimizes edge networks and edge networks support and enable GI computation, draws a closed loop with mutual empowerment and nurtures a reciprocal interplay of their integration, namely "Edge Graph Intelligence" or "EGI" for brevity.</p><p>While the term EGI is fresh to come, research and practices have begun early. Since the development of GCN in 2015 <ref type="bibr" target="#b21">[15]</ref>, GI has increasingly gained popularity in the AI community and ignited a wave of building GNNs over various real-world graphs. Meanwhile, edge networks and edge computing are also rapidly evolving and actively embracing AI since 2019, giving rise to the concept of edge AI or edge intelligence <ref type="bibr" target="#b14">[8]</ref>, <ref type="bibr" target="#b22">[16]</ref>, <ref type="bibr" target="#b23">[17]</ref>. Currently, the interplay of EGI has attracted growing attention from both the industry and academia and propelled a plethora of innovative optimizations, techniques, and applications at the network edge, e.g., traffic flow forecasting <ref type="bibr" target="#b24">[18]</ref>, <ref type="bibr" target="#b25">[19]</ref>, location-based recommendation <ref type="bibr" target="#b26">[20]</ref>, <ref type="bibr" target="#b27">[21]</ref>, and vehicle trajectory prediction <ref type="bibr" target="#b28">[22]</ref>, <ref type="bibr" target="#b29">[23]</ref>. As a substantial extension of edge AI, EGI sheds light on its fundamental questions -how deeply edge networks and AI techniques can be fused and how much potential their fusion can shine -and demonstrates its powerful capability through plentiful realistic applications.</p><p>In this paper, we discuss in-depth how GI and edge networks are reciprocal to each other, and conduct a comprehensive and concrete survey of the recent research efforts on EGI. In particular, centering around the inherently interconnected nature of graphs and networks, this paper reveals the bilateral interplay, for the first time, between GI and edge networks, and provides a concise rating in accordance with their mutually beneficial interactions. In light of the rating, our survey identifies the four primary enablers essential for EGI, as illustrated in Fig. <ref type="figure">2:</ref> • Edge applications of GI Models (Sec. V): Typical application scenarios and use cases for applying GI in edge networks; • Edge Networks for GI (Sec. VI): Paradigms of GI model computation, including model training and inference, for GI over edge networks; • GI for Edge Networks (Sec. VII): Practical GI-based methods for optimizing edge networks concerning their specific functionalities; • EGI ecosystems (Sec. VIII): full-stack infrastructural support for high-performance EGI computation in terms of hardware, software, and benchmarks.</p><p>In general, these key enablers can be well accommodated in the closed loop, i.e., "edge for GI" and "GI for edge" Fig. <ref type="figure">2</ref>. Outline and conceptual relationships of EGI aspects discussed in this survey: Based on fundamental elements of GI (Sec. III-A) and edge networks (Sec. III-B), EGI ecosystems (Sec. VIII) sustain all stakeholders in the closed loop of edge networks and graph intelligence. Edge Network for GI (Sec. VI) reviews techniques for supporting edge computation of GI models and GI for Edge Network (Sec. VII) discusses GI-based optimizations on edge networks. Both of them serve as support for a rich set of EGI applications (Sec. V).</p><p>as described in Fig. <ref type="figure">1</ref>, In the "edge for GI" course, edge networks provide physical platforms and software stacks to graph intelligence, serving as infrastructure to support GI models training and inference processes. More specifically, GI models' intensive training workload can be resolved by means of pools of edge resources (e.g., federated edge learning), and edge inference techniques are developed for deploying and accelerating GI models under resource constraints and SLO requirements. Alternatively, in the "GI for edge" course, GI models with these inference solutions can thereafter be efficiently executed upon edge platforms, which enables miscellaneous graph-based applications and optimizes various aspects of edge networks. Besides reviewing these key enablers, our survey provides fundamental and friendly premiers of GI and edge networks that assume no prior knowledge of GI or edge computing. We also discuss various open challenges and research directions toward future EGI, encouraging both AI and communications communities to advance EGI for a broader range of people.</p><p>In summary, this paper makes the following key contributions.</p><p>• A brief tutorial on the primer of EGI key components that explains basic and necessary concepts about GI and edge networks.</p><p>• We submit an in-depth discussion on EGI advantages as well as an EGI rating taxonomy that can be used as a criterion to identify the advancement of EGI systems.</p><p>• We conduct a comprehensive survey on various aspects of EGI, including edge applications of GI, edge networks for GI, GI for edge networks, and EGI ecosystems.</p><p>• We discuss open challenges and research directions of EGI, acted as a reference for future EGI innovations. The rest of this paper is organized as follows: First, Sec. III-A and Sec. III-B briefly review the primers of graph intelligence and edge computing networks, respectively. Next, the subsequent sections introduce research efforts with respect to the four enablers: GI applications at Edge (Sec. V), edge networks for GI (Sec. VI), GI for edge networks (Sec. VII), and EGI ecosystems (Sec. VIII). Finally, Sec. IX discusses open challenges and future research opportunities of EGI and Sec. X concludes. Table I lists the main abbreviations used in this survey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED SURVEY</head><p>While EGI intersects edge networks and GI, its investigation is still narrowly limited to unilateral dimensions.</p><p>On the GI side, a volume of literature has reviewed the general landscape of GL, providing insights on model taxonomy <ref type="bibr" target="#b30">[24]</ref>, capability boundaries <ref type="bibr" target="#b19">[13]</ref>, and practical tutorials <ref type="bibr" target="#b20">[14]</ref>. As flourishing attention is attracted, publications relevant to GI topics explode. Following this trend, some researchers begin to deliver reviews concentrated on specific types of models, such as GAE <ref type="bibr" target="#b31">[25]</ref>, <ref type="bibr" target="#b32">[26]</ref>, STGNN <ref type="bibr" target="#b33">[27]</ref>, <ref type="bibr" target="#b34">[28]</ref> and DGRL <ref type="bibr" target="#b35">[29]</ref>, <ref type="bibr" target="#b36">[30]</ref>. Surveys on certain scenarios are also released. For instance, some researchers review the use of GI in traffic domain <ref type="bibr" target="#b37">[31]</ref>- <ref type="bibr" target="#b39">[33]</ref>, discussing how traffic networks can be constructed as graphs and how traffic patterns can be resolved with GI; several surveys target power grids, where the electrical network are naturally graphs <ref type="bibr" target="#b40">[34]</ref>- <ref type="bibr" target="#b42">[36]</ref>. Nevertheless, these investigations either center on graph learning landscapes with limited discussion about their roles in edge networks <ref type="bibr" target="#b15">[9]</ref>, <ref type="bibr" target="#b16">[10]</ref>, <ref type="bibr" target="#b19">[13]</ref>, or focused particularly on applying GI techniques on some specific edge scenarios, yet ignoring the big picture of general edge networks spectrum. Some recent literature <ref type="bibr" target="#b43">[37]</ref>- <ref type="bibr" target="#b45">[39]</ref> also reviews the progress of GI in the context of IoT and wireless networks, aiming at exploiting GI for optimizing communication channels in IoT services. These works, however, mainly focus on GI applications in their discussed scopes and lack a systematic taxonomy on how GI can be computed in hierarchical edge networks, which is one of the fundamental pillars in EGI's ecosystem.</p><p>On the edge AI side, surveys on the broader edge computing topics have been carried out for years, pertaining to visions and challenges <ref type="bibr" target="#b13">[7]</ref>, systems and tools <ref type="bibr" target="#b46">[40]</ref>, communication and IoT perspectives <ref type="bibr" target="#b47">[41]</ref>- <ref type="bibr" target="#b49">[43]</ref>, etc. With the popularization of AI in edge networks, many researchers turned their attention to the potential and future directions of edge AI. For instance, Zhou et al. <ref type="bibr" target="#b14">[8]</ref> discuss the motivation and advantages of edge intelligence along with a grading mechanism for edge intelligence by assessing the training and inference on edge platforms. Wang et al. <ref type="bibr" target="#b50">[44]</ref> submit a comprehensive taxonomy of edge AI and analyze a set of open challenges toward future edge AI development. Although these surveys have extensively investigated edge intelligence systems, a majority of them <ref type="bibr" target="#b14">[8]</ref>, <ref type="bibr" target="#b50">[44]</ref>- <ref type="bibr" target="#b53">[47]</ref> center on general AI computation or are dedicated to traditional DL workloads such as CNN or RNN. GI models, which possess distinct capabilities and unique computing characteristics, are much less understood in the edge AI context.</p><p>In summary, while the AI and edge computing communities have pushed their investigation to their respective frontiers, a thorough review of EGI, the combination of both lines, is still absent and desires actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRIMER ON EDGE GRAPH INTELLIGENCE</head><p>Before diving into various aspects of EGI, we briefly review the basic concepts and relevant techniques of GI and edge networks, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Graph Intelligence</head><p>As one of the key flywheel actuating the loop within EGI, graph representation learning is devoted to the algorithm side and contributes enhanced ability in graph data processing. Before diving into EGI, this section introduces graph representation learning with respect to its basic concepts, general workflow, and representative models and learning paradigms. For a more comprehensive treatment of GI, concentrated reviews <ref type="bibr" target="#b15">[9]</ref>, <ref type="bibr" target="#b19">[13]</ref>, <ref type="bibr" target="#b20">[14]</ref>, <ref type="bibr" target="#b30">[24]</ref> on GL are highly recommended. Table <ref type="table" target="#tab_0">II</ref> lists the main notations used in this section.</p><p>1) Basic Concepts: Graphs. Graphs are a way to organize data, and with graphs, one can succinctly characterize relationships across scattered data points. The input of GI models, i.e., GNNs, are graphs, which typically contain two types of data. One is the adjacency matrix or adjacency list, which interprets the graph topology, and the other is the feature vectors that describe vertices and edges' actual properties. Formally, an input graph is denoted as G = ⟨V, E⟩, with vertices and links collected in V and E, respectively.</p><p>Vertices and Links. Vertices or nodes in a graph can be items, objects, or entities, and are not necessarily homogeneous when constructing a graph. For instance, a locationbased knowledge graph can represent its vertices as human users, IoT devices, scenic spots, and any other entities of various types within a specific district. Links are another essential component in graphs that characterizes the relationships between these items, objects, or entities. Note that to avoid misunderstanding, we exclusively use "links" to indicate the connection between vertices in an input graph while leaving "edge" for edge networks. A link can be defined with respect to the two (not necessarily unique) vertices associated with it. For V ∈ G and E ∈ G, we denote their size, i.e., the number of vertices and links, as V and E, respectively, and use v and e to index arbitrary vertex and link in them.</p><p>Neighbors. Neighbors are ego-networks centering on specific vertices within a graph. For a vertex v, its neighbors cover the vertices directly connected to v and their adjoining links. Note that a vertex's neighbors can be iteratively expanded by considering the neighbors of its neighbors. Formally, given</p><formula xml:id="formula_0">N (k) v as vertex v's k-hop neighbors, we have N (k+1) v = {N (1) u |∀u ∈ N (k) v }, where N (1) v indicates v's one-hop direct neighbors.</formula><p>Representation Vectors, Features, and Embeddings. Representation vectors are the numerical vectors associated with vertices and links, and are also referred to as encodings, representations, latent vectors, or high-level feature vectors depending on the context. In this section, we respectively denoted representation vectors by h</p><formula xml:id="formula_1">(l) v and h (l)</formula><p>e at the l-th GNN layer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation Definition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G</head><p>The graph input to the GNN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V, V , v</head><p>The input graph G includes a set V of vertices, where its size is V and v is an arbitrary vertex in V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E, E, e</head><p>The input graph G' includes a set E of links, where its size is E and e is an arbitrary link in E. N</p><formula xml:id="formula_2">(k) v The set of vertex v's k-hop neighbors in G. L, L, l</formula><p>The GNN model's layers set L is of size L, where l is an arbitrary layer in L. h</p><formula xml:id="formula_3">(l) v , h (l) e</formula><p>The representation vector of vertex v and link e of layer l, respectively. When l = 0 and l = L, they represent the cases of input and output representation vectors of vertex v (link e), respectively. φ</p><formula xml:id="formula_4">(l) V , φ (l) E</formula><p>Aggregation function of vertices and links of layer l. ϕ</p><formula xml:id="formula_5">(l) V , ϕ (l) E</formula><p>Update function of vertices and links of layer l. θ (l) , ϑ (l)  Sample function and pooling function of layer l. ψ Readout function. y Global output vector.</p><p>Upon input to the model, the initial representation vectors h</p><formula xml:id="formula_6">(0) v and h (0)</formula><p>e are exactly the features attached to vertices and links, which quantify physical properties in specific applications. Extending the above knowledge graph example, the features of a vertex may include the users' age and food preferences, and for a scenic spot, it can be location and popularity. After processing through model layers, the exported representation vectors are embeddings, a form of compressed feature representations of vertices, links, neighbors, or graphs. Embeddings can be viewed as the mappings of original data in latent spaces, which effectively reserve the semantics implicated in the input graph while can be used by downstream models for specific tasks (e.g., vertex classification and link prediction).</p><p>Model Output. The final output of GI models depends on the way of processing embeddings, i.e., the readout function. In general, the outcome of GI models can be grouped into three types: 1) Vertex-level output, where the result is vertexwise predictions (e.g., classes, scores) for some dedicated vertices. 2) Link-level output, where the result is link-wise predictions for some dedicated links. 3) Graph-level output, where the results are the prediction of the whole graph (e.g., the operational status of a power grid).</p><p>2) General Workflow: A GI model is an algorithm that essentially leverages graph topology to abstract and learn the relationships between vertices and links. It takes an attributed graph as input, and output embeddings or predictions in an application-admitted format. Among versatile GI models, the GNN series is the state-of-the-art genre and is prevalent in various types of edge applications, thus we illustrate the general workflow of GI model based on GNN models. Fig. <ref type="figure" target="#fig_0">3</ref> depicts the general workflow of them.</p><p>Preprocessing. The first step serves as an initialization to prepare data in a format aligned with the targeted GI model's requirement. This can be, for example, reorganizing the adjacency matrix in a dense format or the compressed sparse row format and dropout some irrelevant elements from the feature vectors. Since the GI model is often known ahead of runtime, graph preprocessing is usually done offline. Sampling. With the preprocessed input graph, the GI model dives into iterations. The number of iterations required is exactly the number of layers the GI model possesses. Within each iteration, it first applies sampling on the input graph G to reduce the computational complexity of subsequent steps. Assuming the sampling function as θ (l) , this step can be formally written in:</p><formula xml:id="formula_7">G ′ = θ (l) (G).<label>(1)</label></formula><p>The result of sampling is a sampled graph G ′ , where G ′ = ⟨V ′ , E ′ ⟩. Note that this is an optional step and inference processes typically deactivate this step for prediction accuracy.</p><p>Aggregation. Upon the sampled graph G ′ , the GI model performs neighbor aggregation where each vertex/link pulls feature vectors from its neighbors. Taking vertices aggregation as example, let φ (l)</p><p>V be the aggregation function of vertices, we have</p><formula xml:id="formula_8">a (l) v = φ (l) V (h (l) v , h (l) u ), ∀v ∈ V ′ , ∀u ∈ N (v),<label>(2)</label></formula><p>where {h V to update v's representation vector:</p><formula xml:id="formula_9">h (l+1) v = ϕ (l) V (h (l) v ), ∀v ∈ G ′ ,<label>(3)</label></formula><p>This operator is usually learnable Multi-Layer Perceptron (MLP) and non-linear activations like the sigmoid function. Note that Eq. ( <ref type="formula" target="#formula_8">2</ref>) and Eq. ( <ref type="formula" target="#formula_9">3</ref>) are merely described for vertices for simplicity. Repeating the same procedure to all vertices and links yields the complete representation vectors for the whole graph.</p><p>Pooling. Pooling is also an optional step that aims at reducing the original graph to a smaller graph for lower computational complexity. It directly operates the sampled graph with updated representation vectors, pooling fields of graphs:</p><formula xml:id="formula_10">Ḡ = ϑ (l) (G ′ ).<label>(4)</label></formula><p>Readout. The above sampling, aggregation, update, and pooling steps will iterate until all model layers are processed, and thereafter generate embeddings of all vertices and links. To attain the desired results demanded by applications, these embeddings are obliged to the final readout step, which applies a pre-defined operator or model to transform embeddings to a global output, as explained in Sec. III-A1. Given a readout function ψ, the global output vector can be obtained by:</p><formula xml:id="formula_11">y = ψ(h (L) v , h (L) e |v, e ∈ G).<label>(5)</label></formula><p>In summary, executing a GI model can be regarded as processing a collection of operators and neural networks iteratively over a graph, where each iteration, i.e., each model layer, comprises weights that specify the computation of vertices' and links' feature vectors. These weights are learnable via model training, i.e., through the means of backpropagation algorithms such as gradient-based optimization. Specifically, during model training, a GI model with L layers undergoes a forward pass: first transforms input graph through model layers to graph embeddings, and next converts the obtained embeddings into desired results. With the exported result and known labels, the model computes the pre-defined loss function, where the gradient is then backpropagated across the layers, updating the shared weights. This process is carried out iteratively with multiple samples, which are often in batches until an expected accuracy is attained. For model inference, it directly goes through a forward pass and generates the predictions.</p><p>3) Graph Learning Models: There are multifarious GI model variants developed for multifarious applications with multifarious ability requirements. For brevity, here we enumerate several representatives that are commonly adopted in edge scenarios.</p><p>Recurrent Graph Neural Network (RecGNN) is a pioneering architecture that builds the conceptual foundation in the field of graph representation learning <ref type="bibr" target="#b15">[9]</ref>. They are primely proposed to learn node representations using recurrent neural architectures, integrating a recurrent hidden state and graph signal processing (GSP) to exploit the spatial structural information inherent in graph processes. As a genre of GI models dating back to the "pre-deep-learning" era, RecGNNs have inspired numerous subsequent research such as convolutional variants.</p><p>Convolutional Graph Neural Network (ConvGNN) extend convolution operations from grid data to graph data, aggregating the features of vertices and links with their neighbors to generate representations <ref type="bibr" target="#b16">[10]</ref>, <ref type="bibr" target="#b20">[14]</ref>. Contrary to RecGNNs, successive graph convolutional layers are stacked in ConvGNNs to extract hierarchical patterns from subgraphs <ref type="bibr" target="#b21">[15]</ref>. Among GNNs, ConvGNNs serve as a foundational component in constructing various advanced GI models <ref type="bibr" target="#b54">[48]</ref>.</p><p>Graph Attention Network (GAT) inherit spatial Con-vGNNs by incorporating the attention mechanism into the aggregation functions, which effectively improves the capacity as well as the expressiveness of GI models <ref type="bibr" target="#b55">[49]</ref>. The rationale behind this combination is to differentiate the contribution of vertices' neighbors in a learning manner <ref type="bibr" target="#b56">[50]</ref>. Based on this, many types of attention mechanisms are derived such as selfattention, gating attention, and semantic-level attention.</p><p>Graph Autoencoder (GAE) are unsupervised frameworks that encode vertices, links, or graphs into a latent vector space and reconstruct graph data by decoding their encoded information <ref type="bibr" target="#b19">[13]</ref>. GAEs are particularly useful for graph generation tasks, where a GAE model employs graph convolutional layers to compute embeddings for vertices and rebuild the graph adjacency matrix via decoders. Variational GAE goes beyond traditional GAE by transforming vertex embeddings as distribution, where each node's embedding is represented by a mean and variance, allowing the model to capture uncertainties by sampling from these distributions <ref type="bibr" target="#b57">[51]</ref>.</p><p>Spatio-Temporal Graph Neural Network (STGNN) analyze dynamic graphs from both the spatial and temporal dimensions <ref type="bibr" target="#b33">[27]</ref>, <ref type="bibr" target="#b58">[52]</ref>. Each vertex and link in these graphs attaches a feature vector that describes their behaviors within a time window, and STGNNs aim to learn their patterns and predict their changes in the incoming time slots. To extract information from spatial-temporal dependencies, many sequential decision-making approaches are applied, e.g., Long Short-Term Memory (LSTM).</p><p>Graph Transformer and Graph Foundation Model. Graph transformers explore embracing transformer architecture to the graph domain in pursuit of improved graph modeling ability <ref type="bibr" target="#b59">[53]</ref>- <ref type="bibr" target="#b61">[55]</ref>. Typically, graph transformers incorporate GNN with transformers in dual ways: 1) design tailored positional embedding modules and graph-specific attention matrices, and 2) exploit GNNs as an auxiliary module by combining GNNs into transformer architectures <ref type="bibr" target="#b62">[56]</ref>. Following this line, scaling small transformers to huge foundation models leads to Graph Foundation Models (GFMs) <ref type="bibr" target="#b63">[57]</ref>, <ref type="bibr" target="#b63">[57]</ref> and Large Graph Models (LGMs) <ref type="bibr" target="#b64">[58]</ref>. Motivated by the success of Large Language Models (LLMs), many researchers believe that utilizing pretraining techniques to resolve massive graph data can breed a comprehensive GI model, which possesses advanced abilities such as in-context graph understanding and versatile graph reasoning <ref type="bibr" target="#b65">[59]</ref>. Nevertheless, GFMs and LGMs are still in a very early stage of their development and demand for further exploration.</p><p>4) Learning Paradigms: Given a rich zoo of GI models, distinct learning paradigms empower them with distinct abilities for edge applications. We provide several example learning paradigms as follows.</p><p>Supervised Learning is one of the most fundamental training paradigms in ML, which requires labeled data to guide the optimization of models <ref type="bibr" target="#b66">[60]</ref>, <ref type="bibr" target="#b67">[61]</ref>. For GNNs, supervised learning enables to capture both local and global graph structures and the latent information of vertices and links. It iteratively optimizes model parameters by minimizing the difference between the model's predictions and the labels, where the performance of the model is evaluated on a separate test set of labeled objects. Supervised GL has found success in various domains such as social network analysis, intelligent transportation, and recommendation systems. However, in many real-world scenarios where labels are unavailable or expensive, supervised learning is constrained and other semisupervised or unsupervised learning paradigms are introduced.</p><p>Transfer Learning (TL) for GI models builds upon the assumption that the learned representations and knowledge from a source graph can be effectively transferred and applied to a targeted graph <ref type="bibr" target="#b68">[62]</ref>, <ref type="bibr" target="#b69">[63]</ref>. Based on this, it exploits knowledge distillation methods to extract the knowledge from one graph data to improve the learning performance on another different but related graph data. By transferring knowledge across graphs, the target graph benefits from the learned representations, enabling improved prediction performance for the targeted graph, even with limited labeled data.</p><p>Contrastive Learning (CL) for GI models is a selfsupervised learning paradigm that learns meaningful representations by contrasting positive and negative samples, where positive samples are pairs of vertices, links, or subgraphs that are similar or related, and negative ones are the contrary <ref type="bibr" target="#b70">[64]</ref>- <ref type="bibr" target="#b72">[66]</ref>. With these samples, contrastive learning maximizes the similarity between positive samples and minimizes the similarity between negative samples. Various techniques have been applied to enhance contrastive learning on graphs, such as graph augmentation and sample generation with random walks.</p><p>Variational Learning extends the idea of variational inference to GNN, introducing a probabilistic framework to learn node or graph-level representations. This technique is mainly applied in Variational GAEs <ref type="bibr" target="#b57">[51]</ref>, where each node's embedding is treated as a latent variable sampled from a learned distribution. The variational framework enables the model to capture uncertainties in graph data by learning distributions over node embeddings rather than fixed values. This allows for uncertainty quantification by modeling distributions over node embeddings, improving robustness to noisy data, and preventing overfitting through regularization. This leads to more expressive representations and enables generative tasks like predicting missing links or generating new graph structures <ref type="bibr" target="#b73">[67]</ref>.</p><p>Federated Graph Learning (FGL). FGL applies Federated Learning (FL) on graphs, which allows multiple clients to collaboratively train a GI model without sharing their local data <ref type="bibr" target="#b74">[68]</ref>- <ref type="bibr" target="#b76">[70]</ref>. In particular, each client trains the GI model using its local graph data and shares only the model updates, i.e., gradients or weights, with a central coordinator, and the coordinator aggregates the updates and sends a merged model update back to each client. Graph data are typically distributed across clients, with respect to structural segments, i.e., subgraphs, or feature segments. More details on FGL are discussed in Sec. VI-A.</p><p>Deep Graph Reinforcement Learning (DGRL). DGRL combines GI models with Deep Reinforcement Learning (DRL) techniques for interacting with graph environments Fig. <ref type="figure">4</ref>. Architecture overview of cloud-edge-end hierarchy, where distributed edge devices within edge networks serve as infrastructure for graph-intelligent applications and their networked data can be analyzed by graph representation learning models.</p><p>[29], <ref type="bibr" target="#b36">[30]</ref>. Typically, in DGRL, the GI model is responsible for processing the graph data, extracting features, and capturing the relationships between vertices and links. The DRL component then uses the embeddings computed by the GI model to learn a policy and make decisions, often by taking actions like vertex selection, link insertion/removal, or graph modification. Benefiting from the superior capability of representing graphs, DGRL has become a powerful tool for graph-based sequential decision-making tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Edge Networks and Edge computing</head><p>1) Basic Concepts: Edge networks have emerged as a pivotal architecture, facilitating the transition from centralized cloud-based core networks to the much more decentralized edge <ref type="bibr" target="#b77">[71]</ref>- <ref type="bibr" target="#b79">[73]</ref>. Fig. <ref type="figure">4</ref> illustrates the edge network as a cohesive architecture that integrates the Edge and End layers, encompassing devices naturally situated closer to end users. Besides traditional network-style topology, edge networks can exhibit versatile organizations such as peer-to-peer connection (e.g., client-server mode) and star-like interactions (e.g., oneto-many subscription).</p><p>Specifically, in contrast to the centralized core networks, several salient features distinguish edge networks: (1) Distributed: Edge networks are characterized by their geographically dispersed resources, such as edge servers and mobile devices, in stark contrast to the centralized nature of cloud-based data centers. (2) Heterogeneity: Edge networks encompass a diverse array of edge devices and servers, each varying in computational capacity, network bandwidth, and hardware architecture, embodying an extremely heterogeneous computing environment. (3) Resource Constraints: Unlike cloud-based data centers equipped with high-performance accelerators and dedicated ultra-speed links, devices within edge networks often operate under resource limitations, facing constraints in aspects like computational throughput, device-to-device communication bandwidth, and memory capacity. (4) Dynamic Resources: The proximity of edge network devices to end users inherently results in greater dynamism in resource availability. Their mobility across various networking domains and multitasking with multiple applications simultaneously contribute to frequent fluctuations in both network and computational resources.</p><p>Emerging from the advanced architecture of edge networks, edge computing stands as a new computing paradigm in contrast to cloud computing <ref type="bibr" target="#b14">[8]</ref>, <ref type="bibr" target="#b50">[44]</ref>. Edge computing represents a shift in computational paradigm that brings data processing exponentially closer to the point of data collection and consumption, enabling low-latency and high-bandwidth communication essential for real-time applications <ref type="bibr" target="#b80">[74]</ref>, <ref type="bibr" target="#b81">[75]</ref>. With lower reliance on the core network, edge computing not only alleviates both the stress of centralized cloud and backhaul bandwidth usage but also enhances privacy preservation through localized data processing.</p><p>2) Components of Edge Networks: Locating at the periphery of the Internet, edge networks cover a wide spectrum of diverse and heterogeneous platforms. From fragmentation to integration, we enumerate example components in edge networks in five levels as in Fig. <ref type="figure" target="#fig_2">5</ref>.</p><p>Sensors are devices that capture real-time data from the physical environment, such as image, temperature, motion, and gas composition. This type of device is the most scattered IoT and is thus located at the bottom level in Fig. <ref type="figure" target="#fig_2">5</ref>, where several example sensors as shown.</p><p>Embedded and Mobile Devices are advanced systems that integrate multiple sensors and MCUs into a single, often portable, framework. Unlike standalone sensors or MCUs that primarily capture or process data, these devices offer comprehensive functionality, including data processing, analysis, and user interaction. Embedded devices are specialized computing units designed for specific functions within larger systems.</p><p>Robots and Vehicles usually excel in functionality, autonomy, and complexity. While embedded devices are integral to these systems, robotics and vehicles incorporate them into more complex frameworks, designed for higher autonomy and minimal human intervention.</p><p>Edge Servers act as micro data centers to deliver services in a way similar to using cloud servers but with a key difference: they are situated closer to the data source. This proximity not only ensures adherence to data localization laws but also significantly reduces data transfer latency.</p><p>Edge Cloud services extend cloud computing's convenience to the network's edge, with providers like AWS and Google offering solutions such as AWS Edge Service <ref type="bibr" target="#b82">[76]</ref> and Google Distributed Cloud Edge <ref type="bibr" target="#b83">[77]</ref>. Edge clouds are usually hosted by micro-data centers comprising edge servers that store, analyze, and process data faster than is possible using a connection to a cloud data center.</p><p>3) Software Frameworks for Edge Networks: Software frameworks for edge computing across edge networks are often cross-platform, cross-protocol, language-agnostic, and resource-efficient. EdgeX Foundry <ref type="bibr" target="#b84">[78]</ref> is an open-source edge platform that lets users create IoT gateway functionality from edge devices, which acts as a dual transformation engine sending and receiving data to and from cloud and edge applications. Eclipse Kura <ref type="bibr" target="#b85">[79]</ref> has taken a similar approach to EdgeX Foundry to provide a platform for developing IoT gateways. Apache Edgent <ref type="bibr" target="#b86">[80]</ref> is an open-source stream processing framework for edge computing, enabling developers to process sensor-collected streaming data in real time on edge devices. RedisEdge <ref type="bibr" target="#b87">[81]</ref> is a purpose-built, multi-model database for the demanding conditions at the IoT edge, which can ingest millions of writes per second with less than 1ms latency and a very small footprint (less than 5MB). TensorFlow Lite <ref type="bibr" target="#b88">[82]</ref> and MNN <ref type="bibr" target="#b89">[83]</ref> is an open-source lightweight framework that enables on-device machine learning by helping developers run their AI models on embedded and mobile devices to achieve edge intelligence.</p><p>Some software frameworks offer a simulation environment to model and simulate edge network infrastructures and services, providing timely, repeatable, and controllable methods for evaluating the performance of new edge applications and policies prior to actual development. EdgeCloudSim <ref type="bibr" target="#b90">[84]</ref> provides a simulation environment based on CloudSim <ref type="bibr" target="#b91">[85]</ref> but adds considerable functionality so that it can be efficiently used for edge network scenarios. IFogSim2 <ref type="bibr" target="#b92">[86]</ref> is a toolkit for modeling and simulation of resource management techniques in IoT, edge, and fog computing environments. YAFS <ref type="bibr" target="#b93">[87]</ref> is a Python-based simulator tool for architectures like Fog Computing ecosystems, facilitating analyses related to resource placement, deployment costs, and network design.</p><p>4) Edge Intelligence: AI stands at the forefront of modern technological advancements, enabling computer systems to perform tasks that typically require human intelligence. This encompasses a wide range of activities including learning, decision making, and problem solving. In recent years, deep learning (DL), a branch of machine learning, has become synonymous with AI's progress. Characterized by its use of multi-layered neural networks, DL enables the processing of complex data, driving innovations in areas such as image recognition, natural language processing, and automated decision-making. The marriage of edge computing and AI catalyzes the birth of edge intelligence <ref type="bibr" target="#b14">[8]</ref>, <ref type="bibr" target="#b50">[44]</ref>.</p><p>In examining the advancements in the field of AI, particularly in the realms of DL model training and inference, it becomes clear that edge intelligence holds distinct advantages over traditional cloud intelligence: (1) Model Training: In the current AI landscape, there has been a significant shift in data sources from centralized cloud data centers to increasingly ubiquitous edge devices, such as mobile and IoT devices. These methods require the collection of massive amounts of data in the cloud, exerting immense pressure on core networks due to high data traffic. Additionally, this centralized approach strains data center resources, both in terms of storage and data processing capabilities. Edge intelligence offers a strategic solution to this challenge. By facilitating the processing and training of deep learning models directly at the network edge, closer to where the data is generated <ref type="bibr" target="#b94">[88]</ref>- <ref type="bibr" target="#b96">[90]</ref>. (2) Model Inference: Upon completion of model training, these models are deployed to provide inference services to end users. Routing user requests to cloud-based systems for inference poses significant privacy concerns, as it could lead to the leakage of sensitive information, such as personal identifiers and location data. Moreover, relying on cloud-based inference services, which depend on the stability of core networks, may introduce significant propagation delays. This aspect is particularly critical for applications requiring real-time response, such as autonomous driving and medical-surgical robots. Edge intelligence, by processing these inference requests locally, not only enhances data privacy but also ensures low-latency, efficient service delivery, crucial for such time-sensitive applications <ref type="bibr" target="#b97">[91]</ref>, <ref type="bibr" target="#b98">[92]</ref>. EGI can be regarded as a particular genre of edge intelligence concerning GI and is yet in its seed time for exploration and exploitation. In the following sections, we will discuss EGI in detail from different aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EDGE GRAPH INTELLIGENCE AS A NEW EDGE AI PARADIGM</head><p>Stemed from edge AI, EGI dives into the fusion of edge networks and GI techniques, serving as a brand-new avenue for the evolution of AI deployment. In what follows, we discuss the benefits of EGI and provide a rating taxonomy of EGI in six levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Reciprocal Benefits of Edge Graph Intelligence</head><p>EGI provides reciprocal benefits in the following aspects.</p><p>• Edge networks for GI. With the rapid proliferation of mobile and IoT devices, data generated at edge networks have skyrocketed in both quantity and modality (e.g., physical signals, digital audio, and visual content). As predicted by IDC <ref type="bibr" target="#b99">[93]</ref>, the billions of IoT devices in edge networks are expected to generate over 90 Zettabytes of data in 2025. This naturally provides rich data nurseries Fig. <ref type="figure">6</ref>. Rating of EGI from the perspectives of both graph intelligence and edge network. In particular, EGI in Level 5 coalesces both lines and renders interactional EGI that can dynamically adapt the GI model for optimal model performance and the edge network for optimal runtime performance on the fly.</p><p>and abundant application scenarios for modifying, training, and fine-tuning GI models with real-world data, thus boosting GI models toward higher-degree intelligence.</p><p>Besides, edge networks as user-nearby infrastructures can effectively enhance GI model computing performance, e.g., edge networks assisted with cloud as the back-end can largely reduce the computing latency, thus boosting the GI performance. • GI for edge networks. Given the rich relational data collected at edge networks, GI enables modern graph analysis for understanding, diagnosing, and optimizing edge networks, which steers the enhancement of network performance such as robustness and Quality of Service (QoS). Applying GI to edge networks thus unlocks their extended capability in securing edge networks from anomalies, developing new graph-based applications, and intelligently serving graph-related tasks.</p><p>• Reciprocal technology advancement. The combination of GI and edge computing not only carries out mutual empowerment to improve each other (as mentioned above) but also enhances the advancement of both research and technology. For instance, EGI catalyzes a number of new edge applications (Sec. V) and incubates an ecosystem including GNN-oriented hardware accelerators and programming frameworks (Sec. VIII), which actually expedites edge AI popularization. Additionally, and perhaps more notably, new technologies and system models for edge AI are being nourished and flourishing, extending beyond the traditional scopes and standards of these two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Rating of Edge Graph Intelligence</head><p>Given the reciprocal benefits of EGI, we advocate that EGI should not be restricted to merely applying GI on edge data or running GI on edge platforms. Instead, GI and edge networks are blending a confluence and EGI should be treated as a whole to reflect the inherent interplay between GI and edge networks. This indicates that their bilateral empowerment desires a comprehensive exploration such that the degree of EGI can be identified and measured. Specifically, according to the fusion of GI and edge networks, we may rate EGI into six levels from their respective perspectives, as shown in Fig. <ref type="figure">6</ref>.</p><p>• Level 0: Given the graph data implicated in the edge network infrastructure, analytical models in Level 0 are unaware of the graph structures. The edge computing systems also process data in a graph-agnostic way. In other words, neither the model side nor the infrastructure side explicitly tackles "graphs", and thus they are categorized to the initial level. For instance, visual data mining with traditional ML models and conventional neural networks like CNN <ref type="bibr" target="#b100">[94]</ref>, <ref type="bibr" target="#b101">[95]</ref> and RNN <ref type="bibr" target="#b102">[96]</ref>, <ref type="bibr" target="#b103">[97]</ref> can be categorized in Level 0 since their data are not formulated in graphs and their data processing pipeline has no specific relations with graphs. • Level 1: Data collected from edge networks are modeled in graphs but are not exploited in analytics. Systems at Level 1 push one step further over Level 0 by endowing graph semantic to edge data through graph modeling with collected edge data, but process data with general computing methods (instead of graph-related methods). As an example, while wireless sensory data can be generally abstracted in graphs <ref type="bibr" target="#b43">[37]</ref>, <ref type="bibr" target="#b44">[38]</ref>, Level-1 systems treat them in a vertex-wise manner, e.g., separately analyzing individual sensors' data arrivals, instead of processing as a whole graph. • Level 2: Edge data in graph formats are processed with traditional graph computing algorithms such as PageRank <ref type="bibr" target="#b104">[98]</ref> and single-source shortest path algorithms <ref type="bibr" target="#b105">[99]</ref>.</p><p>In this respect, edge data are modeled in graphs and processed with traditional graph algorithms rather than ML methods. Systems at Level 2 outperform Level 1 by enabling graph-oriented computing capability though they do not introduce AI techniques in graph processing.</p><p>• Level 3: Edge networks serve GI model inference with graph data, where the models may be trained on the cloud. Compared with lower levels, systems at Level 3 not only allow graph formulation and computing of edge data but also initiate AI to edge networks and embrace GI models such as GCN <ref type="bibr" target="#b21">[15]</ref> and GraphSAGE <ref type="bibr" target="#b54">[48]</ref>. In other words, edge systems that compute GNN inference such as GNNbased traffic forecasting systems <ref type="bibr" target="#b24">[18]</ref>, <ref type="bibr" target="#b106">[100]</ref> and DGRL decision systems <ref type="bibr" target="#b107">[101]</ref>, <ref type="bibr" target="#b108">[102]</ref> are located at Level 3. • Level 4: Edge networks perform GI model training with graph data. Example includes SUGAR <ref type="bibr" target="#b109">[103]</ref> and HGNAS <ref type="bibr" target="#b110">[104]</ref>. The key difference between Level 4 and Level 3 lies in the ability to learn edge-native GI models, e.g., fine-tuning model parameters with edge data. Otherwise stated, systems at Level 4 can customize their GI models in-situ, thereby enabling tailored ability for edge AI services. • Level 5: Interactional EGI, where GI and edge networks can dynamically adapt their configurations during the runtime for optimal EGI performance. Systems at Level 5 outperform all other levels because they can adjust GI and edge networks on the fly, whereas lower levels are all static settings. Both perspectives of GI and edge networks reach a convergence since they are in complete harmony. The EGI rating can be mainly divided into three intervals. The first interval covers from Level 0 to Level 2, where EGI is less related to AI and even processes non-graph data. The second interval comprises Level 3 and Level 4, where EGI incorporates GI models by either inference or training on edge networks. The third interval is exactly Level 5, which stands at the highest level because its GI and edge networks have profoundly blended as integration and can adapt to diverse scenarios on the fly. As EGI systems are located at higher levels, their fusions of GI and edge networks go deeper. As a result, the intelligence resources of GI and infrastructural resources of edge networks are progressively exploited for better EGI performance. Nonetheless, this may also come at the cost of additional development effort and system overhead. This conflict implies that there is no "silver bullet" in all cases. Instead, the panacea of EGI in practice should align with user demand, anticipating a joint consideration of specific application scenarios as well as available resources budgets. In this survey, given the focus on advanced GNN in edge environments, the reviewed systems mostly lie in Level 3 and beyond.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EDGE APPLICATIONS OF GRAPH INTELLIGENCE</head><p>Graphs are highly abstract data structures and can be used to represent a spectrum of data generated in edge networks. These graph data drive miscellaneous applications at the last mile of the Internet, as exemplified in Fig. <ref type="figure">7</ref>, and catalyze graph learning as a promising principle for edge intelligence. Following the insights discussed in Sec. IV, we first provide a panorama of representative EGI applications before showing how edge networks and GI interact with each other in subsequent sections. For clarity, we categorize them into five groups, i.e., smart cities, robots and vehicles, human sensing and analysis, location-based recommendation, and graph-based mobile vision. Note that edge applications of GI models mostly only compute GI model inference at the edge and these related EGI systems therefore lie at Level 3 in the rating taxonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Smart Cities</head><p>Managing large cities is one of the key problems for modernization, especially under the stresses of continuously booming urbanization and the rapidly growing population. To enable resource-efficient management, AI has been widely recognized as an advantageous way to assist, promoting the concept of "smart cities" <ref type="bibr" target="#b113">[107]</ref>, <ref type="bibr" target="#b114">[108]</ref>. Given the ubiquity of wireless sensor networks and graph data in cities, GI shines among AI techniques and enables numerous smart applications. Note that many use cases may not be fully deployed on edge networks but involve the cloud as a backend, our review focuses on the processing of graph data collected at the edge and demonstrates how these applications run. In the following, we discuss representatives concerning transportation, energy, environment, and public safety.</p><p>1) Intelligent Transportation Systems: The transportation system spans geographical areas and acts like the blood vessels of a city. To keep it smooth and unimpeded, GI models are applied for forecasting its states, predicting the supply and demand of users, as well as coordinating its resources.</p><p>Traffic state forecasting involves forecasting traffic amount, traffic flow, and travel time between two locations, etc. Typically, it takes data from roadside sensors and organizes them in a graph along with the structure of the road net, as visualized in Fig. <ref type="figure">7(a)</ref>, where the feature vector of each vertex is the collected data of each sensor. GI models can thereafter be utilized to learn the semantics of traffic networks and export predictions. For example, Li et al. <ref type="bibr" target="#b24">[18]</ref> introduce the Diffusion Convolutional Recurrent neural network to model traffic flow as a diffusion process on a directed graph, capturing both spatial dependencies through bidirectional random walks and temporal dynamics using an encoder-decoder architecture. Recognizing the critical role of spatial and temporal dependencies in traffic flow, Yu et al. <ref type="bibr" target="#b106">[100]</ref> present Spatio-Temporal Graph Convolutional Networks, a novel approach for time series prediction in traffic analysis. Instead of applying regular convolutional and recurrent units, STGCN utilizes a fully convolutional structure on graphs, enhancing training efficiency and reducing parameter count.</p><p>Supply and demand predictions are a type of trip prediction task though they are often viewed as an ensemble, namely the origin-destination demand prediction. This can be relevant in many ride-hailing services (e.g., Uber <ref type="bibr" target="#b115">[109]</ref>, DiDi <ref type="bibr" target="#b116">[110]</ref>, and Lyft <ref type="bibr" target="#b117">[111]</ref>), where accurately predicting users' demand is crucial for dispatch orders concerning efficiency and profit. Building on the importance of capturing dynamic dependencies in traffic flow, Lu et al. <ref type="bibr" target="#b118">[112]</ref> developed a dual attentive GNN that can effectively predict the distribution of metro passenger flow considering the spatial and temporal influences. Further expanding on the application of attention mechanisms in GNNs, Makhdomi et al. <ref type="bibr" target="#b119">[113]</ref> introduce a GAT Fig. <ref type="figure">7</ref>. Edge networks host a broad spectrum of platforms including wireless sensors, robots, vehicles, gateways, and cameras. These facilities spawn miscellaneous smart GI applications with their data organized in graphs. (a) A traffic sensory network is a graph with sensors as vertices and links aligned with the road net. (b) A power grid is naturally a graph that connects electrical facilities (image adapted from <ref type="bibr" target="#b111">[105]</ref>). (c) A robotic arm can be abstracted in a graph with joints as vertices (image adapted from <ref type="bibr" target="#b112">[106]</ref>). (d) A drone swarm comprises vehicles and their communication relationships shape a graph. (e) Human skeletons can be represented in graphs. (f) Location-based social networks are constructed upon users' fellowship. (g) A graph representation of an 18×12-pixels image of the digit "6", where pixels are vertices and their direct adjacency are links. (h) An edge network hierarchy is a tree-like graph. method for passenger origin-destination flow prediction that leverages diverse linear and non-linear dependencies among requests originating from distinct locations, capturing both the repetition pattern and contextual data of each location. Their superior performance demonstrates the capability to capture inherent connections between regions or origin-destination pairs, and some of them <ref type="bibr" target="#b118">[112]</ref>, <ref type="bibr" target="#b120">[114]</ref> have been deployed in the wild.</p><p>Traffic resource management is to detect or schedule dedicated components in transportation systems. As an example, Wang et al. <ref type="bibr" target="#b121">[115]</ref> and Yu et al. <ref type="bibr" target="#b122">[116]</ref> both introduce GI-based approaches aimed at addressing critical issues in intelligent transportation systems. These frameworks capture complex dependencies within their respective applications, showcasing the versatility of GNNs in this field. However, their focuses differ significantly. Wang et al. <ref type="bibr" target="#b121">[115]</ref> specifically design their GI model for traffic anomaly analysis in IoT-based intelligent transportation systems, aiming to identify and analyze traffic anomalies, while Yu et al. <ref type="bibr" target="#b122">[116]</ref> focus on the operational problem of relocating and repositioning idle vehicles, a crucial aspect of traffic resource management.</p><p>2) Power Grid: As basic facilities for smart cities, power grids deliver electricity from power plants to end users through transmission and distribution lines, substations, and equipment. To serve as many people in the city as possible, modern power grids have evolved to a colossal scale, becoming an extremely complex system that is vulnerable to attacks and system failure. Given the graph nature of power grids, GI models are employed to ensure their reliability and stability, i.e., for failure detection and energy harvesting prediction.</p><p>Failure detection aims at localizing potential or yetoccurring failures within the power grid. Liao et al. <ref type="bibr" target="#b123">[117]</ref> utilize the adjacency matrix to represent the similarity between unknown and labeled samples, and propose graph convolutional layers for identifying complex nonlinear relationships between dissolved gas and fault type. Building on the use of GCNs in power system diagnostics, Liu et al. <ref type="bibr" target="#b124">[118]</ref> further present a technique that employs GCNs for swiftly identifying key failure points in power systems. This method simplifies and speeds up the process of detecting critical cascading failures, making it highly effective for complex power networks. Extending GI to the realm of cybersecurity in power grids, Boyaci et al. <ref type="bibr" target="#b125">[119]</ref> introduce a deep learning model utilizing Chebyshev GCNs for detecting cyberattacks, specifically false data injection attacks, in large-scale AC power grids.</p><p>Energy harvesting prediction is for power grids with vulnerable energy input, e.g., solar energy and wind energy. Accurately predicting their future behavior is of great importance for power systems with high penetration of RESs for stable operation and economic consideration. Karimi et al. <ref type="bibr" target="#b126">[120]</ref> focus on improving photovoltaic power forecasting by leveraging spatial and temporal coherence among power plants. They propose an STGNN to harness the relationship between power plants, observing that plants in a region experience similar environmental conditions and can thus inform each other's power forecasts. Khodayar et al. <ref type="bibr" target="#b32">[26]</ref> introduce a convolutional GAE for capturing continuous probability densities on graph nodes. By integrating spectral graph convolutions and variational Bayesian inference, convolutional GAE generates samples from these densities. This approach is applied to probabilistic solar irradiance prediction, using an undirected graph model of solar radiation measurement sites for future irradiance estimation. In their subsequent research, Khodayar et al. <ref type="bibr" target="#b127">[121]</ref> further tackle the challenge of forecasting behindthe-meter load and rooftop photovoltaic generation in power systems using a spatio-temporal GAE and graph dictionary learning optimization.</p><p>3) Environment Monitoring: Environmental science assumes a crucial role in comprehending the dynamics of natural systems and their complex interactions with human activities, particularly for smart cities. DL, as a powerful tool, has emerged to support environmental science in smart cities, enabling the analysis of vast amounts of data to model and predict environmental phenomena such as air quality concen-tration. In this context, GI techniques have found extensive applications in the study of wireless sensor networks for environmental monitoring in the realm of smart cities, with respect to environmental assessment and prediction as well as meteorological monitoring and forecasting.</p><p>Environmental assessment and prediction aims at extracting environmental information from sensory data collected across smart cities. Chen et al. <ref type="bibr" target="#b128">[122]</ref> introduce the group-aware GNN (GAGNN) for nationwide air quality forecasting, in order to understand latent dependencies among geographically distant cities. GAGNN constructs a hierarchical model with a city graph and city group graph, combined with a differentiable grouping network to discover and encode these complex intercity relationships. In addition to the use of GCNs, both Gao et al. <ref type="bibr" target="#b129">[123]</ref> and Mao et al. <ref type="bibr" target="#b130">[124]</ref> incorporate LSTM to integrate spatio-temporal information for more accurate predictions. For example, Mao et al. <ref type="bibr" target="#b130">[124]</ref> develop a graph convolutional temporal sliding LSTM model to predict various air pollutants. They use GCNs to model spatial dependencies and a temporal sliding LSTM strategy to capture dynamic changes over time, allowing for a broader application beyond just PM2.5 prediction.</p><p>Meteorological monitoring and forecasting leverage GI models to analyze meteorological data for understanding current weather conditions and predicting future weather patterns. Remote automatic weather stations can collect geo-distributed meteorological data for temperature prediction. The targeted sensory data are usually in a spatio-temporal form, covering atmospheric parameters such as temperature, humidity, pressure, wind speed and direction, precipitation, and other relevant variables. As an example, Lin et al. <ref type="bibr" target="#b131">[125]</ref> present the Conditional Local Convolution Recurrent Network for spatio-temporal forecasting in weather prediction, overcoming challenges of high nonlinearity and complex spatial patterns. It introduces a GCN that captures local spatial patterns through conditional local convolutions and incorporates these into an RNN architecture to model temporal dynamics. Addressing the challenge of accurately forecasting frost events, which significantly impact agriculture, Lira et al. <ref type="bibr" target="#b132">[126]</ref> describe a GNN with spatio-temporal attention architecture. The model, adept at handling the localized nature of frost influenced by various environmental factors, maps weather station data onto a graph structure, optimizing an adjacency matrix during training to capture complex environmental interactions. Similarly focusing on the spatial relationships among weather stations, Stanczyk et al. <ref type="bibr" target="#b133">[127]</ref> introduce GI models for wind speed prediction, focusing on handling data from multiple weather stations.</p><p>4) Public Safety: Ensuring residents' physical safety and security is of primary importance in building smart cities. Towards that, GI techniques are employed to analyze graph data collected from city-wide edge networks and to find patterns related to residents' health. We next discuss them in three respects, namely natural disaster prevention, crime warning, and public health.</p><p>Natural disaster prevention utilizes GI to aid people in mitigating the impact of unexpected extreme hazards, including earthquakes, wildfires, floods, and hurricanes. Bilal et al. <ref type="bibr" target="#b34">[28]</ref> presents a batch normalization GCN for early earthquake detection, which integrates a CNN with a GNN. The model employs batch normalization to reduce training epochs and stabilize activation value distributions, enhancing training efficiency and prediction accuracy for key earthquake parameters like magnitude, depth, and location. This approach of integrating CNNs with GCNs for efficient feature extraction and spatial relationship modeling is not limited to seismology. Similarly, Jin et al. <ref type="bibr" target="#b134">[128]</ref> tackle the challenge of predicting urban fire dynamics, which is crucial for urban safety and emergency response. They propose a model that combines CNNs with GCNs, where CNNs extract pixel-level latent representations from fire situation awareness images and GCNs manage the spatial relationships between different urban areas. By integrating the strengths of CNNs and GCNs, <ref type="bibr" target="#b134">[128]</ref> effectively illustrates how this combined approach can address complex spatio-temporal phenomena, highlighting its versatility and potential across different domains.</p><p>Urban crime is another critical factor imperiling residents' properties and lives. To raise the attention of people potentially in criminal danger, researchers develop GI models to predict crime frequency in dedicated regions. Xia et al. <ref type="bibr" target="#b135">[129]</ref> present the Spatial-Temporal Sequential Hypergraph network (ST-SHN), aimed at improving crime prediction by addressing the dynamic nature of criminal patterns in both spatial and temporal domains, and the evolving dependencies between different crime types. ST-SHN employs a graph-structured messagepassing architecture combined with hypergraph learning to manage the spatial-temporal dynamics and global context of crime. In parallel, Sun et al. <ref type="bibr" target="#b136">[130]</ref> present AGI-STAN, a framework that improves crime prediction by discarding reliance on domain-specific knowledge and predefined graphs. It uses adaptive graph learning to autonomously discern interdependencies among urban communities and integrates a time-aware self-attention mechanism to model temporally varying crime incidents. Toward the same problem, these two methods take different optimization paths: ST-SHN focuses on global context through hypergraph learning, while AGI-STAN discovers community interdependencies and processes temporal information adaptively.</p><p>Epidemic outbreaks, notably the recent novel coronavirus, pose significant threats to global public health systems. Accurate epidemic prediction is crucial, as it plays a vital role in safeguarding public health by informing and guiding proactive strategies to mitigate the impact of such health crises. In this context, GI has emerged as a powerful tool for modeling the complex interactions inherent in epidemic data. Both Kapoor et al. <ref type="bibr" target="#b137">[131]</ref> and Keicher et al. <ref type="bibr" target="#b138">[132]</ref> leverage the expressiveness power of GNNs to address different facets of COVID-19 prediction, underscoring the versatility and efficacy of graphbased modeling in this domain. While both studies employ GNNs to harness the complexity of COVID-19 data, they differ in their specific applications and data integration strategies. <ref type="bibr">Kapoor</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Intelligent Robots and Vehicles</head><p>Robots and vehicles are typical facilities deployed in edge networks and have undertaken multifaceted services for human beings <ref type="bibr" target="#b139">[133]</ref>. Graphs are also widely used to represent their behaviors, thereby promoting GI as a promising tool to empower more autonomous machine intelligence. Regarding the objects that are represented in graphs, we discuss GI for robots and vehicles in three respects, i.e., body control and manipulation, motion prediction and planning, and environment exploration.</p><p>1) Body Control and Manipulation: Controlling the body of a robot is an initial step to steer its work, which requires an accurate modeling of it. However, body modeling is nontrivial, since it usually interacts with objects, environments, and human beings. For instance, when directing a robotic arm to grasp a compliant object, e.g., a soft bread, it very likely suffers a non-linear deformation, depending on the force and torques made by the arm. To address that, the robots are formulated in graphs with the spatial and kinetic relationships between keypoints, as depicted in Fig. <ref type="figure">7(c)</ref>, and GI models are applied to abstract them. Almeida et al. <ref type="bibr" target="#b140">[134]</ref> address the complex task of modeling soft robots using a GNN to simulate a non-rigid kinematic chain, like a robotic soft hand.</p><p>With a model of the robot, we may envisage to command it to firmly grasp or manipulate some objects. This requires, beyond body modeling, to characterize the interaction between robots, objects, and environments. In this context, Li et al. <ref type="bibr" target="#b141">[135]</ref> make a significant contribution by introducing dynamic particle interaction networks (DPINets), a differentiable, particle-based simulator. This innovative approach leverages dynamic interaction graphs to adeptly handle the manipulation of a variety of materials, including fluids, deformables, and rigid bodies. Building upon the foundation laid by the DPINets' focus on material interaction, Xie et al. <ref type="bibr" target="#b142">[136]</ref> present a deep imitation learning framework for bimanual robotic manipulation in continuous state-action spaces, focusing on the challenge of generalizing manipulation skills to objects in varying locations. Further extending the application of graph-based learning in robotics, Liang et al. <ref type="bibr" target="#b143">[137]</ref> introduce a self-supervised learning method, target-oriented Deep Q-Network (DQN), which employs visual affordance graphs for a complex object grasping task, guiding robot actions using environmental cues in both simulated and real-world scenarios. These three works collectively exemplify the power of graphbased modeling in advancing robotic manipulation capabilities</p><p>2) Motion Prediction and Planning: In many circumstances, vehicles are not launched individually but collaboratively, which requires global planning of vehicles to attain mutual goals <ref type="bibr" target="#b144">[138]</ref>. For these cases, GI is also profitable with vehicles modeled in graphs. For instance, Fig. <ref type="figure">7(d)</ref> shows a drone swarm committed to collision-freely flying from a starting point to a targeted location, where they can be viewed as a graph with links indicating their communication paths. Another illustration is shown in Fig. <ref type="figure" target="#fig_3">8</ref>, where the movement of vehicles is modeled in a time-varying graph and fed into a GAE for learning graph representations. Through a predictor and a planner, the EGI system can export the prediction and planning of the vehicle's next motion. Li et al. <ref type="bibr" target="#b145">[139]</ref> tackle the challenge of decentralized multi-robot path planning by introducing a model that synthesizes local communication and decision-making policies for robots in constrained workspaces. The model combines a CNN for extracting features from local observations and a GNN for efficient communication among robots. A similar structure is exploited by <ref type="bibr" target="#b146">[140]</ref>, which presents the dynamic motion planning model based on graph neural networks and historical information to enhance pathfinding in decentralized multi-robot systems.</p><p>3) Environment Exploration: Contrary to motion planning where destinations are known, multi-robot exploration tasks demand exploring an unknown environment a key aspect of automation applications like cleaning, searching, and rescue. For these tasks, scheduling robot swarms to efficiently cover the underexplored field while avoiding conflicts is vital <ref type="bibr" target="#b147">[141]</ref>, <ref type="bibr" target="#b148">[142]</ref>.</p><p>To achieve that, researchers define the spatial relationships between robots and regions of the environment and intend to apply GI to regulate this complex process. Luo et al. <ref type="bibr" target="#b149">[143]</ref> were among the pioneers in this domain, introducing a graphbased DRL approach for autonomous exploration in unknown territories. By translating the exploration task into a graph domain through a hierarchical map segmentation, they paved the way for utilizing a GCN to effectively assign exploration targets to agents. This seminal work highlighted the potential of GNNs in enhancing multi-agent exploration efficiency. Building upon this, Gosrich et al. <ref type="bibr" target="#b150">[144]</ref> advanced the application of GNNs by developing a decentralized control policy for multi-robot sensor coverage. Their innovative approach allowed robots with limited sensing capabilities to efficiently detect events in regions of varying importance. In parallel, Zhang et al. <ref type="bibr" target="#b151">[145]</ref> have taken the application of GNNs a step further with the introduction of Hierarchical-Hops Graph Neural Networks (H2GNN) for multi-robot coarse-to-fine ex-ploration. Their approach stands out by enabling selective integration of key environmental information through a multihead attention mechanism, which discerns the importance of information from different hops.</p><p>Together, these studies provide a comprehensive view of how GNNs can be leveraged to address a spectrum of challenges in multi-agent robotics, setting the stage for future advancements in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Human Sensing and Analysis</head><p>Human sensing is one of the core applications in many edge services, which use edge devices to collect and process data related to human activities and behaviors. Various platforms are involved, including sensors, smartphones, wearables, cameras, etc., to monitor various aspects of human behavior such as movement, gestures, vital signs, facial expressions, and environmental interactions. GI models are employed in this context for those data that can be formulated in graphs. In general, these human sensing applications are mainly recognized in three types: affective computing with facial graphs, action recognition with human skeletons, and smart health with human-centric sensor networks.</p><p>1) Affective Computing: Facial expressions contribute to more than 55% of the information perceived by individuals during verbal communication <ref type="bibr" target="#b152">[146]</ref>, <ref type="bibr" target="#b153">[147]</ref>, which plays a crucial role in conveying significant information related to emotional states and reactions within human interactions. To enable user-centric services deployed at the edge, the community has developed various intelligent affective computing methods to understand users' facial affects. Notably, some researchers establish graph representations for faces, where facial landmarks are marked as vertices and are connected in facial shapes, and introduce GI models to reason users' states.</p><p>In a harmonious convergence, Xie et al. <ref type="bibr" target="#b154">[148]</ref>, Liu et al. <ref type="bibr" target="#b155">[149]</ref>, and Zhao et al. <ref type="bibr" target="#b156">[150]</ref> have each harnessed GNNs to decode the complex language of human emotions manifested through facial movements. Specifically, Xie et al. <ref type="bibr" target="#b154">[148]</ref> delve into the micro-level of facial expressions, integrating action units with emotion category labels within a graph framework, thereby enhancing the precision of recognition tasks that are critical in various real-world applications. Building upon this graph-centric perspective, Liu et al. <ref type="bibr" target="#b155">[149]</ref> propose a semantic graph-based dual-stream network that addresses a key limitation of conventional CNN methods by incorporating semantic information into the recognition process. Their model not only learns from physical appearance but also understands the deeper meaning behind facial movements. Similarly, Zhao et al. <ref type="bibr" target="#b156">[150]</ref> contribute to the field by developing a geometryaware FER framework, which combines the structural analysis capabilities of a GNN with the feature extraction prowess of a CNN. This dual-pronged strategy allows for a detailed examination of both the geometric and appearance-based aspects of facial expressions, leading to a robust recognition system that is sensitive to the minute details of human emotions.</p><p>2) Action Recognition: The rapid advancement of Human Action Recognition (HAR) and tracking techniques has emerged as a crucial catalyst for diverse edge applications, e.g., for security surveillance and robot imitation. The rationale behind using GI models for action recognition is to model human bodies into skeleton-based graphs, as exemplified in Fig. <ref type="figure">7</ref>(e). Specifically, body joints are regarded as vertices with each attached a feature vector indicating its 3D/2D coordinates and confidence scores, while they are connected along with the human skeletons.</p><p>In the realm of graph-based models for skeleton dynamics, a spectrum of approaches has been explored, categorized by their focus on spatial or spatio-temporal characteristics. Wang et al. <ref type="bibr" target="#b157">[151]</ref> present Graph-PCNN, a framework that refines keypoint localization through a two-stage process, enhancing the accuracy of human pose estimation. This model-agnostic framework underscores the importance of accurate initial localization, which is further improved through a graph pose refinement module. Building upon the spatial foundation, Peng et al. <ref type="bibr" target="#b158">[152]</ref> take a leap into the spatio-temporal domain by employing NAS to evolve an adaptive GCN for HAR. Their approach integrates dynamic graph modules and multiple-hop connections, which not only bolsters the network's capacity to capture the nuances of motion in skeleton data but also aligns with the spatial-temporal emphasis of Graph-PCNN, albeit in a different context. Similarly, Jin et al. <ref type="bibr" target="#b159">[153]</ref> address the complexity of multi-person pose estimation by proposing a hierarchical graph grouping method. This work, like Graph-PCNN, leverages the power of graph structures but diverges by reformulating the human part grouping into a graph clustering task, offering a fresh perspective on the integration of graph theory in pose estimation.</p><p>3) Smart Health: Smart health, also known as digital health or eHealth, has been a widely-concerned field in edge networks. GI techniques are widely adopted in the healthcare domain and their applications are mainly about Electronic Health Records (EHRs) analysis and health condition analysis. In this paper, we particularly focus on the latter since it relates to edge networks.</p><p>Health condition analysis integrates GI with sensing techniques to enable healthcare monitoring and intervention. The synergy of these technologies is exemplified in Dong et al.'s work <ref type="bibr" target="#b160">[154]</ref>, where they introduce a GI model that harnesses mobile sensing data to detect early signs of influenza-like symptoms by encapsulating the dynamics of state transitions and internal dependencies within human behaviors through graph representation. Building upon this foundation, the concept of semi-supervised learning is elegantly integrated in the work <ref type="bibr" target="#b161">[155]</ref>, where they propose a Graph Instance Transformer (GIT). GIT not only combines multi-instance learning with contrastive self-supervised learning but also demonstrates the adaptability of GNNs in predicting early signs of mental health disorders. Similarly, Jia et al. <ref type="bibr" target="#b162">[156]</ref> contribute to the field by introducing GraphSleepNet, a GI framework specifically tailored for automatic sleep stage classification. This framework adeptly tackles the challenge of utilizing brain spatial features and the transition information among sleep stages, showcasing the versatility of GNNs in addressing complex health-related problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Location-Based Services</head><p>Social relationships in edge networks usually appear in a location-based manner, i.e., with social entities distributed geographically. Provided with the nature graph structure of social networks as shown in Fig. <ref type="figure">7</ref>(f), GI models bring advanced learning ability for mining location-based social information and exploring Point-of-Interest (POI), raising significant attention from the community. In the context of locationbased social networks, we discuss their applications for social POI recommendation and geographical POI recommendation, respectively.</p><p>1) Social POI Recommendation: Social POI recommendation utilizes users' activities on social media platforms to provide recommendations for friends they may know or products they may like to purchase. In a pioneering approach, Kefalas et al. <ref type="bibr" target="#b163">[157]</ref> enhance the traditional recommender system by introducing a hybrid tripartite graph that intertwines user, location, and session networks. This structure is analyzed using an advanced random walk with a restart algorithm, which captures the fluid nature of user preferences over time and space. Building upon this foundation, Salamat et al. <ref type="bibr" target="#b164">[158]</ref> introduce HeteroGraphRec, a sophisticated recommender system that considers social networks a heterogeneous graph. Continuing this thread of innovation, Wang et al. <ref type="bibr" target="#b165">[159]</ref> tackle the specific challenge of session-based recommendations by proposing an STGCN model. This model predicts a user's immediate interests by considering the sequence of their recent anonymous behaviors, thereby providing a more nuanced and responsive recommendation strategy.</p><p>2) Geographical POI Recommendation: The objective of geographical POI recommendation is to exploit users' behaviors to predict their potentially interested locations. Both Luo et al. <ref type="bibr" target="#b166">[160]</ref> and Yang et al. <ref type="bibr" target="#b167">[161]</ref> have introduced models that ingeniously incorporate spatio-temporal dynamics to predict user preferences for future locations. A common thread between these works is their reliance on attention mechanisms to dissect the complex interplay of spatial and temporal factors. Luo et al.'s STAN model <ref type="bibr" target="#b166">[160]</ref> introduces self-attention to directly model the spatial and temporal aspects of user check-ins, excelling at capturing the significance of non-adjacent and non-consecutive interactions. In a parallel yet distinctive approach, Yang et al.'s STAM model enhances GNNs by incorporating scaled dot-product and multi-head attention mechanisms, which enriches the learning of neighbor embeddings. The transition from STAN to STAM illustrates the field's maturation, moving from specific spatio-temporal interactions to a more integrated and comprehensive understanding of user preferences in recommendation systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Graph-Based Mobile Vision</head><p>Computer vision tasks accept inputs in the forms of images, videos, and point clouds, where many of them are represented by graphs. For instance, Fig. <ref type="figure">7</ref>(g) shows an image of the digit "6" in 18×12 pixels, whereby viewing pixels as vertices and their direct adjacency as links, it can be recognized as a graph. Another example is the skeleton-based graphs in many images of human actions, as discussed in Sec. V-C2 and Fig. <ref type="figure">9</ref>. Example point cloud processing with GI models. The point cloud data captured by autonomous vehicles can be reorganized in a graph format and processed with GI models for high-precision object detection. Image adapted from <ref type="bibr" target="#b168">[162]</ref>.</p><p>depicted in Fig. <ref type="figure">7(e)</ref>. GI models are applied to these graphs to assist various traditional computer vision tasks like image classification, object detection, point cloud analysis, etc.</p><p>1) Image Processing: In the evolving landscape of image processing, Graph Inference (GI) models have emerged as a powerful paradigm, particularly for tasks that require an understanding of the relationships and context within visual data.</p><p>At the forefront of this advancement is the work by Liu et al. <ref type="bibr" target="#b169">[163]</ref>, who introduced the Structure Inference Network (SIN). This pioneering approach in object detection treats objects as nodes and their interactions as links within a graph, providing a more holistic and contextual understanding of the visual scene. Expanding on this foundation, Chen et al. <ref type="bibr" target="#b170">[164]</ref> delve into the domain of multi-label image recognition. They propose a GCN model that constructs a directed graph of object labels, capturing the intricate dependencies and cooccurrences among them. This model not only builds upon the graph-based reasoning initiated by Liu et al <ref type="bibr" target="#b169">[163]</ref>. but also extends the concept to the challenges of recognizing multiple objects within an image. Following this thread, Lu et al. <ref type="bibr" target="#b171">[165]</ref> first apply the GCN to image semantic segmentation with their Graph-FCN, an approach that redefines the task as a graph node classification problem, successfully integrating local location information often overlooked by standard deep learning methods.</p><p>2) Video Analytics: Video analytics with GI models are mainly for HAR and Multi-Object Tracking (MOT). While HAR has been thoroughly explored in Section V-C2, this section delves into the latter, focusing on the innovative approaches that have emerged. Braso et al. <ref type="bibr" target="#b172">[166]</ref> set a message-passing network that not only integrates learning within the MOT paradigm but also crucially extends it to the data association phase (which is traditionally a bottleneck). Simultaneously, Liu et al. <ref type="bibr" target="#b173">[167]</ref> introduce the graph similarity model for MOT, which integrates a unique graph representation of object features and relationships, coupled with a graph matching module, to enhance robustness against occlusion and similar appearances in tracking scenarios. Both of them have independently demonstrated the potential of GI models to transform MOT by focusing on different yet complementary aspects of the problem, i.e., global reasoning and robust feature representation.</p><p>3) Point Cloud Processing: Different from images in 2D representations, point clouds are organized in 3D structure and provide richer semantics in describing scenes and objects. For instance, many autonomous vehicles use LiDAR to scan the environment and export point cloud data for perception, as in Fig. <ref type="figure">9</ref>. Yet the 3D data are still accommodated in a graph representation, and thereby GI models are leveraged for efficient processing.</p><p>Wang et al. <ref type="bibr" target="#b174">[168]</ref> develop EdgeConv, which enhances the representation power of point clouds by recovering topological information. This method uses dynamic graph construction to capture local geometric features, proving its suitability for high-level tasks in computer graphics and vision. Building on this idea of dynamic feature extraction, Shi et al. <ref type="bibr" target="#b168">[162]</ref> propose Point-GNN, a GI model for object detection from LiDAR point cloud, which incorporates an auto-registration mechanism to reduce translation variance and a box merging and scoring operator for accurate detection over multiple vertices.</p><p>Extending these advancements, Lin et al. <ref type="bibr" target="#b175">[169]</ref> develop 3D-GCN to address the challenges of processing and summarizing information in unstructured point clouds for 3D vision applications. Their approach is particularly effective when dealing with data variations such as shift and scale changes, aligning with the principles seen in EdgeConv. Furthermore, Zhang et al. <ref type="bibr" target="#b176">[170]</ref> present the linked dynamic GNN, which tackles the challenge of processing sparse, unstructured point clouds by linking hierarchical features from dynamic graphs. This method optimizes the network's architecture for more effective point cloud classification and segmentation, showing how linking hierarchical features can avoid the vanishing gradient problem and improve overall performance.</p><p>Lessons Learned (Sec. V) EGI has catalyzed a broad range of applications beyond traditional edge AI scenarios. These applications typically follow a general working procedure: the system collects data from components of edge networks and formulates them in graphs. The graph data are ingested into a GI model for graph embedding, along with a subsequent model, e.g., FCN and LSTM, for downstream tasks. The key to building a well-performed EGI application is carefully modeling the graph data and properly selecting the GI model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EDGE NETWORKS FOR GRAPH INTELLIGENCE</head><p>Given the applications introduced in Sec. V, this section discusses how edge networks serve GI execution in their multitier hierarchy. In the following, we survey various computing systems in different architectures according to their reliance on the cloud. Note that in each architecture, we review both model training and model inference systems, and their EGI ratings thus diverge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Federated Graph Learning</head><p>Edge-cloud synergy extends cloud resources as remote computing assists in optimizing the performance and efficiency of user-centric computing and data processing. Specifically, it enables certain computing tasks reserved at the edge for immediate processing, while employing the cloud for offloading more resource-intensive tasks with long-term storage and complex data analysis. This hybrid computing paradigm combines the differentiated capabilities of edge and cloud computing, thereby admitting flexible service computing for various applications <ref type="bibr" target="#b177">[171]</ref>.</p><p>For edge computation of GI models, typical workloads in the form of edge-cloud synergy are FL of GI models, i.e., Federated Graph Learning (FGL). FGL is the Level-4 EGI system in the rating taxonomy but is distinct from GI-assisted FL (GFL) as discussed in Sec. VII-D. Although they both combine GL and FL, the targeted model to be federatively trained in FGL is exactly GI models but GFL allows the targeted model to be any model not only GI models. Readers particularly interested in the combination of GI and FL may find dedicated reviews <ref type="bibr" target="#b178">[172]</ref>, <ref type="bibr" target="#b179">[173]</ref> for more information. With respect to the segmentation of the data space, FGL can be divided into horizontal ones (graph topology space) and vertical ones (feature data space).</p><p>1) Horizontal Federated Graph Learning: Horizontal Federated GNNs pertain to the scenario in which multiple clients participate in a federated learning setting, sharing identical node feature spaces while employing distinct node IDs <ref type="bibr" target="#b75">[69]</ref>. Each client possesses a minimum of one graph or a collection of graphs, and vertices are distributed across diverse clients with interconnections. Concerning the explicity of links between subgraphs on clients, horizontal FGL works can be categorized into two classes, namely with explicit cross-client links and with implicit cross-client links.</p><p>The first setting considers FGL with explicit links across subgraphs on FL clients, as in Fig. <ref type="figure" target="#fig_4">10</ref>. The conventional approach in this setting entails training local GI models within individual clients to initially acquire the local representations or node embeddings of the respective graphs. Subsequently, a Federated Learning (FL) algorithm is applied to facilitate the aggregation process, and the FL server, which is usually a cloud server, accumulates the model parameters or gradients received from the clients and performs FL aggregation. The resultant updated parameters are then returned to the clients for subsequent rounds of training. The introduction of FGL within this framework is contingent upon the specific research problems they address. For Non-IID graph data issues, many approaches intend to enhance the adaptation performance of local models or acquire a robust global model through model adjustment like model interpolation <ref type="bibr" target="#b180">[174]</ref>, <ref type="bibr" target="#b181">[175]</ref> and meta learning <ref type="bibr" target="#b182">[176]</ref>.</p><p>The second setting assumes that certain links connecting vertices across different clients are implicit and absent, illustrated in Fig. <ref type="figure" target="#fig_4">10</ref>. For the case where the implicit links connect vertices with dissimilar IDs, a prevalent strategy involves rectifying the local graphs by reconstructing the missing links. This ensures the local graph's completeness, thereby facilitating high-quality graph representation. Furthermore, the inclusion of links connecting clients aids in mitigating the challenges associated with non-IID data. FASTGNN <ref type="bibr" target="#b183">[177]</ref> introduces a straightforward link generator in the FL server, which is responsible for reconstructing absent links between clients by introducing Gaussian randomly generated links. These reconstructed edges are broadcast to all clients during FL training, prompting them to update their local graphs. In a similar vein, the link generator in FedGL <ref type="bibr" target="#b74">[68]</ref> produces a global pseudo graph with vertex embeddings provided by clients. Subsequently, this global pseudo-graph is disseminated to all clients, enabling them to amend their local graphs to facilitate GI model training. Based on the simple yet effective idea of link generation, follow-up works further develop more complex techniques for better performance <ref type="bibr" target="#b184">[178]</ref>, <ref type="bibr" target="#b185">[179]</ref>, consider privacy issues with security means <ref type="bibr" target="#b186">[180]</ref>- <ref type="bibr" target="#b188">[182]</ref>, and explore to improve communication efficiency <ref type="bibr" target="#b189">[183]</ref>, <ref type="bibr" target="#b190">[184]</ref>.</p><p>For the case where links are implicit in different clients, Knowledge Graph (KG) techniques are involved to complete information between these vertices. Once the local graphs have been rectified, the application of an FL algorithm facilitates the training of GI models in a similar manner as observed in scenarios with explicit links. FKGE <ref type="bibr" target="#b191">[185]</ref> adapts a GANbased module <ref type="bibr" target="#b192">[186]</ref> to facilitate the translation of aligned entity and relation embeddings across paired KGs, where the refined embeddings will be broadcast as long as the paired KGs are improved. FedE <ref type="bibr" target="#b193">[187]</ref> establishes an entity table on the server that catalogs unique entities from multiple clients. This table employs the FedAvg aggregation to process the aligned entity embeddings, and once processed, the updated embeddings are distributed back to the clients. Upon FedE, FedR <ref type="bibr" target="#b194">[188]</ref> and FedEC <ref type="bibr" target="#b195">[189]</ref> further improve the capability of privacy preservation and non-IID data resilience.</p><p>2) Vertical Federated Graph Learning: Vertical FGL assumes that clients possess nodes characterized by fully overlapping node IDs, albeit with distinct feature spaces. Through the utilization of FL, clients collaborate in training a global Graph Neural Network (GNN) model using features sourced from multiple clients. Within vertical FGL, there exist two distinct cases.</p><p>In the first case, graph topology, vertex features, and vertex labels are distributed across different clients. Consequently, clients may not be able to obtain the full graph data with respect to both vertex features and graph topology, as shown in Fig. <ref type="figure" target="#fig_5">11(a)</ref>. To orchestrate these clients in such semi-blind situations, SGCNN <ref type="bibr" target="#b196">[190]</ref> computes a similarity matrix based on the dynamic time-warping algorithm to sketch the graph's topology without knowing the underlying structure. One-hot encoding is employed to describe vertices' features under privacy requirements, which will be transmitted to the server to train the global GI model for GI-based tasks. FedSGC <ref type="bibr" target="#b197">[191]</ref> considers a two-client decentralized setting with vertices' features and graph topology being respectively possessed. In this scenario, FedSGC proposes an additively Homomorphic Encryption (HE) method to ensure privacy preservation during FGL.</p><p>The second case entails the ownership of solely disparate vertex feature spaces by clients, while the graph topology remains accessible to all clients (Fig. <ref type="figure" target="#fig_5">11(b)</ref>). For the case with only two clients and a central server, FedVGCN employs HE to encode intermediate data transferred across clients, where the server generates encryption key pairs and performs global FL aggregation. FMLST <ref type="bibr" target="#b198">[192]</ref> assumes a shared global spatio-temporal pattern across clients and applies an MLP to fuse local patterns and global patterns for personalizing client models. Graph-Fraudster <ref type="bibr" target="#b199">[193]</ref> investigates adversarial attacks on this vertical FGL scenario and shows differential privacy mechanisms and top-k mechanisms as two viable defense strategies against such attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Distributed Edge Collaboration</head><p>Besides completely offloading to the cloud or executing insitu, distributed edge collaboration, as a balanced compromise between them, introduces distributed training or inference of GI models within an edge network or between the edge-Fig. <ref type="figure">12</ref>. The graph data collected from edge networks can be processed via distributed edge collaboration, i.e., edge-cloud collaboration or multiedge collaboration. The former bridges the cloud and the participants from edge networks through GI model computation offloading, while the latter usually assembles multiple edge platforms as a whole to run GI services in a cooperative manner. cloud continuum as in Fig. <ref type="figure">12</ref>. This compromise offers several advantages, such as reduced remote transfer without cloud communication, (conditional) privacy preservation, and resource-augmented scalability <ref type="bibr" target="#b200">[194]</ref>- <ref type="bibr" target="#b203">[197]</ref>. According to the dependency of cloud servers, distributed edge collaboration typically exhibits in two forms, i.e., edge-cloud collaboration and multi-edge collaboration.</p><p>1) Edge-Cloud Collaboration: Edge-cloud collaboration differs from traditional integrated cloud offloading by splitting computation workload between edge platforms and cloud servers and thus can fortify the duty of the edge side and alleviate the reliance on the remote cloud <ref type="bibr" target="#b22">[16]</ref>, <ref type="bibr" target="#b204">[198]</ref>, <ref type="bibr" target="#b205">[199]</ref>. This allows edge facilities to be a key processor that blocks sensitive raw data from the cloud and eliminates redundant data transmission in the backhaul. Following this technical path, Branchy-GNN <ref type="bibr" target="#b206">[200]</ref> concentrates on GI-based point cloud processing and applies edge-cloud collaboration with a learning-based source-channel coding scheme for bandwidthefficient intermediate data transfer. It also borrows the idea of joint split learning and early exiting to reduce the computational cost on edge devices <ref type="bibr" target="#b22">[16]</ref>, <ref type="bibr" target="#b207">[201]</ref>. Pyramid proposes a hierarchical architecture for edge-cloud synergetic GNNs that trains a local, small model on edge servers with its collected data and a global model on a cloud server to capture inter-region spatio-temporal relationships. During the runtime, Pyramid <ref type="bibr" target="#b208">[202]</ref> allows GI-based predictions with either the local model or the global model in an on-demand fashion and achieves lower inference latency against baselines. Branchy-GNN is a Level-3 EGI system since it only tackles GNN inference at the edge, while Pyramid rates Level-4 because of its joint training and inference designs.</p><p>2) Multi-Edge Collaboration: Multi-edge collaboration <ref type="bibr" target="#b209">[203]</ref>- <ref type="bibr" target="#b211">[205]</ref> provisions all data flow within the edge networks, where edge devices individually perform local computation on the local data they possess and collectively train or infer GI models by sharing information and merging the results.</p><p>On the one hand, compared to the cloud-assisted solutions, multi-edge collaboration fully reserves data without leaking them to the remote datacenter, thus avoiding users' privacy concerns from cloud providers <ref type="bibr" target="#b97">[91]</ref>, <ref type="bibr" target="#b212">[206]</ref>, <ref type="bibr" target="#b213">[207]</ref>. On the other hand, collaborating multiple edge devices augments the available resources for targeted GI tasks beyond a single edge device, which therefore enables superior performance against on-device computation <ref type="bibr" target="#b94">[88]</ref>, <ref type="bibr" target="#b214">[208]</ref>. Besides, privacy requirements are also guaranteed if the participating edge devices are mutually trusted, which can be relevant for many edge scenarios, e.g., in a smart home with edge devices owned by the same user and in a manufacturing pipeline with cameras and sensors possessed by the same company <ref type="bibr" target="#b177">[171]</ref>, <ref type="bibr" target="#b215">[209]</ref>.</p><p>Under this paradigm, Fograph <ref type="bibr" target="#b216">[210]</ref>, <ref type="bibr" target="#b217">[211]</ref> proposes a distributed GNN inference system that leverages multiple edge servers in proximity to IoT data sources for real-time GI model serving. To address resource heterogeneity and dynamics among edge servers, Fograph designs a load-aware inference execution planner as well as an agile workload scheduler for maximum parallelization. It also introduces a degree-aware compression mechanism to minimize data transmission overhead. Following this principle, GLAD <ref type="bibr" target="#b218">[212]</ref> studies the cost optimization problem for distributed GNN serving in multitier edge networks. By formulating cost factors in the whole lifecycle of edge-enabled GI services, it separately considers static graphs and dynamics graphs and derives a holistic graph layout scheduling solution with theoretical performance guarantees. Both Fograph and GLAD are Level-4 systems for their functionality of GNN inference at the edge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. On-Device Computation</head><p>On-device computation for GI models refers to performing GI model computations directly on edge devices rather than relying on cloud or remote servers. This entails executing the training or inference tasks locally on edge devices such as smartphones, laptops, or tablets, without requiring a constant internet connection or external server support. This paradigm is particularly useful for privacy-sensitive applications because it ensures users' data to be fully preserved in situ. Nonetheless, given the intensive workload of computing GI models, on-device edge computation of them is non-trivial, and researchers have developed several routines to tackle that by designing resource-friendly procedures and models or compression for compact GI models.</p><p>1) Resource-Efficient Procedure: Without modifying GI models, resource-efficient procedure design indicates the endeavors that develop GI processing flows in minimal resource usage, e.g., memory footprint. For instance, centering on the out-of-memory issues where GI models' sizes are too large to fit into edge devices' memory, Zhou et al. <ref type="bibr" target="#b219">[213]</ref> (Level-3 rating) design a feature decomposition approach that decomposes the dimension of feature vectors and performs aggregation respectively, reducing up to 5× memory footprint against generic GI frameworks. Building on the theme of memory efficiency, SUGAR <ref type="bibr" target="#b109">[103]</ref> (Level-4 rating) targets resourceefficient training on resource-constrained edge devices through a subgraph-level training scheme that first partitions the initial graph into a set of disjoint subgraphs and then performs local training for individual subgraphs. Complementing these approaches, RAIN <ref type="bibr" target="#b220">[214]</ref> (Level-3 rating) explores the opportunity of conservatively processing similar inference batches based on local sensitive hash and reusing repeated vertices' data among successive batches to reduce redundant data loading.</p><p>There are also some works that utilize channel pruning methods to reduce input feature dimensions for GI model inference acceleration. Zhou et al. <ref type="bibr" target="#b221">[215]</ref> set the stage by employing a LASSO regression-based pruning technique, which identifies the most influential feature channels, thus ensuring that the pruning process is both effective and minimally disruptive to the model's accuracy. Yik et al. <ref type="bibr" target="#b222">[216]</ref> extend this line of inquiry by conducting a meticulous analysis of the trade-offs inherent in channel pruning. They develop algorithms that not only preserve the model's predictive prowess but also enhance computational efficiency, aligning seamlessly with the work <ref type="bibr" target="#b221">[215]</ref> by further honing in on the most valuable features.</p><p>2) Resource-Efficient Model: Designing resource-efficient GI models usually involves simplifying operators in GI semantics to improve computational efficiency in both GI model training and inference. Recent advances in this routine have explored eliminating redundant operators like linear aggregation and non-linear activation. For instance, SGC <ref type="bibr" target="#b223">[217]</ref> removes the non-linear ReLU operators in conventional GI models to reduce the model complexity and reserves only the final Softmax function for probabilistic output generation, which significantly accelerates the model training yet maintains comparable accuracy in many generic tasks like text and graph classification. Other examples include LightGCN <ref type="bibr" target="#b224">[218]</ref> and UltraGCN <ref type="bibr" target="#b225">[219]</ref> for location-based social recommendation tasks, where the former drops the feature transformation and non-linear activation and the latter modifies the message-pass process into a simplified approximate embedding method. As a result, both of them effectively decrease the computational load against baselines and attain remarkable speedup.</p><p>To automate the resource-efficient model design for edge platforms, some researchers <ref type="bibr" target="#b110">[104]</ref>, <ref type="bibr" target="#b226">[220]</ref>, <ref type="bibr" target="#b227">[221]</ref> introduce NAS techniques to the GI domain and present hardware-aware NAS frameworks tailored to GNNs, aiming to strike a balance between model accuracy and efficiency corresponding to the characteristics of targeted devices. Zhou et al. <ref type="bibr" target="#b110">[104]</ref> present HGNAS, a hardware-aware graph neural architecture search (GNAS) framework that optimizes GNN designs for edge devices by balancing accuracy and efficiency using a hardware performance predictor. Similarly, PaSca <ref type="bibr" target="#b226">[220]</ref> constructs scalable GNNs through a novel scalable GNAS paradigm, enabling systematic exploration of a vast design space to optimize GNNs for both accuracy and efficiency via multi-objective optimization. Building upon these concepts, MaGNAS <ref type="bibr" target="#b227">[221]</ref> is a mapping-aware GNAS framework that efficiently processes vision-based GNN workloads on heterogeneous multiprocessor platforms by identifying optimal GNN architectures and mappings for maximized resource efficiency and performance trade-offs. Together, these works highlight the growing trend towards hardware-aware and scalable GNAS frameworks that address both the accuracy and efficiency requirements crucial for deploying GNNs on edge devices. This line of work represents Level-4 EGI systems since they enable both edge training and inference.</p><p>3) Model Compression: Compressing a complete model into a smaller one that appropriately fits the capability of the targeted edge device has been a popular deployment means for many edge intelligence services. The smaller model, which usually with fewer parameters, allows much less computing cost and thus significant acceleration for on-device computation. To obtain such a lightweight model for EGI, researchers typically employ three ways, i.e., model quantization, knowledge distillation, and neural architecture search.</p><p>Model quantization intends to quantize GI model parameters from an origin, larger bitwidth to a targeted, smaller bitwidth, and thus reduce the total size of the model. In this context, SGQuant <ref type="bibr" target="#b228">[222]</ref> proposes a multi-granularity method that can quantize feature vectors at the component level, topology level, and layer level to meet diverse data precision demands. It also designs an automatic bitwidth-selecting algorithm to attain proper configuration among different quantization granularities. Building upon the quantization paradigm, Degree-Quant <ref type="bibr" target="#b229">[223]</ref> pioneers a quantization-aware training scheme specifically crafted for GI models. This scheme is designed to facilitate low-precision inference on devices with constrained resources, without compromising the model's predictive capabilities. VQ-GNN <ref type="bibr" target="#b230">[224]</ref> takes a quantum leap in this domain by introducing a unified framework that applies vector quantization (VQ) for dimensionality reduction and learns a small number of quantized reference vectors of global node representations, which viably avoids the "neighbor explosion" problem and enables faster mini-batch training and inference of GI models. Following this quantization principle, some researchers go one step further with GI model binarization, i.e., binarizing parameters in GI models for aggressive execution speedup <ref type="bibr" target="#b231">[225]</ref>.</p><p>Knowledge Distillation (KD) aims at extracting knowledge from a complex teacher model and transferring it into a compact student model while maintaining comparable performance <ref type="bibr" target="#b232">[226]</ref>, <ref type="bibr" target="#b233">[227]</ref>, as depicted in Fig. <ref type="figure" target="#fig_6">13</ref> While KD is originally applied in the computer vision domain <ref type="bibr" target="#b234">[228]</ref>- <ref type="bibr" target="#b236">[230]</ref>, Yang et al. <ref type="bibr" target="#b237">[231]</ref> first introduce KD for GI models along with a local structure preserving method for teacher-student similarity measurement and experimentally show its effectiveness in GIbased 3D object detection tasks. Along with this line, Yang et al. <ref type="bibr" target="#b238">[232]</ref> combine parameterized label propagation and feature-based MLP in the KD's student model, allowing better utilization of the knowledge from both the teacher model and prior basement. TinyGNN <ref type="bibr" target="#b239">[233]</ref> focuses the KD principle on accelerating model inference and designs a peer-aware module and a neighbor distillation strategy for preserving model accuracy. They all focus on the edge inference aspect and are Level-3 EGI systems in the rating taxonomy. Lessons Learned (Sec. VI) Edge networks as a physical infrastructure can support GI in various architectures, including FGL with edge-cloud synergy, collaborative computing with distributed edge platforms, and in-situ computing on individual edge devices. The architecture used for EGI services depends on the demand of SLO (e.g., latency and privacy requirements) and the availability of the cloud. The lower reliance on the cloud the system has, the more stringent the constraint of computing resources, and thus the more attention is paid to resource-efficient optimizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. GRAPH INTELLIGENCE FOR EDGE NETWORKS</head><p>Besides directly using GI models to specific edge applications discussed in Sec. V, GI techniques are also employed for optimizing edge networks. This can be relevant since many components in edge networks, e.g., network hierarchy as illustrated in Fig. <ref type="figure">7</ref>(e), can be naturally recognized in graphs. Towards that, we discuss GI-based optimization on edge networks with respect to their resource management, graph-based decision-making, security issues, and GI-assisted FL in the following. Using GI for optimizing edge not only involves GI model inference at the edge but also training tailored GI at targeted edge platforms, thus their EGI systems are at Level 4 in the rating taxonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Network Resource Management</head><p>Given the graph structure of massively connected edge networks, GI models are deemed to be a useful tool to achieve that and are leveraged for optimizing network resource allocation and network function orchestration.</p><p>1) Resource Allocation: Resource allocation is critical for ensuring networking efficiency and robustness, and has been extensively studied using traditional optimization means. Instead of applying complicated formulation and optimization, GI-based methods model the whole network as a graph and schedule an allocation strategy in a holistic manner <ref type="bibr" target="#b240">[234]</ref>- <ref type="bibr" target="#b242">[236]</ref>.</p><p>Power control in wireless networks seeks the optimal power allocation to transmitters to minimize power consumption while maintaining signal quality <ref type="bibr" target="#b243">[237]</ref>, <ref type="bibr" target="#b244">[238]</ref>. Shen et al. <ref type="bibr" target="#b245">[239]</ref> introduce an interference GCN to solve the power control problem in wireless networks, designed to model K-user interference channels as complete graphs and incorporate wireless channel data as graph features for scalability. Their approach is complemented by Eisen et al. <ref type="bibr" target="#b246">[240]</ref>, <ref type="bibr" target="#b247">[241]</ref>, who employed spectral-based GCNs for power allocation in Device-to-Device (D2D) wireless networks, highlighting the effectiveness of GCNs in managing interference. Salaün <ref type="bibr" target="#b248">[242]</ref> study cell-free MIMO networks and formulate a graph of the dominant dependence relationship between access points and user equipment, using GNN for scheduling the power control. Building on these ideas, Nikoloska et al. <ref type="bibr" target="#b249">[243]</ref> utilized REGNN to tackle power control challenges in decentralized wireless networks, leveraging the adaptability of GNNs to changing network topologies. Similarly, Yang et al. <ref type="bibr" target="#b250">[244]</ref> propose UWGNN, which enhances GNNs by unrolling modules in the weighted minimum mean-square error algorithm into GI frameworks, demonstrating a method to integrate knowledge more effectively. Together, these studies underscore the versatility of GNNs in addressing power control problems across various wireless network settings, from centralized to decentralized architectures, and from static to dynamic topologies.</p><p>Link and channel scheduling is another key issue in communication networks as it drastically impacts the overall performance of the system (throughput, delay, etc.) <ref type="bibr" target="#b244">[238]</ref>. Some researchers apply GNN or combine GNN with other models for channel tracking and throughput optimization in MIMO networks, where the channel states and links are formulated in graphs <ref type="bibr" target="#b248">[242]</ref>, <ref type="bibr" target="#b251">[245]</ref>- <ref type="bibr" target="#b253">[247]</ref>. Yang et al. <ref type="bibr" target="#b251">[245]</ref> intend to represent the obtained channel data in graphs by associating channel correlations as links' weights, based on which a GNN model is trained for channel tracking. D2D networks are also studied in a similar vein, e.g., GCN-GAN <ref type="bibr" target="#b254">[248]</ref> integrates the strengths of GCN, LSTM, and GAN to capture the dynamics, topology, and evolutionary patterns of weighted dynamic networks for temporal link prediction. These methods collectively leverage graph-based models to enhance link scheduling and prediction, demonstrating the versatility and effectiveness of graph neural networks in addressing various aspects of network performance optimization.</p><p>Beamforming techniques are regarded as promising solutions in multi-user, multi-antenna communication systems <ref type="bibr" target="#b255">[249]</ref>, and also play a crucial role in wireless resource management. Chen et al. <ref type="bibr" target="#b256">[250]</ref> present an innovative unsupervised GNN approach for beamforming design in D2D wireless networks. Their method significantly reduces the problem dimension by transforming beamforming into primal power and dual variables, showcasing superior performance with fewer samples. Further extending the application of GNNs, Kim et al. <ref type="bibr" target="#b257">[251]</ref> develop a bipartite graph neural network framework for multi-antenna beamforming optimization in multi-user MISO systems. This approach partitions the beamforming optimization into suboperations for individual antennas and users, allowing for scalable and efficient computations. Both studies leverage the flexibility and efficiency of GNNs to handle complex beamforming tasks, demonstrating the potential of graph-based methods in optimizing wireless communication systems.</p><p>2) Network Function Orchestration: Virtual Network Function (VNF) virtualizes the functions that traditionally run on dedicated hardware devices such as routers and firewalls and has become a key enabler in software-defined networks (SDNs) <ref type="bibr" target="#b258">[252]</ref>. Researchers employ GI models on VNF for orchestrating various tasks including adaptive Service Function Chain (SFC) and network slicing. SFC, crucial for identifying efficient paths in network servers for processing requested VNFs, faces challenges in maintaining high QoS in complex scenarios.</p><p>Heo et al. <ref type="bibr" target="#b259">[253]</ref> introduce a GAE for dynamic network topologies, where the encoder represents the network topology and the decoder evaluates nodes for processing VNFs, adapting to topology changes. Heo et al.'s subsequent work <ref type="bibr" target="#b260">[254]</ref> overcomes the limitation of earlier approaches restricted to fixed topologies, by employing RL for GNN-based model training across various unlabeled network topologies. Pioneering studies on network slicing <ref type="bibr" target="#b261">[255]</ref>, <ref type="bibr" target="#b262">[256]</ref> employ Digital Twin (DT) technology to digitally replicate slicing-enabled networks, creating detailed virtual models that mirror the physical network's characteristics. These models are then used to develop GNNs that learn and optimize network behaviors directly from these non-Euclidean graph representations, thereby addressing challenges in resource allocation and QoS management in highly dynamic network environments. Besides the above aspects, we refer readers interested more about GNN for communications to related discussions <ref type="bibr" target="#b37">[31]</ref>, <ref type="bibr" target="#b263">[257]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph-Based Decision Making</head><p>Given the powerful ability to abstract graphs, GI models can be integrated with DRL techniques to enable decisionmaking on graphs. Their confluence leads to DGRL, which is extensively utilized for scheduling decisions on edge networks, e.g., offloading, routing, and wireless network control. In general, the DGRL framework can be illustrated in Fig. <ref type="figure" target="#fig_7">14</ref>, where an agent observes the state, schedules configurations, and feeds the agent (neural network) back with a reward after each action. The GI model is incorporated as a graph information encoder to abstract relational semantics from the state.</p><p>1) Offloading and Routing: Offloading and routing are classic techniques in edge networks that allow workload migration across networking entities and some researchers <ref type="bibr" target="#b107">[101]</ref>, <ref type="bibr" target="#b108">[102]</ref>, <ref type="bibr" target="#b264">[258]</ref> use graphs to abstract tasks to be scheduled for offloading decisions. Specifically, ACED <ref type="bibr" target="#b107">[101]</ref> introduces an actor-critic mechanism for DAGs-based computation offloading decisions considering task dependencies and wireless interference. Swaminathan et al. <ref type="bibr" target="#b108">[102]</ref> enhance a routing algorithm for SDN using a GNN functioning with a deep Q-Network. Trained to forecast efficient routing paths, this GI model minimizes packet delivery delays through simultaneous training and inference, enabling continuous learning and realtime adaptation. 2) Wireless-Enabled Control Systems: DRL techniques have been frequently used in attaining efficient control of communication resources in wireless networks. However, trivially applying DRL does not scale well with the network size, and GI models are thus employed to overcome this challenge. For example, Nakashima et al. <ref type="bibr" target="#b265">[259]</ref> design a DGRL method for scalable, model-free resource allocation in large-scale wireless control systems. It capitalizes on the ability of GNNs to apply spatial-temporal convolutions to graph-structured data, harnessing the natural graph form of wireless networks for efficient policy design. Some of its follow-up works <ref type="bibr" target="#b266">[260]</ref>, <ref type="bibr" target="#b267">[261]</ref> extend this approach by incorporating long-term constraints and demonstrate the permutation invariance and transferability of graph-based reinforcement learning policies in wireless control systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Security and Anomaly Detection</head><p>Detecting anomalies in a graph is an important task in the analysis of complex systems, especially for ubiquitous edge networks. The anomalies, in the context of graphs, are patterns that fail to conform to normal patterns expected of the graph's attributes or structures. In this respect, the community has developed GI models for anomaly detection tasks and applied them to optimize edge networks. Fig. <ref type="figure" target="#fig_8">15</ref> illustrates its rationale, where vertices (with features) can be transformed into embeddings, which are used for anomaly identification in a latent space.</p><p>1) Static Network: For edge networks that are static within a period, e.g., a smart home network in a short slot, we call it a static network. Extensive research has been conducted focusing on the detection of anomalies within static graphs, encompassing various categories including vertex, link, and graph-level anomalies <ref type="bibr" target="#b268">[262]</ref>. AnomMAN <ref type="bibr" target="#b269">[263]</ref> incorporates a graph auto-encoder module to leverage the low-pass filtering characteristic of graph convolution, typically a disadvantage for anomaly detection, transforming it into a beneficial feature by utilizing reconstruction errors to effectively identify anomalies. EFraudCom <ref type="bibr" target="#b270">[264]</ref> proposes a fraud detection system employing GI to identify anomalous edges in e-commerce platforms. The system's core innovation lies in modeling the distributions of normal and fraudulent behaviors separately, enhancing robustness against evolving fraud patterns. GLocalKD <ref type="bibr" target="#b271">[265]</ref> and OCGTL <ref type="bibr" target="#b272">[266]</ref> both tackle graph-level anomaly detection. The former introduces a method using random distillation of graph and node representations for deep anomaly detection, and the latter employs self-supervised and transformation learning to enhance existing deep one-class approaches <ref type="bibr" target="#b273">[267]</ref>.</p><p>2) Dynamic Network: Dynamic edge networks take temporality into consideration where their topology and attributes may change over time <ref type="bibr" target="#b274">[268]</ref>. Recent studies, such as those by Deng et al. <ref type="bibr" target="#b275">[269]</ref> and Zhang et al. <ref type="bibr" target="#b276">[270]</ref>, have delved into the intricacies of multivariate time series anomaly detection within cyber-physical systems. Both of them underscore the significance of understanding the complex interplay between sensors over time. <ref type="bibr">Deng et al. [269]</ref> propose an attention-based graph deviation network to learn the complex relationships between sensors in multivariate time series, not only accurately detecting anomalies but also providing an explainable model that identifies and clarifies deviations from normal sensor interactions. Similarly, Zhang et al. <ref type="bibr" target="#b276">[270]</ref> focus on sensor dependence relationships in cyber-physical systems, utilizing a VAE for feature extraction and a GNN with stochastic learning to capture inter-sensor dependencies. Building upon these methodologies, FuSAGNet <ref type="bibr" target="#b277">[271]</ref> combines Sparse Autoencoder with GNN for anomaly detection in high-dimensional time series, which optimizes both reconstruction and forecasting while explicitly modeling the relationships within multivariate time series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. GI-Assisted Federated Learning</head><p>In certain FL scenarios, clients exhibit relational dependencies, a structural representation of which can be established through a graph. For instance, traffic sensors in physical proximity often result appear in similar traffic patterns. In this case, a cross-client graph can be established by identifying them as respective vertices. The presence of this cross-client graph prompts the utilization of GI algorithms to enhance the FL training process, resulting in the paradigm of GI-assisted FL (GFL), as shown in Fig. <ref type="figure" target="#fig_10">16</ref>. As we have discussed in Sec. VI-A, GFL and FGL are different mechanisms, where the former applies GI techniques to optimize FL on arbitrary ML models (which do not necessarily be GI models) and the latter applies FL to jointly train GI models. In other words, GI models are optimization tools in GFL, whereas they are the targeted models to be trained in FGL. Due to such distinct functionality, we categorize GFL into the GIbased optimization for edge networks and discuss it in this subsection, while FGL will be introduced in the context of edge computation of GI models in Sec. VI-A.</p><p>GFL works upon the premise that clients closely connected in the graph likely share similar data distributions. Based on that, GNNs can utilize the graph structure inherent in the FL system to tackle the non-IID data heterogeneity among clients. With respect to the utilization of centralized servers, we discuss GFL in the centralized setting and the decentralized setting, respectively.</p><p>1) Centralized Federated Learning: Under the centralized setting for GFL, a centralized server is employed to coordinate FL among clients, as depicted in Fig. <ref type="figure" target="#fig_10">16(a</ref>). The GI model, which is applied for optimizing the FL procedure based on cross-client graphs, can be executed either on the server or the clients.</p><p>For the case of server-side GI execution, a GI model undergoes training on the server using graph relationships between clients, operating under the assumption that proximate clients exhibit similarities in their local models or feature embeddings. Initially, the server initiates the collection of parameters from clients, following a standard FL protocol. These uploaded parameters collected from client models are construed as node features within the context of the cross-client graph, using which the server trains a GI model to facilitate the aggregation process in FL. Note that the specification of the cross-client graph may either be predefined or dynamically extracted through the application of a self-attention module during the training phase <ref type="bibr" target="#b278">[272]</ref>. The resultant updated parameters are then transmitted back to the respective clients.</p><p>In this process, researchers have proposed different routines to tackle different issues in training the coordinated GI model. For instance, some researchers focus on the convergence speed of GI models under non-IID circumstances, designing bilevel optimization to train both the client models and the server-side GI model simultaneously, e.g., using unsupervised contrastive learning <ref type="bibr" target="#b279">[273]</ref> or regularization-aided supervised learning methods <ref type="bibr" target="#b280">[274]</ref>. Others ponder the specific functionality of the GI models and develop training strategies in various aspects <ref type="bibr" target="#b281">[275]</ref>, <ref type="bibr" target="#b282">[276]</ref>.</p><p>For the case of client-side GI execution, each client is assumed to possess a global cross-client graph and trains not only its local model but a GI model to obtain global knowledge from other clients. Building different graphs within the clients can be employed to address various problem-solving objectives like data heterogeneity and model heterogeneity. For instance, FedCG <ref type="bibr" target="#b283">[277]</ref>   Weight summation methods update clients' local models by aggregating their neighbors' local model parameters following the global cross-client graph topology. Under this principle, DSGT <ref type="bibr" target="#b284">[278]</ref> employs decentralized stochastic gradient tracking to achieve faster convergence, and PSO-GFML <ref type="bibr" target="#b285">[279]</ref> selectively exchanging local model parameters with the servers to improve communication efficiency. The weights of the cross-client graph's links are determined based on the similarity between unlabeled graph embeddings <ref type="bibr" target="#b286">[280]</ref> or hidden parameters <ref type="bibr" target="#b287">[281]</ref>.</p><p>Graph regularization integrates graph Laplacian regularization into the objective function to transform model parameters from neighboring clients <ref type="bibr" target="#b288">[282]</ref> and is particularly beneficial to multi-task GFL. In dFedU <ref type="bibr" target="#b289">[283]</ref>, a pre-defined fully connected cross-client graph is given ahead where each client is assigned a single task. When receiving local updated models from neighboring clients, each client conducts model updating with graph regularization. He et al. <ref type="bibr" target="#b290">[284]</ref> alternatively posit that each client runs multiple tasks and initializes a cross-client task relationship graph with task classifier parameters, where decentralized periodic averaging SGD is employed to optimize the objective function.</p><p>Lessons Learned (Sec. VII) GI can serve as an optimization tool for enhancing different functionalities of edge networks, including network resource management, graph-based decisionmaking, security and anomaly detection, and GFL. To well harness GI in these cases, there are dual knobs: on the one hand, the system needs to concisely identify the optimization constraints and objectives from graph perspectives, where one or more graph(s) should be built to represent the structure of the targeted problem; on the other hand, the graph may associate appropriate (encoded) properties that supply sufficient information and convert optimization objectives into learning objectives, such that GI models can use these graph semantics to induce expected output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. EDGE GRAPH INTELLIGENCE ECOSYSTEMS</head><p>After reviewing the interaction between GI and edge networks in Sec. VI and Sec. VII, we discuss the EGI ecosystem inflated from this loop. Fig. <ref type="figure" target="#fig_11">17</ref> shows the landscape of the EGI ecosystem from levels of hardware, software, benchmark, and applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Edge Hardware for EGI</head><p>Edge networks cover a wide spectrum of edge platforms from embedded and mobile devices to vehicles and edge servers, as discussed in Sec. III-B2. At the core of these edge facilities, different processors deliver different capabilities and require different optimizations for GI model computation. In general, they can be discussed in three types, mobile CPUs and GPUs, Field Programmable Gate Array (FPGA), and Domain-Specific Accelerators (DSAs).</p><p>1) CPU and GPU: A majority of edge facilities, especially wearable and mobile devices, are equipped only with conventional CPUs and GPUs such as Qualcomm SnapDragon series and Huawei Kirin series. Given the intensive workload of GI-driven applications, efficient execution of them requires meticulously exploiting the capability of low-power processors. To better understand the characteristics of GI models on conventional platforms, Huang et al. <ref type="bibr" target="#b291">[285]</ref> examine in detail representative GI systems and reveal five major gaps in optimizing GI computation performance, i.e, poor data locality, severe workload imbalance, redundant memory access, large memory footprint, and inefficiency on variant feature lengths. Based on these observations, Huang et al. <ref type="bibr" target="#b291">[285]</ref> propose a set of tailored optimizations to bridge the gaps and achieve 1.37×-15.5× performance improvement on various GI models. Towards the same objective, Zhang et al. <ref type="bibr" target="#b292">[286]</ref> study the GI execution performance on commercial platforms from the perspective of computational graph and summarize three issues that existing systems suffer, namely redundant neural operator computation, inconsistent thread mapping, and excessive intermediate data. To tackle these challenges, Zhang et al. <ref type="bibr" target="#b292">[286]</ref> introduce three corresponding designs, i.e., propagation-postponed operator reorganization, unified thread mapping for fusion, and intermediate data  recomputation, achieving notable speedup in lower memory IO and footprint.</p><p>These empirical studies motivate literature <ref type="bibr" target="#b293">[287]</ref>- <ref type="bibr" target="#b297">[291]</ref> in efficiently leveraging the potential of conventional CPUs and GPUs. For instance, Adiletta et al. <ref type="bibr" target="#b298">[292]</ref> study a detailed characterization of GI models on Intel's Programmable Integrated Unified Memory Architecture (PIUMA) for scalable training. Graphite <ref type="bibr" target="#b294">[288]</ref> addresses GI model training on CPUs by eliminating the memory limitation through software-hardware co-design including layer fusion, feature compression, and a vertex processing reordering algorithm for improving temporal locality, and implements a high-performance GI computation system on Intel CPUs. Some works explore optimizing matrix computation in GI tasks from the kernel level. FeatGraph <ref type="bibr" target="#b299">[293]</ref> provides efficient implementations of Sampled Dense-Dense Matrix Multiplication (SDDMM) and Sparse-dense Matrix Multiplication (SpMM) for both CPUs and GPUs, and FusedMM <ref type="bibr" target="#b293">[287]</ref> further develops a general solution for different GI programming backends. There are also many comprehensive systems developed to tackle the various aspects of GI training and inference for distributed training on CPU or GPU clusters (e.g., Dorylus <ref type="bibr" target="#b296">[290]</ref>, FlexGraph <ref type="bibr" target="#b297">[291]</ref>). However, most of them rely on the computation infrastructure at datacenter levels and are thus out of the scope of this survey. Interested readers may refer to recent reviews <ref type="bibr" target="#b300">[294]</ref>, <ref type="bibr" target="#b301">[295]</ref> on large-scale distributed GI systems.</p><p>2) Field-Programmable Gate Array: FPGA is a type of integrated circuit with a differentiated ability to be (re)programmed to desired functionality requirements after manufacturing. This advanced ability allows FPGA to be used in applications with requirements on flexibility, speed, and parallelism, and thus are embedded and employed in edge platforms for GI workload processing. HP-GNN <ref type="bibr" target="#b302">[296]</ref> generates high-throughput GNN training implementations on a given CPU-FPGA platform by designing an automatic algorithm that maps GI training algorithms, GI models, and hardware specifics to the targeted CPU-FPGA platform. GenGNN <ref type="bibr" target="#b303">[297]</ref> develops a generic GI model acceleration framework using High-Level Synthesis (HLS) techniques, aiming to render GI inference in low latency and support various GI models in flexible extensibility. It embraces an optimized messagepassing structure to accommodate the majority of popular GI models and provides a rich library of model-specific components. GraphAGILE <ref type="bibr" target="#b304">[298]</ref> designs a hardware module named adaptive computation kernel for efficient execution of GI matrix operations such as sparse-dense matrix multiplication and sampled dense-dense matrix multiplication, and proposes a set of compiler optimizations to reduce inference latency. Graph-OPU <ref type="bibr" target="#b305">[299]</ref> proposes an FPGA-based overlay processor for accelerating GI execution, which introduces microarchitecture for fully-pipelined GI processing and customizes the instruction sets for various GI model adoptions.</p><p>Besides optimizing FPGA solutions for general GI model execution, some researchers further study how to utilize FGPA-integrated platforms for specific applications efficiently. For example, Heintz et al. <ref type="bibr" target="#b306">[300]</ref> develop an FPGA implementation for charged particle tracking based on GI models, incorporating OpenCL and hls4ml in an interaction network architecture. Zhang et al. <ref type="bibr" target="#b307">[301]</ref> consider synthetic aperture radar-assisted remote-sensing image recognition tasks and design an FPGA acceleration solution with customized data path and memory organization for various GI model kernels. To further speed up GI inference, it exploits FPGA's high bandwidth memory for loading data and storing intermediate results, as well as a splitting kernel technique to improve the on-chip routability and frequency. Huang et al. <ref type="bibr" target="#b308">[302]</ref> specify an FPGA-based parallel particle tracking system with memory-aware data allocation and buffer arrays and collisionaware scheduling on parallel events.</p><p>3) Domain-Specific Accelerator: Domain-Specific Accelerators (DSAs) are important computing components and becoming more pervasive in many edge facilities such as dedicated edge servers and some mobile devices <ref type="bibr" target="#b309">[303]</ref>- <ref type="bibr">[306]</ref>. By optimizing specifically for a narrow range of computations, DSAs are tailored to meet the needs of targeted algorithms in dedicated domains and enable orders of magnitude improvements in performance or cost compared to general-purpose processors. Motivated by the achieved success of DSAs in CNNs, the community has made plentiful efforts in developing DSAs for GI workload. Towards that, EnGN [307] presents a unified architecture inspired by CNN accelerators, where GI computations are viewed in a matrix perspective and matrix multiplication optimizations are applied for improved runtime performance. Auten et al. <ref type="bibr" target="#b314">[308]</ref> propose a modular DSA architecture for convolutional GNNs, where each tile as a basic unit is composed of an aggregation module, a DNN accelerator module, a DNN queue, and a graph processing element.</p><p>Nonetheless, GNNs are semantically different from traditional DNNs (c.f. Sec. III-A), bringing new computing characteristics desired for tailored designs. To better understand such computing characteristics, Yan et al. <ref type="bibr" target="#b315">[309]</ref> and Lin et al. <ref type="bibr" target="#b316">[310]</ref> respectively conduct detailed profiling of general GNN workload and distributed GNN training workload on GPUs, providing useful insight on GNN-oriented DSA design. Based on that, HyGCN <ref type="bibr" target="#b317">[311]</ref> introduces a hybrid architecture to tame the alternating phases of GI computation, which is composed of separate dedicated engines for the aggregate and update functions as well as a control scheme to pipeline the execution of both functions. GRIP <ref type="bibr" target="#b318">[312]</ref> leverages the programming abstraction of GReTA <ref type="bibr" target="#b319">[313]</ref> to develop a general DSA for GNNs, which organizes a GI model inference into four steps, i.e., gather, reduce, transform, and activate. Regarding this abstraction, GRIP specializes in the processing units for links and vertices separately and designs a control module to coordinate data movement between units and buffers. AWB-GCN <ref type="bibr" target="#b320">[314]</ref> raises an aggressive adaptation to the structural sparsity of GI models under the motivation that for power-law graphs, GI computation can be polarly dense or sparse and suffers from workload imbalance. To address this imbalance, AWB-GCN <ref type="bibr" target="#b320">[314]</ref> develops a custom matrix multiplication engine with autotuning workload balancing techniques, and GNNIE <ref type="bibr" target="#b321">[315]</ref> advocates a flexible MAC architecture that splits features into blocks with load (re)distribution and graph-specific caching to bypass the high costs of random DRAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Developmemt Frameworks</head><p>GI models' unique computing workflow introduces different programming patterns from traditional DL models (e.g., CNNs and RNNs), which requires dedicated frameworks for implementation. Towards that, the community has developed various programming frameworks compatible with edge computing platforms. Among them, PyTorch Geometric (PyG) <ref type="bibr" target="#b322">[316]</ref> and Deep Graph Library (DGL) <ref type="bibr" target="#b323">[317]</ref> are the two most popular ones and are widely used in various applications.</p><p>PyG is a geometric deep learning extension library built upon PyTorch that provides flexible interfaces for programming GI models on both CPUs and GPUs. It adopts a message-passing programming abstraction for building GI models, which is programmer-friendly to express various GI variants. DGL is another general framework specialized for deep learning models on graphs. It also leverages the message-passing primitives in a user-configurable way and introduces a set of parallelization strategies for high-performance GNN execution. Both PyG and DGL can be used in edge devices and edge servers as long as they enable the PyTorch library in their execution environments. In addition, DGL also supports TensorFlow and MXNet, and edge platforms that run these two frameworks also allow model execution with DGL. Besides PyG and DGL, the industry has also developed many frameworks upon their customized demand, such as AGL <ref type="bibr" target="#b324">[318]</ref>, BGL <ref type="bibr" target="#b325">[319]</ref>, TF-GNN <ref type="bibr" target="#b326">[320]</ref>, and Angel-Graph, etc. Nonetheless, most of them are dedicated to cloud-level resources without consideration of the deployment on edge networks and thus require tailored adjustments when building edge GI services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Open Datasets</head><p>To assess how well edge GI systems perform and learn their behaviors upon deployment, versatile datasets are collected from diverse edge scenarios, serving as performance benchmarks. Table III lists some representative datasets in several application domains discussed in Sec. V.</p><p>The first dataset series lies on smart cities, including data collected from intelligent transportation systems, meteorological stations, power grids, and governments. Their graphs are mostly derived from the geographical network relations in cities, e.g., road nets, power networks, and regional adjacencies. The second domain is intelligent robotics and vehicles, taking datasets from various robot manipulation scenarios such as UAV swarms and vehicle trajectories The third category is for human sensing applications, including human action recognition, facial affective analysis, and sleep quality prediction. Specifically, for the sleep quality dataset, researchers construct sleep stage graphs with electronic channel records and employ GI models for prediction. The fourth domain is location-based social recommendation, where social networks are naturally graphs and the location information of users puts its analysis into the context of edge networks. The last group focuses on mobile vision, where the datasets are also widely utilized in many computer vision models. Readers are encouraged to exact their interested datasets from the links to learn more about their sources and applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lessons Learned (Sec. VIII)</head><p>The promising fusion of EGI facilitates the EGI ecosystem in a full-stack manner. Specifically, the ecosystem provides an abundant set of facilities covering hardware, software, and testing benchmarks, acting as a stage for developing and deploying EGI services. Developers are suggested to develop their EGI services agilely with well-established open-sourced toolkits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. OPEN CHALLENGES AND FUTURE RESEARCH OPPORTUNITIES</head><p>The confluence of GI and edge networks is still in its infancy stage and many of the considered parts of the EGI landscape are yet under exploration. In this section, we articulate key open challenges and future research directions for EGI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. New Promising Applications and Optimizations</head><p>The integration of GI and edge networks opens up new possibilities for low-latency, context-aware analysis, and decisionmaking, holding great potential for miscellaneous promising applications. Given the ubiquitous nature of graph data, there are still many areas to be explored for service providers, network operators, and end users with optimization opportunities as well as business revenues.</p><p>1) New EGI Applications: Besides applications discussed in Sec. V, there are still many burgeoning edge scenarios well matching EGI's capability. For instance, in digital twin networks, the mapping between physical objects and digital twins can be regarded as graphs and EGI may be applied for task offloading, power allocation, and network slicing <ref type="bibr" target="#b261">[255]</ref>,</p><p>[349], <ref type="bibr" target="#b354">[350]</ref>. Satellite-aerial-ground intergaetd networks are also one of the emerging edge networks <ref type="bibr" target="#b355">[351]</ref>- <ref type="bibr" target="#b357">[353]</ref>, where high-altitude platform stations and ground stations constitute vertices with their communication channels as links. EGI thus can also be used for them.</p><p>2) B5G and 6G Protocols Design: Communication in edge networks, particularly for cross-device services, often involves complex interactions that can be naturally represented as graphs. The networking topology, defined by communication nodes, forms the vertices, while relevant data such as channel capacity, queuing delays, and link states can be modeled as graph properties. This representation opens up opportunities to apply GI for developing advanced communication protocols, such as those for B5G and 6G networks, enabling smarter, faster, and more energy-efficient data transmission. For instance, GNNs can be utilized to dynamically optimize routing strategies and detect intermittent anomalies within edge networks <ref type="bibr" target="#b358">[354]</ref>, <ref type="bibr" target="#b359">[355]</ref>. Furthermore, communication channel states can be incorporated as link attributes in graph models, allowing GI methods to enhance network management and resource allocation <ref type="bibr" target="#b248">[242]</ref>, <ref type="bibr" target="#b251">[245]</ref>- <ref type="bibr" target="#b253">[247]</ref>.</p><p>3) Personalized Services: End users nowadays are immersively surrounded by a vast amount of IoT devices like mobile smartphones, wearable kits, and smart home assets. For individual users, we can weave a user-centric network <ref type="bibr" target="#b360">[356]</ref> by collecting all user-related data from these surrounding devices and connecting them in a logic graph, on which EGI techniques can be applied to process, understand, and learn. In other words, EGI can serve as a tool to summarize data points scattered around individual users and be leveraged as a core component to build everyone-centric customized services.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Edge-Centric Graph Learning Models and Systems</head><p>Many existing GI models are originally designed to improve accuracy on specific tasks. In real deployment, however, a set of SLOs beyond accuracy are required by service providers such as responsive latency, system energy, and data privacy, and implementing GI models at edge faces unique challenges. Note that the graphs in edge networks may not be as huge as social networks on Twitter <ref type="bibr" target="#b361">[357]</ref>. However, it does not necessarily mean that training and deploying GNN on edge networks is technically trivial.</p><p>1) Resource Constraints to GI Models: As we discussed in Sec. VI, edge devices typically have limited but heterogeneous computational capabilities compared to cloud servers, possessing platforms from MCUs to mobile smartphones to edge servers. Edge-centric GI models need to be lightweight, have acceptable memory footprints, and minimize computational complexity while still delivering accurate results, especially for EGI-based services with real-time or near real-time requirements. This directs innovations in both model level and system level, e.g., lightweight algorithms like computation deduplication <ref type="bibr" target="#b362">[358]</ref> and memory-efficient on-device systems <ref type="bibr" target="#b109">[103]</ref>. Besides, fine-grained characteristics of GI models also expect precious profiling for refined resource utilization.</p><p>2) System Dynamics: There are two types of system dynamics, namely resource dynamics and graph dynamics. On the one hand, edge devices frequently operate in dynamic and unpredictable resource conditions, including intermittent connectivity, dynamic computing capabilities, or fluctuated communication bandwidths <ref type="bibr" target="#b363">[359]</ref>, <ref type="bibr" target="#b364">[360]</ref>. A stable, satisfactory EGI system is obliged to be robust to these variations and capable of adapting to different network conditions to ensure reliable and timely analysis, especially for those services that process graph data across multiple edge devices. On the other hand, many real-world graph data can be dynamic in both properties and topologies, requiring both algorithmic and system flexibility to adapt to the input variation. Some work <ref type="bibr" target="#b217">[211]</ref>, <ref type="bibr" target="#b218">[212]</ref> exploit online incremental adjustment for minor input variation, where drastic changes like graph reconstitution are still under exploration.</p><p>3) Scaling to Large Graphs: Many real-world networks represented as graphs can be massive and evolve in size, but how to scale EGI systems to large and heavy-attributed graphs poses significant challenges on both the algorithm and system sides. From the algorithm perspective, large graph models borrow wisdom from LLM and incorporate pre-training methods to embrace graphs on giant scales, but also bring overload stress to edge networks. Distributed edge collaboration (cf. Sec. VI-B), which aggregates multiple edge devices as a resource pool for model computation, can be a potential solution but still requires tailored designs with parallel processing, graph partitioning, and incremental learning, etc <ref type="bibr" target="#b365">[361]</ref>. From the system perspective, orchestrating a tremendous volume of graph data through edge network channels tackles the communication bottleneck as well as the storage capacity of edge devices. Data compression like graph pruning and feature quantization can be helpful, but how to balance the tradeoff between model accuracy and execution latency requires careful design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Emerging Learning Paradigms</head><p>Data generated at the network edge are massive but also usually in varying quality. To improve the applicability and usability of EGI models, emerging learning paradigms should be utilized to tackle different data cases. While some have been adopted (e.g., Federated Learning, Reinforcement Learning, etc.), there are still many that can be exploited and we discuss three below.</p><p>1) Large Graph Model:</p><p>LGMs borrow the wisdom of LLMs to the graph domain that simultaneously scales both training data and models. This scaling mechanism envisions</p><p>LGMs to be capable of capturing complex relationships and patterns within large-scale graphs, which are common representations of data in various domains such as social networks, biological networks, and transportation systems <ref type="bibr" target="#b63">[57]</ref>, <ref type="bibr" target="#b65">[59]</ref>. Nonetheless, applying LGM in edge networks severely suffers from the constrained computing capability and network capacity. Edge-cloud collaboration, which marries the local data processing ability of edge networks and the powerful computing power of the cloud, can be a potential solution for deployment. Given the promising ability of large models,</p><p>LGMs desire more effort in the context of EGI. On the other hand, EGI may also explore the translation between graphs and natural language to exploit the capability of LLMs, e.g., by semantically converting a graph into a paragraph of sentences for LLM input and generation <ref type="bibr" target="#b64">[58]</ref>.</p><p>2) Learning with Small Data: Edge devices can collect a large volume of data but only with a small portion of labels, which demands EGI to be capable few-shot learners. Towards that, few-shot learning techniques can be promising, which aims at training GL models for accurate predictions on unseen classes or categories with limited labeled data. For example, in some EGI-based object detection tasks <ref type="bibr" target="#b170">[164]</ref>, GI models can learn to recognize novel objects with a few labeled examples by leveraging information from similar objects and their relationships in a graph representation. Another potential path is transfer learning, which borrows knowledge learned from a source domain or task to improve performance in a target domain or task. An instance of transfer graph learning is anomaly detection in networked systems <ref type="bibr" target="#b270">[264]</ref>, <ref type="bibr" target="#b271">[265]</ref>, where GI can learn patterns of fraud by pre-training on a large graph and transfer this knowledge to identify fraudulent activities in a target domain with limited labeled data. TL can also be used for STGNN streams, e.g., for traffic prediction in smart cities <ref type="bibr" target="#b366">[362]</ref>.</p><p>3) Continual Learning: Continual Learning (CL) for GI is to incrementally retrain GNN models to adapt to new data or tasks without forgetting previous knowledge. It also adjusts the learned latent distribution like Transfer Learning but emphasizes learning patterns from the additional incoming data while preserving previously learned representations. For EGI services, CL enables incremental service refinement for evolved graphs, e.g., in temporal graph data analysis tasks, without training GI models from scratch. Examples include predicting traffic conditions in a road network and running the status of power grids, where continual learning of GI models allows the model to adapt over time and incorporate new temporal information while retaining the knowledge learned from past time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Native Edge Support for Graph Intelligence</head><p>Edge networks serve as the infrastructural support of GI model computation, for which an EGI-native pipeline is crucial for efficient and effective EGI services provisioning. Despite its importance, research on EGI-native edge support is yet limited in the context, and it confronts challenges in the full lifespan of GI model computation, i.e., from data collection to data processing to system development.</p><p>1) Graph Data Collection: EGI applications can not be realized without pervasive graph data. For many applications, however, these graph data are generated and distributed in different places, e.g., traffic sensory data scattered in road networks and perception information gathered by vehicles in robotic swarms. How to collect these (geographically) distributed data over the edge networks efficiently, i.e., in a high-quality, low-latency, and privacy-preserved manner, thereby becomes an unavoidable problem in running GI-based services. In certain situations, graph generation techniques <ref type="bibr" target="#b367">[363]</ref> may be a useful supplement for graph data requirements.</p><p>2) Edge-Cloud Collaboration: Edge networks render computing power in versatile forms, e.g., by a single edge device, a pool of collaborated ones, and even a synergetic edge-cloud continuum. Provisioning these versatile resources efficiently for EGI applications not only requires flexible resource management but also judicious workload scheduling that well aligns with computation and communication. In particular, edge-cloud collaboration provides a combined mechanism to embrace both data locality at the edge and resource richness in the cloud, which allows GI to be more efficient and sustainable and attracts growing attention from the community. Possible means towards this objective include designing GI-oriented communication protocols, GI-specific computation scheduling mechanisms, and a holistic edge network cost optimization methodology.</p><p>3) System Deployment: Given the broad use cases of EGI, their development yet lacks a comprehensive framework with full-stack toolkits, particularly for distributed edge collaboration and edge-cloud synergy. This requires addressing the complexity of distributed systems, including edge device coordination, data synchronization, and fault tolerance, and also tackling long-term interoperability and testing issues. Existing virtualization techniques such as container and function computing can be further explored for friendly EGI development and deployment. The communication aspects, such as timely data transmission of (potentially distributed) graph data and graph modeling of network channels, also desire tailored consideration.</p><p>4) Supporting Large Models: As an edge-oriented methodology, EGI can support large models in the following angles. First, EGI provides an effective way to abstract edge data in the form of graphs, acting as a graph data processing module for large model deployment at the edge. For instance, we may use EGI to transform graph data into prompts acceptable by large language models, allowing language intelligence on edge graphs. Second, with EGI models, edge data can be abstracted into graph embeddings. These embeddings can be used as a knowledge base for multi-modal foundation models aiming at specific edge scenarios, i.e., enabling retrievalaugmented generation. Third, EGI can also be operated as an optimization tool to orchestrate resource allocation for large model computation. To deploy resource-hungry large models on edge platforms, we may utilize many devices in edge networks, where EGI can be a scheduler, as discussed in Sec. VII-A, to schedule efficient resource allocation for large model acceleration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Explainability, Security, and Privacy</head><p>The open nature of EGI requires trustworthiness across different entities in the ecosystem to make EGI happen. Nonetheless, in many scenarios, edge services are practical only if they are reliable. For EGI, this relates to explainability, security, and privacy.</p><p>1) Explainability: Explainability makes GI models predictable and understandable, which is crucial for some actioncritical applications such as crime warnings and autonomous vehicle control. However, taming EGI models' behaviors is challenging, which usually involves specific knowledge in their application scenarios. Some literature has explored explaining GI models' behaviors in general with mathematical tools like Weisfeiler-Lehman graph isomorphism test <ref type="bibr" target="#b368">[364]</ref>- <ref type="bibr" target="#b370">[366]</ref>, but those GI models dedicated designed for edge scenarios still lack investigation.</p><p>2) Security: Security holds a dual significance in the context of EGI services. From a model perspective, GI models must be both secure and robust, as they are particularly vulnerable to attacks when malicious vertices are present in the graph input. The risk is further amplified when input graph data is aggregated from multiple entities, increasing the likelihood of fraudulent activity, and underscoring the importance of developing and implementing secure GI models. From a system perspective, edge networks are also susceptible to malicious devices, which can disrupt the learning process or compromise data integrity. This calls for the establishment of verifiable trust mechanisms among edge networks, alongside the development of secure tools to defend against and recover from such attacks.</p><p>3) Privacy: Edge networks typically operate in close proximity to individuals, collecting data from edge devices that may include personal and sensitive information, such as geographic location, health and activity records, and electricity consumption patterns <ref type="bibr" target="#b364">[360]</ref>. In light of privacy protection regulations, such as the European Union's General Data Protection Regulation (GDPR), the sharing and processing of this data across edge service providers poses significant risks of privacy leakage and unforeseen legal liabilities. Consequently, this raises critical research questions regarding not only secure but privacy-preserving computation in EGI models, where cryptographic techniques such as differential privacy and homomorphic encryption can be utilized to mitigate these risks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. CONCLUSION</head><p>Recent advances in ML have extrapolated representation learning techniques to the graph domain, cultivating GI as a powerful tool to learn from graphs. Meanwhile, edge computing networks are thriving with the rapid proliferation of edge facilities and becoming a fundamental infrastructure of miscellaneous user-centric intelligent services. These gamechanging trends push GI and edge networks to a closelooped confluence, where edge networks serve as infrastructural support to GI-based tasks and GI conversely serves as a key enabler to build and optimize edge services. Their complementary interaction raises a promising paradigm, i.e., Edge GI or EGI for brevity, to model, abstract, and analyze the ubiquitous graph data in edge networks, flourishing versatile graph-based applications at the network edge.</p><p>In this paper, we advocate EGI as a brand-new principle in the context of edge intelligence by revealing its motivational benefits, conceptual scope, and rating principle. Based on that, we conduct a comprehensive survey of recent research efforts in this emerging field from multiple dimensions. We first provide primers on GI and edge networks and summarize miscellaneous edge applications built with GI models. Next, from the perspectives of "edge for GI" and "GI for edge", we thoroughly review related concepts, techniques, and systems on computing GI models on edge networks and applying GI for optimizing edge networks, respectively. We finally present the overview of EGI ecosystems, discuss future directions, and conclude. We hope that this survey can garner increased attention, foster meaningful discussions, and inspire future research in EGI.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. General workflow of GI models. Given an input graph with feature vectors, a GI model iteratively performs sampling, aggregation, update, and pooling through consecutive model layers. The obtained embeddings will be finally converted to results in an expected form through a readout function.</figDesc><graphic coords="5,61.82,56.07,488.37,119.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>u</head><label></label><figDesc>|u ∈ N (v)} collects v's neighboring vertices' representation vectors and a (l) v is the aggregation result. Update. The GI model then passes the aggregation h (l) v through a neural network operator ϕ (l)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The spectrum of edge networks can be classified into five categories: sensors and micro control units, embedded and mobile devices, robotics and Vehicles, edge servers, and edge cloud.</figDesc><graphic coords="8,55.24,56.07,238.51,268.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. An illustration of vehicle trajectory planning via GI models, where the historical trajectories of vehicles are modeled as a time-varying graph.</figDesc><graphic coords="13,330.81,56.07,213.40,202.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Federated Graph Learning (FGL) leverages FL mechanisms to collaboratively train GI models with distributed clients. Specifically, horizontal FGL considers data splitting in the graph topology dimension, where the relationship across client data may be explicit or implicit to the centralized server.</figDesc><graphic coords="16,324.53,56.07,225.95,139.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Vertical FGL considers data split in the feature space with (a) incomplete graphs or (b) complete graphs.</figDesc><graphic coords="17,330.81,56.07,213.40,321.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 13 .</head><label>13</label><figDesc>Fig.<ref type="bibr" target="#b19">13</ref>. In general, KD for GNN follows a similar procedure of KD for traditional DL models, where we share the knowledge of the teacher model with the student model to improve its accuracy.</figDesc><graphic coords="20,55.24,56.07,238.51,144.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 14 .</head><label>14</label><figDesc>Fig.<ref type="bibr" target="#b20">14</ref>. In a general GI-incorporated DRL workflow, an agent observes states in a graph format and, through the GI model, abstracts relational semantics from states. Next, the agent passes the encoded data to a neural network operator to decide a scheduling action and receives a reward from the targeted environment (i.e., edge networks).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. GI models can abstract vertices's features into embeddings, which can be used for detecting anomalies by classifying in a latent space.</figDesc><graphic coords="22,61.52,56.07,225.96,71.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>establishes a fully connected graph by leveraging the similarity among clients' model weights or pattern features. Each client undertakes the training of a GNN using the crossclient graph and derives a global embedding. Subsequently, the local model embedding and the global embedding are amalgamated by applying a trainable weight, which enhances the capacity of the model to incorporate both local and global information, addressing data heterogeneity.2) Decentralized Federated Learning: Contrary to the centralized setting, decentralized GFL allows clients to communicate with their neighbors but does not have a central server to coordinate them (Fig.16(b)), making FL model aggregation a key challenge for global model convergence. To address</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. GI-assisted FL employs GI models as a tool to orchestrate FL clients with relationships and can be categorized into (a) centralized settings and (b) decentralized settings.</figDesc><graphic coords="23,61.52,56.07,225.95,292.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 17</head><label>17</label><figDesc>Fig. 17. The EGI ecosystem includes all stakeholders related to EGI from hardware, software, benchmark, and applications. The hardware involves edge hardware for sustaining EGI computation, covering CPU, GPU, FPGA, and DSA. The software indicates development frameworks for programming and deploying EGI models such as DGL and PyG. The benchmarks provide datasets and unified toolkits for evaluating dedicated EGI models and services. The applications show a rich set of scenarios where EGI actively works.</figDesc><graphic coords="24,61.82,56.07,488.37,219.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Fig. 17. The EGI ecosystem includes all stakeholders related to EGI from hardware, software, benchmark, and applications. The hardware involves edge hardware for sustaining EGI computation, covering CPU, GPU, FPGA, and DSA. The software indicates development frameworks for programming and deploying EGI models such as DGL and PyG. The benchmarks provide datasets and unified toolkits for evaluating dedicated EGI models and services. The applications show a rich set of scenarios where EGI actively works.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="2,311.98,56.07,251.06,293.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,87.52,56.07,436.97,194.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,61.82,56.07,488.37,159.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE II LIST</head><label>II</label><figDesc>OF MAIN NOTATIONS IN GRAPH REPRESENTATION LEARNING.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>et al. focus on macro-level predictions of case numbers across regions, emphasizing the epidemiological aspect of the disease spread. In contrast, Keicher et al. concentrate on microlevel patient outcomes within a clinical setting, emphasizing the individual variability in disease progression and response to treatment.</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Human skeleton Human action recognition dataset with acclerometer, gyroscope, and orientation sensory data [336TST V2 Vertex: Body joint Link: Human skeleton Fall detection dataset with depth frames, skeleton joints, acceleration sensory</title>
		<idno>334</idno>
	</analytic>
	<monogr>
		<title level="m">CORSMAL Vertex: Entity Link: Entity relationship A multimodal dataset focused on robotic perception for manipulating containers, including audio, visual, and depth data to estimate container properties and contents in real-time interactions</title>
		<imprint>
			<biblScope unit="page">337</biblScope>
		</imprint>
		<respStmt>
			<orgName>Human Sensing NTU RGB+D Vertex</orgName>
		</respStmt>
	</monogr>
	<note>: Body joint Link: Human skeleton Large-scale dataset for human action recognition that contains RGB videos, depth map sequences, and 3D skeletal data</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m">Locations -Based Social Recommendation Gowalla Vertex: User Link: Friendship Location-based social networks where users share their locations by checking-in. [340Foursquare Vertex: User and Hotel Link: Visiting history Location-based digital footprints from Foursquare for personalized location recommendation and search</title>
		<imprint/>
	</monogr>
	<note>MASS-SS3 Vertex: Monitoring channel Link: Channel connection Polysomnography recordings collected in a lab-based environment for sleep quality prediction</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">SIoT Vertex: IoT device Link: Social connection Network of IoT devices with social connections with identity information including device type, brand, and ownership</title>
		<imprint>
			<biblScope unit="page">341</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">User comment Link: Comment history Users&apos; review comments of POIs from Yelp with location, purchasing, and social information</title>
		<imprint>
			<biblScope unit="page">342</biblScope>
		</imprint>
	</monogr>
	<note>Yelp Vertex</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Mobile Vision MNIST Vertex: Pixel Link: Pixel adjacency Handwritten digits dataset, where pixels are viewed in grid-structure graphs</title>
		<imprint>
			<biblScope unit="page">343</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Entity Link: Entity relationship Video instance segmentation dataset that contains video clips from YouTube with segmentation masks, instance identity labels, etc</title>
		<imprint>
			<publisher>DAVIS Vertex</publisher>
			<biblScope unit="page">344</biblScope>
		</imprint>
	</monogr>
	<note>Entity Link: Entity relationship Video object segmentation dataset that consists of 50 videos in total with pixel-wise annotations for every frame</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Point Link: Point adjacency Point cloud dataset of various kinds of objects for 3D object detection</title>
		<imprint>
			<biblScope unit="page">346</biblScope>
		</imprint>
		<respStmt>
			<orgName>KITTI Vertex</orgName>
		</respStmt>
	</monogr>
	<note>ModelNet40 Vertex: Point Link: Point adjacency Synthetic object point clouds with CAD-generated meshes in various categories</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Edge computing in industrial internet of things: Architecture, advances and challenges</title>
		<author>
			<persName><forename type="first">T</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Atiquzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">O</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2462" to="2488" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A survey on edge and edge-cloud computing assisted cyber-physical systems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karnouskos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="7806" to="7819" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Edge video analytics: A survey on applications, systems and enabling techniques</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey on mobile augmented reality with 5g mobile edge computing: Architectures, applications, and technical aspects</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Siriwardhana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Porambage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liyanage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ylianttila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1160" to="1192" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A survey on the convergence of edge computing and ai for uavs: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mcenroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liyanage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="15" to="435" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Survey on the internet of vehicles: Network architectures and applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mumtaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Standards Magazine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="41" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Edge computing: Vision and challenges</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="637" to="646" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Edge intelligence: Paving the last mile of artificial intelligence with edge computing</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1738" to="1762" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph neural networks: A review of methods and applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Computing graph neural networks: A survey from algorithms to accelerators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abadal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guirado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>López-Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Alarcón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Parallel and distributed graph neural networks: An in-depth concurrency analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Besta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep learning on graphs: A survey</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A practical tutorial on graph neural networks</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Joyner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lickfold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10s</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations, ICLR 2017</title>
		<title level="s">Conference Track Proceedings</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<publisher>OpenReview.net</publisher>
			<date type="published" when="2017">April 24-26, 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Edge ai: On-demand accelerating deep neural network inference via edge computing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="447" to="457" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">In-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Network</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="156" to="165" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Traffic flow prediction via spatial temporal graph neural network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1082" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hybrid graph convolutional networks with multi-head attention for location recommendation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Trajcevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning graph-based geographical latent representation for point-of-interest recommendation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scale-net: Scalable vehicle trajectory prediction network under random number of interacting vehicles via edge-enhanced graph convolutional neural network</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<publisher>IEEE/RSJ</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ast-gnn: An attention-based spatio-temporal graph neural network for interactionaware pedestrian trajectory prediction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">445</biblScope>
			<biblScope unit="page" from="298" to="308" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Graph neural networks: A review of methods and applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI open</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="81" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Symmetric graph convolutional autoencoder for unsupervised graph representation learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6519" to="6528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Convolutional graph autoencoder: A generative deep neural network for probabilistic spatio-temporal solar irradiance forecasting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khodayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohammadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Khodayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Sustainable Energy</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="571" to="583" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph neural networks for predictive learning in urban computing: A survey</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Graph neural network for spatiotemporal data: methods and applications</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.00012</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Challenges and opportunities in deep with graph neural networks: A comprehensive review of algorithms and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Munikoti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Halappanavar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Reinforcement learning on graphs: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computational Intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Graph-based deep learning for communication networks: A survey</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="40" to="54" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Spatial-temporal graph neural network for traffic forecasting: An overview and open research issues</title>
		<author>
			<persName><forename type="first">K.-H</forename><forename type="middle">N</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2763" to="2774" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph neural networks for intelligent transportation systems: A survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baghbani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bouguila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A review of graph neural networks and their applications in power systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bak-Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Modern Power Systems and Clean Energy</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="345" to="360" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A survey of cyber-physical power system modeling methods for future energy systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abdelmalak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Macwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Applications of physics-informed neural networks in power systems-a review</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Power Systems</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An overview on the application of graph neural networks in wireless networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Open Journal of the Communications Society</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Graph neural networks in iot: a survey</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Campbel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukhechba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Sensor Networks</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="50" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Survey of graph neural network for internet of things and nextg networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Moorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jagannath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.17309</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A survey on edge computing systems and tools</title>
		<author>
			<persName><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="1537" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A survey on mobile edge computing: The communication perspective</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE communications surveys &amp; tutorials</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2322" to="2358" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Edge-computing-driven internet of things: A survey</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A survey on the edge computing for the internet of things</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Hatcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="6900" to="6919" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Convergence of edge computing and deep learning: A comprehensive survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Niyato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="869" to="904" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Machine learning at the network edge: A survey</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Murshed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Bringing ai to edge: From deep learning&apos;s perspective</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Subramaniam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">485</biblScope>
			<biblScope unit="page" from="297" to="320" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Edge computing with artificial intelligence: A machine learning perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Attention-based graph neural networks: a survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">Suppl 2</biblScope>
			<biblScope unit="page" from="2263" to="2310" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Bayesian Deep Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Spatio-temporal graph neural networks: A survey</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">A</forename><surname>Sahili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Awad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10569</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Graph transformer networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Heterogeneous graph transformer</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the web conference 2020</title>
		<meeting>the web conference 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2704" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Recipe for a general, powerful, scalable graph transformer</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rampášek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">P</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Beaini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="14" to="501" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Transformer for graphs: An overview from architecture perspective</title>
		<author>
			<persName><forename type="first">E</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08455</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Towards graph foundation models: A survey and beyond</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.11829</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Graph meets llms: Towards large graph models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2023 Workshop: New Frontiers in Graph Learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Opengraph: Towards open graph foundation models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.01121</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Graph-based semi-supervised learning: A review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">408</biblScope>
			<biblScope unit="page" from="216" to="230" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Graph-based semi-supervised learning: A comprehensive review</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Transfer learning of graph neural networks with ego-graph information maximization</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1766" to="1779" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Adaptive transfer learning on graph neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="565" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with augmentations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5812" to="5823" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Graph Contrastive Learning with Adaptive Augmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2021</title>
		<meeting>The Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2069" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">An Empirical Study of Graph Contrastive Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks</title>
		<meeting>the Neural Information Processing Systems Track on Datasets and Benchmarks</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations, ICLR 2014</title>
		<title level="s">Conference Track Proceedings</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">April 14-16, 2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Fedgl: Federated graph learning framework with global self-supervision</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">657</biblScope>
			<biblScope unit="page">119976</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Fedgraph: Federated graph learning with intelligent sampling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1775" to="1786" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Federatedscope-gnn: Towards a unified, comprehensive and efficient package for federated graph learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4110" to="4120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A survey on mobile edge networks: Convergence of computing, caching and communications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ieee Access</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="6757" to="6779" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Edge network optimization based on ai techniques: A survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pooyandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">2830</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Multi-tier computing networks for intelligent iot</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Electronics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="5" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Large-scale measurements and optimizations on latency in edge clouds</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Socialized learning: A survey of the paradigm shift for edge intelligence in networked systems</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Aws for the edge</title>
		<author>
			<persName><surname>Amazon</surname></persName>
		</author>
		<ptr target="https://aws.amazon.com/edge/" />
	</analytic>
	<monogr>
		<title level="j">Official Product Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Google distributed cloud edge</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://cloud.google.com/distributed-cloud-edge" />
	</analytic>
	<monogr>
		<title level="j">Official Product Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Edgex foundry: An open framework for iot edge computing</title>
		<ptr target="https://www.edgexfoundry.org/" />
	</analytic>
	<monogr>
		<title level="j">Official Website</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
		<respStmt>
			<orgName>Linux Foundation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Eclipse kura: Open source iot edge framework</title>
		<author>
			<orgName type="collaboration">Eclipse Foundation</orgName>
		</author>
		<ptr target="https://www.eclipse.org/kura/" />
	</analytic>
	<monogr>
		<title level="j">Official Website</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Apache edgent</title>
		<ptr target="https://incubator.apache.org/projects/edgent.html" />
		<imprint>
			<publisher>Official Website</publisher>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
		<respStmt>
			<orgName>The Apache Software Foundation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Redisedge: A dedicated iot database for edge computing</title>
		<author>
			<persName><surname>Redis</surname></persName>
		</author>
		<ptr target="https://redis.com/blog/redisedge-iot-database-for-edge-computing/" />
	</analytic>
	<monogr>
		<title level="m">Official Website</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">On-device training with tensorflow lite</title>
		<author>
			<persName><surname>Tensorflow</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/lite/examples/ondevicetraining/overview" />
	</analytic>
	<monogr>
		<title level="j">Official Website</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Mnn: A universal and efficient inference engine</title>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Edgecloudsim: An environment for performance evaluation of edge computing systems</title>
		<author>
			<orgName type="collaboration">EdgeCloudSim Project Team</orgName>
		</author>
		<idno>2024-01-31</idno>
		<ptr target="https://github.com/CagataySonmez/EdgeCloudSim" />
		<imprint/>
	</monogr>
	<note type="report_type">GitHub Repository</note>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Cloudsim: A framework for modeling and simulation of cloud computing infrastructures and services</title>
		<author>
			<persName><surname>Cloudslab</surname></persName>
		</author>
		<idno>2024-01-31</idno>
		<ptr target="https://github.com/Cloudslab/cloudsim" />
		<imprint/>
	</monogr>
	<note type="report_type">GitHub Repository</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">ifogsim: odeling and simulation of resource management techniques in internet of things, edge and fog computing environments</title>
		<author>
			<persName><surname>Cloudslab</surname></persName>
		</author>
		<idno>2024-01-31</idno>
		<ptr target="https://github.com/Cloudslab/iFogSim" />
		<imprint/>
	</monogr>
	<note type="report_type">GitHub Repository</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Yafs: Yet another fog simulator</title>
		<author>
			<orgName type="collaboration">YAFS Project Team</orgName>
		</author>
		<idno>2024-01-31</idno>
		<ptr target="https://github.com/acsicuib/YAFS" />
		<imprint/>
	</monogr>
	<note type="report_type">GitHub Repository</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Asteroid: Resourceefficient hybrid pipeline parallelism for collaborative dnn training on heterogeneous edge devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 30th Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Efficient federated learning for modern nlp</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 29th Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Mandheling: Mixed-precision on-device dnn training with dsp offloading</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Conference on Mobile Computing And Networking</title>
		<meeting>the 28th Annual International Conference on Mobile Computing And Networking</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="214" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Galaxy: A resource-efficient collaborative edge ai system for in-situ transformer inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2024-IEEE Conference on Computer Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Codl: efficient cpu-gpu co-execution for deep learning inference on mobile devices</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services</title>
		<meeting>the 20th Annual International Conference on Mobile Systems, Applications and Services<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="209" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">The digitization of the world from edge to core</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.-J. G.-J</forename><surname>Rydning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reinsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gantz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Framingham: International Data Corporation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Lstm: A search space odyssey</title>
		<author>
			<persName><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2222" to="2232" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A review of recurrent neural networks: Lstm cells and network architectures</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1235" to="1270" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer networks and ISDN systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-7</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">A note on two problems in connexion with graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische mathematik</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: a deep learning framework for traffic forecasting</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3634" to="3640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Multitask offloading strategy optimization based on directed acyclic graphs for edge computing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="9367" to="9378" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Graphnet: Graph neural networks for routing optimization in software defined networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chaba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="169" to="182" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Sugar: Efficient subgraph-level training via resource-aware graph partitioning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Hardware-aware graph neural network automated design for edge computing platforms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 60th ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<ptr target="https://en.wikipedia.org/wiki/File:UnitedStatesPowerGrid.jpg" />
		<title level="m">United states power grid</title>
		<imprint>
			<date type="published" when="2023">cember 4, 2023</date>
		</imprint>
	</monogr>
	<note>Rolypolyman@Wikipedia. EB/OL</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Structure aware slam using quadrics and planes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hosseinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Latif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Suenderhauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ACCV 2018: 14th Asian Conference on Computer Vision</title>
		<meeting><address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">December 2-6, 2018. 2019</date>
			<biblScope unit="page" from="410" to="426" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers. Part III 14</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Understanding the smart city domain: A literature review</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Anthopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transforming city governments for successful smart cities</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="9" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">The &apos;actually existing smart city</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shelton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wiig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cambridge journal of regions, economy and society</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<ptr target="https://www.uber.com" />
		<title level="m">Uber company information</title>
		<imprint>
			<publisher>Official Website</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Didi company information</title>
		<author>
			<persName><forename type="first">Didi</forename><surname>Chuxing</surname></persName>
		</author>
		<ptr target="https://www.didiglobal.com" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Official Website</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<author>
			<persName><forename type="first">Inc</forename><surname>Lyft</surname></persName>
		</author>
		<ptr target="https://www.lyft.com" />
		<title level="m">Lyft company information</title>
		<imprint>
			<publisher>Official Website</publisher>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Dual attentive graph neural network for metro passenger flow prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="13" to="417" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Gnn-based passenger request prediction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Makhdomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Gillani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Letters</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Gallat: A spatiotemporal graph attention network for passenger demand prediction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 37th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2129" to="2134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Contrastive gnn-based traffic anomaly against imbalanced dataset in iot-based its</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Bashir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Imran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GLOBECOM 2022-2022 IEEE Global Communications Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3557" to="3562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Deep with graph representation for vehicle repositioning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="13" to="094" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Fault diagnosis of power transformers using graph convolutional network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSEE Journal of Power and Energy Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="249" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Searching for critical power system cascading failures with graph convolutional network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Botterud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Control of Network Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1304" to="1313" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Cyberattack detection in large-scale smart grids using chebyshev graph convolutional networks</title>
		<author>
			<persName><forename type="first">O</forename><surname>Boyaci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Narimani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Serpedin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 9th International Conference on Electrical and Electronics Engineering (ICEEE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="217" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Spatiotemporal graph neural network for performance prediction of photovoltaic power systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Koyuturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="15" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Spatiotemporal behind-the-meter load and pv power forecasting via deep graph dictionary learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Khodayar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kaynak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Khodayar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4713" to="4727" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Group-aware graph neural network for nationwide city air quality forecasting</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">A graph-based lstm model for pm2. 5 forecasting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric Pollution Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">101150</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">A hybrid integrated deep learning model for predicting various air pollutants</title>
		<author>
			<persName><forename type="first">W</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GIScience &amp; Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1395" to="1412" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Conditional local convolution for spatio-temporal meteorological forecasting</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="7470" to="7478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Frost forecasting model using graph neural networks with spatio-temporal attention</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sanchez-Pi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AI: Modeling Oceans and Climate Change Workshop at ICLR 2021</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Deep graph convolutional networks for wind speed prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Stanczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehrkanoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="147" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Ufsp-net: a neural network with spatio-temporal information fusion for urban fire situation prediction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">IOP Conference Series: Materials Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">853</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12050</biblScope>
			<date type="published" when="2020">2020</date>
			<publisher>IOP Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Spatial-temporal sequential hypergraph network for crime prediction with dynamic multiplex relation learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Spatial-temporal attention network for crime prediction with adaptive graph learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="656" to="669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Examining covid-19 forecasting using spatio-temporal graph neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>O'banion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Mining and Learning with Graphs</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Multimodal graph attention network for covid-19 outcome prediction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Keicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Burwinkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bani-Harouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Paschali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Czempiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Burian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Makowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Braren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wendler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">19539</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Edge robotics: Edge-computing-accelerated multi-robot simultaneous localization and mapping</title>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Sensorimotor graph: Action-conditioned graph neural network for learning robotic soft hand dynamics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schydlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dehban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos-Victor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="9569" to="9576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Learning particle dynamics for manipulating rigid bodies, deformable objects, and fluids</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tedrake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Deep imitation learning for bimanual robotic manipulation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Paolis Kaluza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2327" to="2337" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Learning visual affordances with target-orientated deep q-network to grasp objects by harnessing environmental fixtures</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2562" to="2568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Adadrone: Quality of navigation based neural adaptive scheduling for edge-assisted drones</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="548" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Graph neural networks for decentralized multi-robot path planning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prorok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="11" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Dynamic motion planning model for multirobot using graph neural network and historical information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Intelligent Systems</title>
		<imprint>
			<biblScope unit="page">2300036</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">A3d: Adaptive, accurate and autonomous navigation for edge-assisted drones</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2023">2023</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">A survey on human-aware robot navigation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Furnari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Battiato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Härmä</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Farinella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page">103837</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Multi-agent collaborative exploration through graph-based deep reinforcement learning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Subagdja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-H</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Agents (ICA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Coverage control in multi-robot systems via graph neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gosrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mayya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="8787" to="8793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">H2gnn: hierarchical-hops graph neural networks for multi-robot exploration in unknown environments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3435" to="3442" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Silent messages</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrabian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">152</biblScope>
			<pubPlace>Wadsworth Belmont, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<title level="m">An approach to environmental psychology</title>
		<imprint>
			<publisher>the MIT Press</publisher>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">Au-assisted graph attention convolutional network for micro-expression recognition</title>
		<author>
			<persName><forename type="first">H.-X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-H</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Multimedia</title>
		<meeting>the 28th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2871" to="2880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Sg-dsn: A semantic graph-based dual-stream network for facial expression recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">462</biblScope>
			<biblScope unit="page" from="320" to="330" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Geometryaware facial expression recognition via attentive graph convolutional networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>.-K. Lun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Graph-pcnn: Two stage human pose estimation with graph pose refinement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">August 23-28, 2020. 2020</date>
			<biblScope unit="page" from="492" to="508" />
		</imprint>
	</monogr>
	<note>Part XI 16</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Learning graph convolutional network for skeleton-based human action recognition by neural searching</title>
		<author>
			<persName><forename type="first">W</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2669" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Differentiable hierarchical graph grouping for multi-person pose estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">August 23-28, 2020. 2020</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="718" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Influenza-like symptom recognition using mobile sensing and graph neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukhechba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on health, inference, and learning</title>
		<meeting>the conference on health, inference, and learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Semisupervised graph instance transformer for mental health inference</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boukhechba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1221" to="1228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Graphsleepnet: Adaptive spatial-temporal graph convolutional networks for sleep stage classification</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page" from="1324" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Recommendations based on a heterogeneous spatio-temporal social network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kefalas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Symeonidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="345" to="371" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Heterographrec: A heterogeneous graph-based neural networks for social recommendations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Salamat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jafari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="page">106817</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">A spatiotemporal graph neural network for session-based recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page">117114</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">Stan: Spatio-temporal attention network for next location recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the web conference 2021</title>
		<meeting>the web conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2177" to="2185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Stam: A spatiotemporal aggregation method for graph neural network-based recommendation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3217" to="3228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Point-gnn: Graph neural network for 3d object detection in a point cloud</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rajkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1711" to="1719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Structure inference net: Object detection using scene-level context and instance-level relationships</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="6985" to="6994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<analytic>
		<title level="a" type="main">Multi-label image recognition with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Z.-M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5177" to="5186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">Graph-fcn for image semantic segmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International symposium on neural networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">Learning a neural solver for multiple object tracking</title>
		<author>
			<persName><forename type="first">G</forename><surname>Brasó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6247" to="6257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">Gsm: Graph similarity model for multi-object tracking</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="530" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (tog)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Convolution in the cloud: Learning deformable kernels in 3d graph convolution networks for point cloud analysis</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1800" to="1809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Linked dynamic graph cnn: Learning through point cloud by linking hierarchical features</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>De Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 27th international conference on mechatronics and machine vision in practice (M2VIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">Eco-fl: Adaptive federated learning with efficient edge collaborative pipeline training</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st International Conference on Parallel Processing</title>
		<meeting>the 51st International Conference on Parallel Processing</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Federated graph machine learning: A survey of concepts, techniques, and applications</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="32" to="47" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<analytic>
		<title level="a" type="main">Federated graph neural networks: Overview, techniques, and challenges</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Asfgnn: Automated separated-federated graph neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Peer-to-Peer Networking and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1692" to="1704" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Fedego: Privacy-preserving personalized federated graph learning with ego-graphs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b182">
	<analytic>
		<title level="a" type="main">Graphfl: A federated learning framework for semi-supervised node classification on graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="498" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Fastgnn: A topological information protected federated learning approach for traffic speed forecasting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="8464" to="8474" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Subgraph federated learning with missing neighbor generation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Yiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="6671" to="6682" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Fedni: Federated graph learning with network inpainting for population-based disease prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dvornek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<analytic>
		<title level="a" type="main">A privacypreserving subgraph-level federated graph neural network via differential privacy</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Science, Engineering and Management</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="165" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b187">
	<analytic>
		<title level="a" type="main">A federated graph neural network framework for privacy-preserving personalization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3091</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b188">
	<monogr>
		<title level="m" type="main">Fedgnn: Federated graph neural network for privacy-preserving recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04925</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">Federated graph learning with periodic neighbour sampling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM 30th International Symposium on Quality of Service (IWQoS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022. 2022</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Fedgcn: Convergencecommunication tradeoffs in federated training of graph convolutional networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Joe-Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<analytic>
		<title level="a" type="main">Differentially private federated knowledge graphs embedding</title>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1416" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Pate-gan: Generating synthetic data with differential privacy guarantees</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on learning representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b193">
	<analytic>
		<title level="a" type="main">Fede: Embedding knowledge graphs in federated setting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Joint Conference on Knowledge Graphs</title>
		<meeting>the 10th International Joint Conference on Knowledge Graphs</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="80" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b194">
	<analytic>
		<title level="a" type="main">Efficient federated learning on knowledge graphs via privacy-preserving relation embedding aggregation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2022 Workshop on Federated Learning for Natural Language Processing</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b195">
	<analytic>
		<title level="a" type="main">Federated knowledge graph completion via embedding-contrastive learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">252</biblScope>
			<biblScope unit="page">109459</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b196">
	<analytic>
		<title level="a" type="main">Sgnn: A graph neural network based federated learning approach by hiding structure</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2560" to="2568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b197">
	<analytic>
		<title level="a" type="main">Fedsgc: Federated simple graph convolution for node classification</title>
		<author>
			<persName><forename type="first">T.-H</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI Workshops</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<analytic>
		<title level="a" type="main">Federated meta-learning for spatial-temporal prediction</title>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="10" to="355" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<analytic>
		<title level="a" type="main">Graphfraudster: Adversarial attacks on graph neural network-based vertical federated learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Social Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="492" to="506" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b200">
	<analytic>
		<title level="a" type="main">A survey on collaborative dnn inference for edge intelligence</title>
		<author>
			<persName><forename type="first">W.-Q</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-B</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Q</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="395" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b201">
	<analytic>
		<title level="a" type="main">Digital twin-based 3d map management for edge-assisted device pose tracking in mobile ar</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<analytic>
		<title level="a" type="main">Adaptive deviceedge collaboration on dnn inference in aiot: A digital twin-assisted approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">S</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Stochastic cumulative dnn inference with rl-aided adaptive iot deviceedge collaboration</title>
		<author>
			<persName><forename type="first">K</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<analytic>
		<title level="a" type="main">Boomerang: On-demand cooperative deep neural network inference for edge intelligence on the industrial internet of things</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="96" to="103" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Jupiter: Fast and resource-efficient collaborative inference of generative llms on edge devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2025-IEEE Conference on Computer Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<analytic>
		<title level="a" type="main">Branchy-gnn: A deviceedge co-inference framework for efficient cloud processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8488" to="8492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b207">
	<analytic>
		<title level="a" type="main">Spinn: synergistic progressive inference of neural networks over device and cloud</title>
		<author>
			<persName><forename type="first">S</forename><surname>Laskaridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Venieris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Leontiadis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 26th Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b208">
	<analytic>
		<title level="a" type="main">Pyramid: Enabling hierarchical neural networks with edge computing</title>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1860" to="1870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<analytic>
		<title level="a" type="main">Implementation of big ai models for wireless networks with collaborative edge computing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b210">
	<analytic>
		<title level="a" type="main">Online orchestration of collaborative caching for multi-bitrate videos in edge computing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yahyapour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4207" to="4220" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b211">
	<analytic>
		<title level="a" type="main">Ents: An edge-native task scheduling system for collaborative edge computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sahni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/ACM 7th Symposium on Edge Computing (SEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="149" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b212">
	<analytic>
		<title level="a" type="main">Mobile collaborative learning over opportunistic internet of vehicles</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3187" to="3199" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b213">
	<analytic>
		<title level="a" type="main">Distributed dnn inference with fine-grained model partitioning in mobile edge computing networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b214">
	<analytic>
		<title level="a" type="main">Coedge: Cooperative dnn inference with adaptive workload partitioning over heterogeneous edge devices</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Collaborative edge computing for social internet of things: Applications, solutions, and challenges</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Social Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="291" to="301" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Fograph: Enabling real-time deep graph inference with fog computing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1774" to="1784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<analytic>
		<title level="a" type="main">Serving graph neural networks with distributed fog servers for smart iot services</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2023">2023</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b218">
	<analytic>
		<title level="a" type="main">Gnn at the edge: Cost-efficient graph neural network processing over distributed edge servers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="720" to="739" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<analytic>
		<title level="a" type="main">Brief industry paper: Optimizing memory efficiency of graph neural networks on edge computing platforms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 27th Real-Time and Embedded Technology and Applications Symposium (RTAS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="445" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b220">
	<analytic>
		<title level="a" type="main">Efficient inference of graph neural networks using local sensitive hash</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Sustainable Computing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b221">
	<analytic>
		<title level="a" type="main">Accelerating large scale real-time gnn inference using channel pruning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1597" to="1605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<analytic>
		<title level="a" type="main">Input feature pruning for accelerating gnn inference on heterogeneous platforms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Kuppannagari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE 29th International Conference on High Performance Computing, Data, and Analytics (HiPC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="282" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b223">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b224">
	<analytic>
		<title level="a" type="main">Lightgcn: Simplifying and powering graph convolution network for recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR conference on research and development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b225">
	<analytic>
		<title level="a" type="main">Ultragcn: ultra simplification of graph convolutional networks for recommendation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1253" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b226">
	<analytic>
		<title level="a" type="main">Pasca: A graph neural architecture search system under the scalable paradigm</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1817" to="1828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<analytic>
		<title level="a" type="main">Magnas: A mapping-aware graph neural architecture search framework for heterogeneous mpsoc deployment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Odema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bouzidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ouarnoughi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Niar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Al Faruque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Embedded Computing Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5s</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b228">
	<analytic>
		<title level="a" type="main">Sgquant: Squeezing the last bit on graph neural networks with specialized quantization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1044" to="1052" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<analytic>
		<title level="a" type="main">Degree-quant: Quantization-aware training for graph neural networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tailor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fernández-Marqués</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021</title>
		<meeting><address><addrLine>Virtual Event, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">May 3-7, 2021. 2021</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b230">
	<analytic>
		<title level="a" type="main">Vq-gnn: A universal framework to scale up graph neural networks using vector quantization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="6733" to="6746" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<analytic>
		<title level="a" type="main">Bi-gcn: Binary graph convolutional network</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1561" to="1570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b233">
	<monogr>
		<title level="m" type="main">Graph-based knowledge distillation: A survey and experimental evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.14643</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b234">
	<analytic>
		<title level="a" type="main">On the efficacy of knowledge distillation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4794" to="4802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b235">
	<analytic>
		<title level="a" type="main">Knowledge distillation for mobile edge computation offloading</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ZTE Communications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<analytic>
		<title level="a" type="main">Knowledge distillation: A survey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="1789" to="1819" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b237">
	<analytic>
		<title level="a" type="main">Distilling knowledge from graph convolutional networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7074" to="7083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b238">
	<analytic>
		<title level="a" type="main">Extract the knowledge of graph neural networks and go beyond it: An effective knowledge distillation framework</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the web conference 2021</title>
		<meeting>the web conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1227" to="1237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<analytic>
		<title level="a" type="main">Tinygnn: Learning efficient graph neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1848" to="1856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b240">
	<analytic>
		<title level="a" type="main">Graph neural networks for scalable radio resource management: Architecture design and theoretical analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<analytic>
		<title level="a" type="main">Flocoff: Data heterogeneity resilient federated learning with communication-efficient edge offloading</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3262" to="3277" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<analytic>
		<title level="a" type="main">Hyperjet: Joint communication and computation scheduling for hypergraph tasks in distributed edge computing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2025-IEEE Conference on Computer Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b243">
	<analytic>
		<title level="a" type="main">Power control in wireless cellular networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends® in Networking</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="533" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b244">
	<analytic>
		<title level="a" type="main">Optimal routing, link scheduling and power control in multihop wireless networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Santhanam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No. 03CH37428</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003">2003. 2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="702" to="711" />
		</imprint>
	</monogr>
	<note>IEEE INFOCOM</note>
</biblStruct>

<biblStruct xml:id="b245">
	<analytic>
		<title level="a" type="main">A graph neural network approach for scalable wireless power control</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Globecom Workshops (GC Wkshps)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<analytic>
		<title level="a" type="main">Optimal wireless resource allocation with random edge graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ieee transactions on signal processing</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="2977" to="2991" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<analytic>
		<title level="a" type="main">Transferable policies for large scale wireless networks with graph neural networks</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alejandro</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5040" to="5044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b248">
	<analytic>
		<title level="a" type="main">A gnn approach for cell-free massive mimo</title>
		<author>
			<persName><forename type="first">L</forename><surname>Salaün</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GLOBECOM 2022-2022 IEEE Global Communications Conference</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3053" to="3058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b249">
	<analytic>
		<title level="a" type="main">Fast power control adaptation via metalearning for random edge graph neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Nikoloska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Simeone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="146" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b250">
	<analytic>
		<title level="a" type="main">Knowledge-driven resource allocation for wireless networks: A wmmse unrolled graph neural network approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Aldubaikhy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alqasir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b251">
	<analytic>
		<title level="a" type="main">Graph neural network-based channel tracking for massive mimo networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Dobre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1747" to="1751" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b252">
	<analytic>
		<title level="a" type="main">Message passing meets graph neural networks: A new paradigm for massive mimo systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Letaief</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b253">
	<analytic>
		<title level="a" type="main">Graph neural network based access point selection for cell-free massive mimo systems</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ranasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rajatheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Latva-Aho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE Global Communications Conference (GLOBECOM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<analytic>
		<title level="a" type="main">Gcn-gan: A non-linear temporal link prediction model for weighted dynamic networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2019-IEEE conference on computer communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="388" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b255">
	<analytic>
		<title level="a" type="main">Optimal multiuser transmit beamforming: A difficult problem with a simple solution structure [lecture notes</title>
		<author>
			<persName><forename type="first">E</forename><surname>Björnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bengtsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="142" to="148" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b256">
	<analytic>
		<title level="a" type="main">Graph neural network based beamforming in d2d wireless networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lambotharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSA 2021; 25th International ITG Workshop on Smart Antennas</title>
		<imprint>
			<publisher>VDE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">A bipartite graph neural network approach for scalable beamforming optimization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-E</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="333" to="347" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<analytic>
		<title level="a" type="main">Holistic network virtualization and pervasive network intelligence for 6g</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<analytic>
		<title level="a" type="main">Graph neural network based service function chaining for automatic network control</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b260">
	<analytic>
		<title level="a" type="main">Reinforcement learning of graph neural networks for service function chaining in computer network management</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 23rd Asia-Pacific Network Operations and Management Symposium (APNOMS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b261">
	<analytic>
		<title level="a" type="main">A graph neural network-based digital twin for network slicing management</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Miao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1367" to="1376" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b262">
	<analytic>
		<title level="a" type="main">Digital twin-empowered network slicing in b5g networks: Experience-driven approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Naeem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kaddoum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tariq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE Globecom Workshops (GC Wkshps)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b263">
	<analytic>
		<title level="a" type="main">Graph neural networks for communication networks: Context, use cases and opportunities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Suárez-Varela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Almasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferriol-Galmés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rusek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cabellos-Aparicio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE network</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="146" to="153" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<analytic>
		<title level="a" type="main">Mogr: Multi-task offloading via graph representation in heterogeneous computing network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning-based channel allocation for wireless lans with graph convolutional networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ohtsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nishio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morikura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="31" to="823" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<analytic>
		<title level="a" type="main">Unfolding wmmse using graph neural networks for efficient power allocation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Segarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="6004" to="6017" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<analytic>
		<title level="a" type="main">Wi-fi meets ml: A survey on improving ieee 802.11 performance with machine learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Szott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kosek-Szott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gawłowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bellalta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zubow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dressler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1843" to="1893" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<analytic>
		<title level="a" type="main">Graph anomaly detection with graph neural networks: Current status and challenges</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<analytic>
		<title level="a" type="main">Anomman: Detect anomalies on multi-view attributed networks</title>
		<author>
			<persName><forename type="first">L.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">628</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<analytic>
		<title level="a" type="main">efraudcom: An e-commerce fraud detection system via competitive graph neural networks</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<analytic>
		<title level="a" type="main">Deep graph-level anomaly detection by glocal knowledge distillation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Fifteenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="704" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b272">
	<analytic>
		<title level="a" type="main">Raising the bar in graph-level anomaly detection</title>
		<author>
			<persName><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b273">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4393" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b274">
	<analytic>
		<title level="a" type="main">Graph time-series modeling in deep learning: A survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eldardiry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b275">
	<analytic>
		<title level="a" type="main">Graph neural network-based anomaly detection in multivariate time series</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4027" to="4035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b276">
	<analytic>
		<title level="a" type="main">Grelen: Multivariate time series anomaly detection from the perspective of graph relational learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tsung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</title>
		<meeting>the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2390" to="2397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<analytic>
		<title level="a" type="main">Learning sparse latent graph representations for anomaly detection in multivariate time series</title>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2977" to="2986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b278">
	<analytic>
		<title level="a" type="main">Multi-level federated graph learning and self-attention based personalized wi-fi indoor fingerprint localization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Letters</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1794" to="1798" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b279">
	<analytic>
		<title level="a" type="main">Big-fed: Bilevel optimization enhanced graph-aided federated learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<analytic>
		<title level="a" type="main">Personalized federated learning with a graph</title>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence</title>
		<meeting>the Thirty-First International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<analytic>
		<title level="a" type="main">Power allocation for wireless federated learning using graph neural networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Segarra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5243" to="5247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b282">
	<analytic>
		<title level="a" type="main">Privacy-preserving federated multi-task linear regression: A one-shot linear mixing approach inspired by graph regularization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Bertozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kovačević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5947" to="5951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b283">
	<analytic>
		<title level="a" type="main">Cluster-driven graph federated learning over multiple domains</title>
		<author>
			<persName><forename type="first">D</forename><surname>Caldarola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Galasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ciccone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rodolà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2749" to="2758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<analytic>
		<title level="a" type="main">Decentralized federated learning for electronic health records</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 54th Annual Conference on Information Sciences and Systems (CISS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b285">
	<analytic>
		<title level="a" type="main">Decentralized graph federated multitask learning for streaming data</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">C</forename><surname>Gogineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 56th Annual Conference on Information Sciences and Systems (CISS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b286">
	<analytic>
		<title level="a" type="main">Semigraphfl: Semi-supervised graph federated learning for graph classification</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Parallel Problem Solving from Nature</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="474" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b287">
	<analytic>
		<title level="a" type="main">Fedstn: Graph representation driven federated learning for edge computing enabled urban traffic flow prediction</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Taherkordi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b288">
	<analytic>
		<title level="a" type="main">Graph signal processing: Overview, challenges, and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kovačević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="808" to="828" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b289">
	<analytic>
		<title level="a" type="main">A new look and convergence rate of federated multitask learning with laplacian regularization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b290">
	<analytic>
		<title level="a" type="main">Spreadgnn: Serverless multi-task federated learning for graph neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ceyani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Annavaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avestimehr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Sixth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6865" to="6873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<analytic>
		<title level="a" type="main">Understanding and bridging the gaps in current gnn performance optimizations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</title>
		<meeting>the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="119" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b292">
	<analytic>
		<title level="a" type="main">Understanding gnn computational graph: A coordinated computation, io, and memory perspective</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Machine Learning and Systems</title>
		<meeting>Machine Learning and Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="467" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b293">
	<analytic>
		<title level="a" type="main">Fusedmm: A unified sddmm-spmm kernel for graph embedding and graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Sujon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Azad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="256" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b294">
	<analytic>
		<title level="a" type="main">Graphite: optimizing graph neural networks on cpus through cooperative software-hardware techniques</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Torrellas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual International Symposium on Computer Architecture</title>
		<meeting>the 49th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="916" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b295">
	<analytic>
		<title level="a" type="main">Distgnn: Scalable distributed training for large-scale graph neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mohanty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Georganas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Heinecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kalamkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Avancha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</title>
		<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b296">
	<analytic>
		<title level="a" type="main">Dorylus: Affordable, scalable, and accurate {GNN} training with distributed {CPU} servers and serverless threads</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Eyolfson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Netravali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th USENIX Symposium on Operating Systems Design and Implementation (OSDI 21)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="495" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b297">
	<analytic>
		<title level="a" type="main">Flexgraph: a flexible and efficient distributed framework for gnn training</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixteenth European Conference on Computer Systems</title>
		<meeting>the Sixteenth European Conference on Computer Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="67" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b298">
	<analytic>
		<title level="a" type="main">Characterizing the scalability of graph convolutional networks on intel® piuma</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Adiletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Tithi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-I</forename><surname>Farsarakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gerogiannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Benke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hsia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petrini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b299">
	<analytic>
		<title level="a" type="main">Featgraph: A flexible and efficient backend for graph neural network systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC20: International Conference for High Performance Computing, Networking, Storage and Analysis</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b300">
	<analytic>
		<title level="a" type="main">Distributed graph neural network training: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b301">
	<analytic>
		<title level="a" type="main">A comprehensive survey on distributed training of graph neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b302">
	<analytic>
		<title level="a" type="main">Hp-gnn: Generating high throughput gnn training implementation on cpu-fpga heterogeneous platform</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<meeting>the 2022 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="123" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<monogr>
		<title level="m" type="main">Gengnn: A generic fpga framework for graph neural network acceleration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Abi-Karam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sathidevi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.08475</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b304">
	<analytic>
		<title level="a" type="main">Graphagile: An fpga-based overlay accelerator for low-latency gnn inference</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prasanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Parallel and Distributed Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b305">
	<analytic>
		<title level="a" type="main">Graphopu: A highly integrated fpga-based overlay processor for graph neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 33rd International Conference on Field-Programmable Logic and Applications (FPL)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="228" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b306">
	<analytic>
		<title level="a" type="main">Accelerated charged particle tracking with graph neural networks on fpgas</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Razavimaleki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Workshop on Machine Learning and the Physical Sciences</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b307">
	<analytic>
		<title level="a" type="main">Accelerating gnnbased sar automatic target recognition on hbm-enabled fpga</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Prasanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Busart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE High Performance Extreme Computing Conference (HPEC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b308">
	<analytic>
		<title level="a" type="main">Low latency edge classification gnn for particle trajectory tracking on fpgas</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-R</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-C</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hauck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Neubauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 33rd International Conference on Field-Programmable Logic and Applications (FPL)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="294" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b309">
	<analytic>
		<title level="a" type="main">Ultra power-efficient cnn domain specific accelerator with 9.3 tops/watt for mobile and embedded applications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1677" to="1685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b310">
	<analytic>
		<title level="a" type="main">Tensor processing unit</title>
		<author>
			<persName><surname>Google</surname></persName>
		</author>
		<ptr target="https://cloud.google.com/tpu/" />
	</analytic>
	<monogr>
		<title level="j">Official Product Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">Mobile ai solutions</title>
		<author>
			<persName><surname>Qualcomm</surname></persName>
		</author>
		<ptr target="https://www.qualcomm.com/products/mobile/snapdragon/smartphones/mobile-ai" />
	</analytic>
	<monogr>
		<title level="j">Official Product Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b312">
	<analytic>
		<title level="a" type="main">Deploying transformers on the apple neural engine</title>
		<author>
			<persName><surname>Apple</surname></persName>
		</author>
		<ptr target="https://machinelearning.apple.com/research/neural-engine-transformers" />
	</analytic>
	<monogr>
		<title level="m">Apple Machine Learning Research Website</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b313">
	<analytic>
		<title level="a" type="main">Engn: A high-throughput and energy-efficient accelerator for large graph neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huawei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1511" to="1525" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b314">
	<analytic>
		<title level="a" type="main">Hardware acceleration of graph neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Auten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tomei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 57th ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b315">
	<analytic>
		<title level="a" type="main">Characterizing and understanding gcns on gpu</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="25" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b316">
	<analytic>
		<title level="a" type="main">Characterizing and understanding distributed gnn training on gpus</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="24" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b317">
	<analytic>
		<title level="a" type="main">Hygcn: A gcn accelerator with hybrid architecture</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="15" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b318">
	<analytic>
		<title level="a" type="main">Grip: A graph neural network accelerator architecture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kiningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="914" to="925" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b319">
	<analytic>
		<title level="a" type="main">Greta: Hardware optimized graph processing for gnns</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kiningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Resource-Constrained Machine Learning</title>
		<meeting>the Workshop on Resource-Constrained Machine Learning<address><addrLine>ReCoML</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b320">
	<analytic>
		<title level="a" type="main">Awb-gcn: A graph convolutional network accelerator with runtime workload rebalancing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tumeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="922" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b321">
	<analytic>
		<title level="a" type="main">Gnnie: Gnn inference engine with load-balancing and graph-specific caching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Manasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kunal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Sapatnekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th ACM/IEEE Design Automation Conference</title>
		<meeting>the 59th ACM/IEEE Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="565" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b322">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b323">
	<monogr>
		<title level="m" type="main">Deep graph library: A graph-centric, highly-performant package for graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01315</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b324">
	<analytic>
		<title level="a" type="main">Agl: A scalable system for industrialpurpose graph machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b325">
	<analytic>
		<title level="a" type="main">{BGL}:{GPU-Efficient}{GNN} training by optimizing graph data {I/O} and preprocessing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="103" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b326">
	<monogr>
		<title level="m" type="main">Tf-gnn: Graph neural networks in tensorflow</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ferludin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eigenwillig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pfeifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bulut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.03522</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b327">
	<analytic>
		<title level="a" type="main">Caltrans Performance Measurement System</title>
		<ptr target="http://pems.dot.ca.gov/" />
	</analytic>
	<monogr>
		<title level="m">PeMS Official Website</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
	<note>Pems dataset</note>
</biblStruct>

<biblStruct xml:id="b328">
	<analytic>
		<title level="a" type="main">Metr-la dataset</title>
		<ptr target="https://www.kaggle.com/datasets/annnnguyen/metr-la-dataset" />
	</analytic>
	<monogr>
		<title level="j">Kaggle</title>
		<imprint>
			<biblScope unit="page">322</biblScope>
			<pubPlace>Metro</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b329">
	<analytic>
		<title level="a" type="main">Nyc taxi dataset</title>
		<author>
			<persName><forename type="first">&amp; Limousine</forename><surname>Nyc Taxi</surname></persName>
		</author>
		<author>
			<persName><surname>Commission</surname></persName>
		</author>
		<ptr target="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page" />
	</analytic>
	<monogr>
		<title level="j">NYC Data and Reports</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b330">
	<analytic>
		<title level="a" type="main">Chicago bike trip dataset</title>
		<author>
			<persName><surname>Divvy</surname></persName>
		</author>
		<ptr target="https://divvybikes.com/system-data" />
	</analytic>
	<monogr>
		<title level="m">Divvy Data</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b331">
	<analytic>
		<title level="a" type="main">Beijing multisite air quality dataset</title>
		<idno>2023-07-31</idno>
		<ptr target="https://archive.ics.uci.edu/dataset/501/beijing+multi+site+air+quality+data" />
	</analytic>
	<monogr>
		<title level="m">UC Irving Machine Learning Repository</title>
		<imprint>
			<biblScope unit="page">325</biblScope>
		</imprint>
		<respStmt>
			<orgName>Beijing Municipal Environmental Monitoring Center</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b332">
	<monogr>
		<title level="m" type="main">Weatherbench2 dataset</title>
		<ptr target="https://github.com/google-research/weatherbench2" />
		<imprint/>
	</monogr>
	<note>326Google. Github, accessed: 2023-07-31</note>
</biblStruct>

<biblStruct xml:id="b333">
	<analytic>
		<title level="a" type="main">Powergraph dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Varbella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Amara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gjorgiev1</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Giovanni</surname></persName>
		</author>
		<ptr target="https://figshare.com/articles/dataset/PowerGraph/22820534" />
	</analytic>
	<monogr>
		<title level="j">Figshare</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b334">
	<monogr>
		<title level="m" type="main">Covid-19 dataset</title>
		<ptr target="https://github.com/CSSEGISandData/COVID-19" />
		<imprint>
			<date type="published" when="2023-07-31">2023-07-31</date>
			<publisher>Github</publisher>
		</imprint>
		<respStmt>
			<orgName>JHU CSSE</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b335">
	<monogr>
		<title level="m" type="main">Us-101 dataset</title>
		<ptr target="https://www.fhwa.dot.gov/publications/research/operations/07030/" />
		<imprint>
			<publisher>Federal Highway Administration Research and Technology</publisher>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
		<respStmt>
			<orgName>Federal Highway Administration Research and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b336">
	<monogr>
		<title level="m" type="main">Stanford drone dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<ptr target="https://cvgl.stanford.edu/projects/uavdata/" />
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
	<note type="report_type">Stanford Project Page</note>
</biblStruct>

<biblStruct xml:id="b337">
	<monogr>
		<title level="m" type="main">Kinetics dataset</title>
		<author>
			<orgName type="collaboration">Kinetics Project Team</orgName>
		</author>
		<ptr target="https://github.com/cvdfoundation/kinetics-dataset" />
		<imprint>
			<publisher>Github</publisher>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b338">
	<analytic>
		<title level="a" type="main">nuscenes dataset</title>
		<author>
			<persName><surname>Team</surname></persName>
		</author>
		<ptr target="https://www.nuscenes.org/" />
	</analytic>
	<monogr>
		<title level="m">nuScenes Project Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b339">
	<analytic>
		<title level="a" type="main">Corsmal dataset</title>
		<author>
			<orgName type="collaboration">CORSMAL Project Team</orgName>
		</author>
		<ptr target="https://corsmal.eecs.qmul.ac.uk/" />
	</analytic>
	<monogr>
		<title level="m">CORSMAL Project Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b340">
	<analytic>
		<title level="a" type="main">Robonet dataset</title>
		<author>
			<orgName type="collaboration">RoboNet Project Team</orgName>
		</author>
		<ptr target="https://www.robonet.wiki/" />
	</analytic>
	<monogr>
		<title level="m">RoboNet Project Page</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b341">
	<analytic>
		<title level="a" type="main">Ntu rgb+d dataset</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
		<ptr target="https://bmi.hmu.gr/the-mobifall-and-mobiact-datasets-2/" />
	</analytic>
	<monogr>
		<title level="m">ROSE Lab Website</title>
		<imprint>
			<date type="published" when="2023-07-31">2023-07-31</date>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
	<note>BMI Lab</note>
</biblStruct>

<biblStruct xml:id="b342">
	<analytic>
		<title level="a" type="main">Tst fall detection datasets v2 dataset</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cippitelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gambi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gasparrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Spinsante</surname></persName>
		</author>
		<ptr target="http://ceams-carsm.ca/mass/" />
	</analytic>
	<monogr>
		<title level="m">Montreal archive of sleep studies dataset</title>
		<imprint>
			<date type="published" when="2023-07-31">2023-07-31</date>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
	<note>CARSM Official Website</note>
</biblStruct>

<biblStruct xml:id="b343">
	<analytic>
		<title level="a" type="main">Affectnet dataset</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mollahosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hasani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Mahoor</surname></persName>
		</author>
		<ptr target="http://mohammadmahoor.com/affectnet/" />
	</analytic>
	<monogr>
		<title level="m">AffectNet Official Website</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b344">
	<monogr>
		<title level="m" type="main">Gowalla dataset</title>
		<author>
			<persName><forename type="first">E</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<ptr target="https://snap.stanford.edu/data/loc-gowalla.html" />
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
		<respStmt>
			<orgName>SNAP Group</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b345">
	<analytic>
		<title level="a" type="main">Foursquare dataset</title>
		<author>
			<orgName type="collaboration">Foursquare Dataset Team</orgName>
		</author>
		<ptr target="https://sites.google.com/site/yangdingqi/home/foursquare-dataset" />
	</analytic>
	<monogr>
		<title level="m">Dingqi Yang&apos;s Homepage</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b346">
	<analytic>
		<title level="a" type="main">Social iot dataset</title>
		<author>
			<persName><forename type="first">C</forename><surname>Marche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Atzori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pilloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nitti</surname></persName>
		</author>
		<ptr target="https://www.social-iot.org/" />
	</analytic>
	<monogr>
		<title level="m">Social Internet of Things Project Official Website</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b347">
	<analytic>
		<title level="a" type="main">Yelp open dataset</title>
		<author>
			<persName><surname>Yelp</surname></persName>
		</author>
		<ptr target="https://www.yelp.com/dataset" />
	</analytic>
	<monogr>
		<title level="m">Yelp Official Website</title>
		<imprint/>
	</monogr>
	<note>accessed: 2023-07-31</note>
</biblStruct>

<biblStruct xml:id="b348">
	<analytic>
		<title level="a" type="main">Mnist dataset</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/datasets/catalog/mnist" />
	</analytic>
	<monogr>
		<title level="m">Google TensorFlow Datasets</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b349">
	<analytic>
		<title level="a" type="main">Davis dataset</title>
		<author>
			<orgName type="collaboration">DAVIS Dataset Team</orgName>
		</author>
		<ptr target="https://davischallenge.org/" />
	</analytic>
	<monogr>
		<title level="m">DAVIS Challenge Official Website</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b350">
	<analytic>
		<title level="a" type="main">Youtube video instance segmentation dataset</title>
		<author>
			<orgName type="collaboration">YouTube-VOS Project Team</orgName>
		</author>
		<idno>2023-07-31</idno>
		<ptr target="https://youtube-vos.org/dataset/vis/" />
	</analytic>
	<monogr>
		<title level="m">YouTube-VOS Official Website</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b351">
	<analytic>
		<title level="a" type="main">The kitti vision benchmark suite</title>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<ptr target="https://www.cvlibs.net/datasets/kitti/" />
	</analytic>
	<monogr>
		<title level="j">CVLIBS</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b352">
	<analytic>
		<title level="a" type="main">Modelnet dataset</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<ptr target="https://modelnet.cs.princeton.edu/" />
	</analytic>
	<monogr>
		<title level="m">Princeton ModelNet Official Website</title>
		<imprint>
			<biblScope unit="page" from="2023" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b353">
	<analytic>
		<title level="a" type="main">Cooperative task offloading and service caching for digital twin edge networks: A graph attention multiagent approach</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b354">
	<analytic>
		<title level="a" type="main">Gnn-based power allocation and user association in digital twin network for the terahertz band</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b355">
	<analytic>
		<title level="a" type="main">Haps-based interference suppression through null broadening with directivity control in space-air-ground integrated networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hangai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b356">
	<analytic>
		<title level="a" type="main">Traffic prediction-based dynamic resource control strategy in haps-mounted mec-assisted satellite communication systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tsuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Miura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b357">
	<analytic>
		<title level="a" type="main">Challenges and machine learning solutions for optical communications in space-air-ground integrated networks for 6g</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ariyoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Funada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L T</forename><surname>De Gabory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b358">
	<analytic>
		<title level="a" type="main">Graph-based deep learning for communication networks: A survey</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="40" to="54" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b359">
	<analytic>
		<title level="a" type="main">Task-oriented 6g native-ai network architecture</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b360">
	<analytic>
		<title level="a" type="main">6g network ai architecture for everyone-centric customized services</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><forename type="middle">P</forename><surname>Yum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Aghvami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="71" to="80" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b361">
	<analytic>
		<title level="a" type="main">What is twitter, a social network or a news media?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on World wide web</title>
		<meeting>the 19th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="591" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b362">
	<analytic>
		<title level="a" type="main">Guide: Training deep graph neural networks via guided dropout over edges</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4465" to="4477" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b363">
	<analytic>
		<title level="a" type="main">Intelligence beyond the edge: Inference on intermittent embedded systems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gobieski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lucia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems</title>
		<meeting>the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="199" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b364">
	<analytic>
		<title level="a" type="main">Smart handover with predicted user behavior using convolutional neural networks for wigig systems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Fouda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b365">
	<analytic>
		<title level="a" type="main">Multi-tier multi-node scheduling of llm for collaborative ai computing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM 2025-IEEE Conference on Computer Communications</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b366">
	<analytic>
		<title level="a" type="main">Transfer learning with spatial-temporal graph convolutional network for traffic prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="8592" to="8605" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b367">
	<analytic>
		<title level="a" type="main">A systematic survey on deep generative models for graph generation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5370" to="5390" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b368">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b369">
	<analytic>
		<title level="a" type="main">Provably powerful graph networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Serviansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b370">
	<analytic>
		<title level="a" type="main">Explainability in graph neural networks: A taxonomic survey</title>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5782" to="5799" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
