<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Design Fundamentals of Diffusion Models: A Survey</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-10-19">19 Oct 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ziyi</forename><surname>Chang</surname></persName>
							<email>ziyi.chang@durham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Koulieris</surname></persName>
							<email>georgios.a.koulieris@durham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Hubert</forename><forename type="middle">P H</forename><surname>Shum</surname></persName>
							<email>hubert.shum@durham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<postCode>DH1 3LE</postCode>
									<settlement>Durham</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On the Design Fundamentals of Diffusion Models: A Survey</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-10-19">19 Oct 2023</date>
						</imprint>
					</monogr>
					<idno type="MD5">31ED3F57BD8463730B536B4C9CD4E8E8</idno>
					<idno type="arXiv">arXiv:2306.04542v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-01-21T07:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Diffusion Model</term>
					<term>Forward Process</term>
					<term>Reverse Process</term>
					<term>Sampling Procedure</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Diffusion models are generative models, which gradually add and remove noise to learn the underlying distribution of training data for data generation. The components of diffusion models have gained significant attention with many design choices proposed. Existing reviews have primarily focused on higher-level solutions, thereby covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review on component-wise design choices in diffusion models. Specifically, we organize this review according to their three key components, namely the forward process, the reverse process, and the sampling procedure. This allows us to provide a fine-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the applicability of design choices, and the implementation of diffusion models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>D IFFUSION models are an emerging class of generative models to obtain novel data <ref type="bibr">[1]</ref>. During training, a diffusion model is trained by adding and removing noise when given a set of training samples. During inference, it generates a new sample using random noise as input.</p><p>Diffusion models have been applied in a wide range of fields. Diffusion models have shown impressive results in inpainting <ref type="bibr">[2]</ref>, text-to-image <ref type="bibr" target="#b2">[3]</ref>, super-resolution <ref type="bibr" target="#b3">[4]</ref>, colorization <ref type="bibr" target="#b4">[5]</ref>, instance segmentation <ref type="bibr" target="#b5">[6]</ref>, and so on. They have been popular as a non-autoregressive alternative solution in conventionally autoregressive tasks <ref type="bibr" target="#b6">[7]</ref>. Diffusion models have also demonstrated superiority in speech generation <ref type="bibr" target="#b7">[8]</ref>, music synthesis <ref type="bibr" target="#b8">[9]</ref>, and audio enhancement <ref type="bibr" target="#b9">[10]</ref>. Besides, they become increasingly popular in 3D shape generation <ref type="bibr" target="#b10">[11]</ref>, human motion synthesis <ref type="bibr" target="#b11">[12]</ref>, video synthesis <ref type="bibr" target="#b12">[13]</ref>, molecule synthesis <ref type="bibr" target="#b13">[14]</ref>, trajectory prediction <ref type="bibr" target="#b14">[15]</ref>, simulation <ref type="bibr" target="#b15">[16]</ref>, and astronomical data synthesis <ref type="bibr" target="#b16">[17]</ref>.</p><p>The generic pipeline of diffusion models involves a forward process and a reverse process to learn a data distribution, as well as a sampling procedure to generate novel data. The pipeline is featured by a time-indexed multistep chain where the three components move either forwards, i.e., timestep increases, or backwards, i.e., timestep decreases. The forward process moves forwards on the chain and perturbs the training data by adding noise at each timestep. The reverse process moves on the chain in the opposite direction. It optimizes a network to remove the aforementioned perturbation. The two processes jointly enable the network to be trained for distribution modelling. Finally, the sampling procedure obtains a random noise and uses the optimized network for data generation. It also moves backwards on the chain as the reverse process does. The main difference is that the network during the sampling procedure is already optimized and used for inference only.</p><p>Typically, two distinctive formulations are available for realizing the three components in the generic pipeline. First, diffusion models may be formulated with discrete timesteps <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Second, diffusion models may also be formulated with continuous timesteps. These components are defined by stochastic differential equations (SDEs) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b19">[20]</ref>. This formulation unifies the one with discrete timesteps, and facilitates the theoretical analysis of diffusion models <ref type="bibr" target="#b20">[21]</ref>.</p><p>Although these three components generally define the generic pipeline, they are currently lacking a comprehensive survey. Some existing survey papers focus on higher-level solutions to facilitate applications, and explore less on the design details of each component <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Some concentrate on specific domains or aspects of diffusion models, lacking insights on the holistic design fundamentals of the generic pipeline <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. Others focus on the application side, and thereby provide fewer observations on theoretical designs <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Overall, a survey that concentrates specifically on designing the aforementioned components of diffusion models is lacking.</p><p>This survey bridges the gap in the literature by offering a thorough and cohesive review of component-wise design fundamentals in diffusion models. In particular, we have organized design fundamentals of diffusion models into the forward process, the reverse process, and the sampling procedure, as shown in Figure <ref type="figure">1</ref>. This breakdown is aligned with the generic pipeline. Drawing upon the latest research and implementations, we have summarized the main streams of design fundamentals for each component. Overall, this survey offers a fine-grained perspective of diffusion models, and facilitates future analysis of individual components, the applicability of design fundamentals, and the implementation of diffusion models.</p><p>The rest of this survey is organised as follows. Section 2 introduces the preliminaries of diffusion models, including the generic pipeline and its two formulations. Sections 3, 4, and 5 respectively review the design fundamentals of the forward process, the reverse process, and the sampling procedure, as visualised in Figure <ref type="figure">1</ref>. Section 6 provides Fig. <ref type="figure">1</ref>. The overview of diffusion models. The forward process, the reverse process, and the sampling procedure are the three core components of diffusion models, which are responsible for adding noise, training networks, and generating samples, respectively. insights on the future trends and Section 7 gives a brief conclusion on diffusion models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>This survey uses commonly-used notations and terminologies in existing papers, as shown in Table <ref type="table" target="#tab_0">1</ref>, and represents concepts with figures whose legends are defined in Table <ref type="table" target="#tab_1">2</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Generic Pipeline</head><p>The generic pipeline in diffusion models is generally specified by the forward process, the reverse process, and the sampling procedure. The generic pipeline is characterized by a timestep-indexed multi-step chain where the three components move forwards or backwards. The forward Combination, e.g., Addition.</p><p>With probability p for dropping out and reverse processes are implemented jointly to optimize a denoising network by gradually adding and removing noise <ref type="bibr" target="#b18">[19]</ref>. After the optimization, the sampling procedure leverages the trained network to generate a novel sample x * 0 ∼ p θ * (x 0 ) ≈ p(x 0 ) whose distribution p θ * (x 0 ) conforms to the same distribution as the original one p(x 0 ) <ref type="bibr" target="#b17">[18]</ref>. The forward process perturbs a training sample x 0 to {x t } T t=1 as the timestep t increases, as shown in Figure <ref type="figure" target="#fig_1">2</ref>. A forward transition p(x t |x t-1 ) describes such a perturbation where a small amount of noise ϵ t is added between two timesteps. In other words, as the forward process moves on the chain, more and more noise is added through p(x t |x t-1 ) and the perturbed sample x t becomes noisier and noisier. Through multiple timesteps, the original distribution p(x 0 ) is eventually perturbed to a tractable terminal distribution p(x T ), which is usually full of noise <ref type="bibr" target="#b33">[34]</ref>. Since only noise is added through the chain, the forward process does not have any trainable parameters. In particular, the forward process is represented as a chain of forward transitions:</p><formula xml:id="formula_0">p(x T |x 0 ) := p(x 1 |x 0 ) • • • p(x t |x t-1 ) • • • p(x T |x T -1 ), = T t=1 p(x t |x t-1 ), (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where t is the timestep, T is the total number of timesteps, x 0 is a training sample at t = 0 and is then perturbed to be x T after T timesteps, and p(x t |x t-1 ) is a forward distribution transition between two consecutive time steps.</p><p>The forward process has both similarities and differences with variational autoencoders (VAEs) <ref type="bibr" target="#b34">[35]</ref>. Similar to VAEs, it usually perturbs p(x 0 ) to the commonly-used isotropic Gaussian distribution p(x T ) = N (0, I) as the terminal distribution <ref type="bibr" target="#b35">[36]</ref>. In contrast to learning an encoder to obtain p(x T ) in VAEs, the forward process has no trainable parameters and only adds noise to x 0 for perturbation <ref type="bibr" target="#b18">[19]</ref>. The reverse process trains a denoising network to recursively remove the noise, as shown in Figure <ref type="figure" target="#fig_2">3</ref>. Instead of removing all noise in a single timestep like GANs <ref type="bibr" target="#b36">[37]</ref>, a denoising network is trained to iteratively remove the noise between two consecutive timesteps. The reverse process moves backwards on the multi-step chain as t decreases from T to 0. Such iterative noise removal is termed as the reverse transition p θ (x t-1 |x t ), which is approximated by optimizing the trainable parameters θ in the denoising network <ref type="bibr" target="#b37">[38]</ref>. In particular, the reverse process is formulated as a chain of reverse transitions:</p><formula xml:id="formula_2">p θ (x 0 ) := p(x T )p θ (x T -1 |x T ) • • • p θ (x t-1 |x t ) • • • p θ (x 0 |x 1 ), = p(x T ) T t=1 p θ (x t-1 |x t ),<label>(2)</label></formula><p>where θ is the parameters of the denoising network and p θ (x t-1 |x t ) is the reverse distribution transition. In particular, the reverse process is usually parameterized as:</p><formula xml:id="formula_3">p θ (x t-1 |x t ) := N (x t-1 ; µ θ (x t , t), Σ θ (x t , t)),<label>(3)</label></formula><p>where µ θ (x t , t) and Σ θ (x t , t) are, respectively, the Gaussian mean and variance to be estimated by the network θ.</p><p>The denoising network is trained by the standard variational bound on negative log likelihood:</p><formula xml:id="formula_4">L =E[D KL (p(x T |x 0 )||p(x T )) + t≥1 D KL (p(x t-1 |x t , x 0 )||p θ (x t-1 |x t )) -log p θ (x 0 |x 1 )],<label>(4)</label></formula><p>where D KL (•∥•) is the Kullback-Leibler (KL) divergence and computes the difference between two distributions. Overall, minimization of the objective L is to reduce the discrepancy between p θ (x 0 ) and p(x 0 ). The sampling procedure leverages the optimized denoising network θ * to generate novel data x * 0 , as illustrated in Figure <ref type="figure" target="#fig_3">4</ref>. It moves backwards on the chain to recursively apply the optimized network θ * <ref type="bibr" target="#b38">[39]</ref>. Concretely, it firstly obtains a sample x T from the terminal distribution p(x T ) and then uses the trained network to iteratively remove noise by the sampling transition p θ * (x t-1 |x t ). Through a chain of such transitions, it finally generates new data x * 0 ∼ p θ * (x 0 ) ≈ p(x 0 ). In particular, the sampling procedure is defined as a chain of sampling transitions:</p><formula xml:id="formula_5">p θ * (x 0 ) := p(x T )p θ * (x T -1 |x T ) • • • p θ * (x 0 |x 1 ), = p(x T ) T t=1 p θ * (x t-1 |x t ),<label>(5)</label></formula><p>where θ * represents the optimized parameters of the denoising network, p(x T ) is the terminal distribution, and p θ * (x t-1 |x t ) is the sampling transition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Discrete and Continuous Formulations</head><p>Diffusion models can be formulated in two distinct ways, i.e., discrete and continuous formulations, which differ in the definition of the timesteps <ref type="bibr" target="#b39">[40]</ref>. The discrete formulation defines timesteps to be integer values, ranging from 0 to T <ref type="bibr" target="#b18">[19]</ref>, and results in a finite number of timesteps that is specified by the value of T . In contrast, the continuous formulation defines the timesteps as continuous values, which are constrained within the interval of [0, 1], and allows for an infinite number of timesteps in theory <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">The Discrete Formulation</head><p>Regarding the discrete formulation, denoising diffusion probabilistic model (DDPM) <ref type="bibr" target="#b18">[19]</ref> is a popular configuration of such formulated diffusion models. It is straightforward to define, efficient to train, and capable to achieve high quality and high diversity in the generated samples <ref type="bibr" target="#b40">[41]</ref>.</p><p>Concretely, the forward transition in DDPM is defined to add isotropic Gaussian noise ϵ t ∼ N (0, I):</p><formula xml:id="formula_6">p(x t |x t-1 ) := N (x t ; 1 -β t x t-1 , β t I),<label>(6)</label></formula><p>where β t is the noise schedule, which is a hyper-parameter to control the amount of noise to be added in each timestep. As all forward transitions (Eq. 6) are Gaussian, the forward process (Eq. 1) in DDPM is simplified as:</p><formula xml:id="formula_7">p(x t |x 0 ) := N (x t ; √ ᾱt x 0 , (1 -ᾱt )I),<label>(7)</label></formula><p>where ᾱt is defined as ᾱt = t s=1 α s and α t = 1β t . In theory, ᾱt has a similar effect with β t in Eq. 6. Please refer to Section 1 in supplementary material for the detailed derivation of Eq. 7 from Eq. 6.</p><p>The reverse process has the same functional form as the forward process <ref type="bibr">[1]</ref>. In DDPM configuration, the transition Eq. 3 in the reverse process is formulated as:</p><formula xml:id="formula_8">p θ (x t-1 |x t ) := N (x t-1 ; 1 √ α t (x t - 1 -α t √ 1 -ᾱt ϵ θ (x t , t)), β t I),<label>(8)</label></formula><p>where the variance Σ θ (x t , t) in Eq. 3 is empirically fixed as the noise schedule β t , and µ θ (x t , t) is reparametrized by the noise prediction ϵ θ (x t , t). Accordingly, the training objective defined in Eq. 4 is also simplified as:</p><formula xml:id="formula_9">L = E xt,t ∥ϵ t -ϵ θ (x t , t)∥ 2 2 .<label>(9)</label></formula><p>Finally, the sampling process obtains x T ∼ p(x T ), and applies p θ * (x t-1 |x t ) to generate x * 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">The Continuous Formulation</head><p>The continuous formulation manipulates data distributions in continuous time. Noise is added in an infinitesimal interval between timesteps. Therefore, a stochastic differential equation (SDE) is adopted in such formulated diffusion models to describe changes in continuous timesteps <ref type="bibr" target="#b41">[42]</ref>.</p><p>Concretely, the forward transition to add noise is formulated as a forward SDE:</p><formula xml:id="formula_10">dx = f (x, t)dt + g(t)dw, (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where w is the standard Wiener process and accounts for noise in the forward transition, and f (x, t) and g(t) are the drift and diffusion coefficients to account for the mean and variance in the forward transitions, respectively <ref type="bibr" target="#b42">[43]</ref>. At the same time. a reverse SDE for the reverse transition (Eq. 3) is also determined by these coefficients <ref type="bibr" target="#b43">[44]</ref>:</p><formula xml:id="formula_12">dx = f (x, t) -g 2 (t)s θ (x t , t) dt + g(t)dw,<label>(11)</label></formula><p>where the output of the denoising network s θ (x t , t) = ∇ x log p(x t ) is the score <ref type="bibr" target="#b44">[45]</ref>. Likewise, f (x, t)g 2 (t)s θ (x t , t) and g(t) account for the mean and the variance in Eq. 3. The training objective is defined as:</p><formula xml:id="formula_13">L = E t λ(t)E x0 E xt|x0 ∥s θ (x t , t) -∇ x log p(x t |x 0 )∥ 2 2 , (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>where λ(t) is the weighting function. Section 3 in supplementary material presents the equivalence of using ∇ x log p(x t ) and ∇ x log p(x t |x 0 ) in Eq. 12.</p><p>Finally, the sampling procedure obtains x T , and applies the trained network θ * to generate novel data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE FORWARD PROCESS</head><p>The forward process defines the way data to be perturbed by configuring the noise and specifying a transition chain. The way the perturbation happens affects not only the forward process but also the reverse process and the sampling procedure <ref type="bibr" target="#b45">[46]</ref>. Noise configuration involves the schedule and the type of noise to be added <ref type="bibr" target="#b46">[47]</ref>. The transition chain specifies how the data distribution are transformed <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Noise Configuration</head><p>The schedule <ref type="bibr" target="#b45">[46]</ref> and the type of noise <ref type="bibr" target="#b48">[49]</ref> are configured for effective and expressive diffusion models. Specifically, a suitable schedule provides such a noise intensity that perturbs the data samples at an appropriate speed <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b49">[50]</ref>. Moreover, different types of noise have an influence on the modeling capabilities of diffusion models <ref type="bibr" target="#b49">[50]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">The Noise Schedule</head><p>The noise schedule controls the amount of noise ϵ t to be added at timestep t. It schedules a value β t as the noise level for each timestep t <ref type="bibr">[1]</ref>. The noise ϵ t is scaled by the noise level and then is used to perturb x 0 <ref type="bibr" target="#b17">[18]</ref>.</p><p>A suitable schedule encourages a balance between exploration and exploitation. Exploration describes the ability of generalization on data not seen during training <ref type="bibr" target="#b50">[51]</ref> while exploitation refers to the convergence situation where a model fits the training data well <ref type="bibr" target="#b51">[52]</ref>. According to the definition of the forward process in Eq. 1, the larger the amount of noise that is used, the faster the data structures are destroyed, and vice versa. On the one hand, a sufficient amount of noise is necessary to encourage exploration to generalize well on unseen data, while excessive noise may result in sub-optimal convergence or inconvergence of a model, which cannot adequately recover the details of data <ref type="bibr" target="#b52">[53]</ref>. On the other hand, too little noise boosts exploitation to fit distributions well but undermines generalization <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref>. Empirically, smaller noise levels are scheduled at early timesteps for exploitation, and higher levels are assigned at late timesteps for exploration for a better balance <ref type="bibr" target="#b55">[56]</ref>.</p><p>Data are often considered when a noise schedule is designed. From the viewpoint of data representation, the number of data dimensions and the maximum Euclidean distance of training samples need to be considered to design the noise schedule <ref type="bibr" target="#b56">[57]</ref>. Furthermore, the noise schedule should align with the complexity and redundancy of the data <ref type="bibr" target="#b45">[46]</ref>. For example, larger images may require more noise than smaller ones <ref type="bibr" target="#b57">[58]</ref>. In the context of data reconstruction, adding sufficient noise is beneficial for easy modeling of the distribution while adding little noise helps accurate reconstruction <ref type="bibr" target="#b58">[59]</ref>.</p><p>The noise schedule can be learned by a network or empirically designed using mathematical formulations. To learn a noise schedule, existing methods recognize it as a parameter to be learned jointly with other parameters <ref type="bibr" target="#b58">[59]</ref>. These parameters are usually optimized by maximizing a variational lower bound on the log-likelihood <ref type="bibr" target="#b60">[61]</ref>. Since the noise schedule is learned by the network, it can be different for training and sampling to achieve optimal results <ref type="bibr" target="#b54">[55]</ref>. In contrast, manually-designed noise schedules are formulated with a wide variety of mathematical heuristics. Some design Simple Linear <ref type="bibr" target="#b45">[46]</ref> Cosine <ref type="bibr" target="#b57">[58]</ref> Exponential <ref type="bibr" target="#b17">[18]</ref> Sigmoid <ref type="bibr" target="#b59">[60]</ref> the noise schedule to be affine <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b45">[46]</ref>, or to have an exponential relationship <ref type="bibr" target="#b17">[18]</ref> with the timestep. Both are thought to perturb data quicker than necessary. Consequently, other functions, such as cosine <ref type="bibr" target="#b57">[58]</ref>, sigmoid <ref type="bibr" target="#b59">[60]</ref>, and mathematical integral <ref type="bibr" target="#b19">[20]</ref>, are used to achieve a more appropriate perturbation speed in the forward process. Table <ref type="table" target="#tab_2">3</ref> shows several examples of designed noise schedules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">The Noise Type</head><p>The selection of the noise type leads to improved distribution approximation and greater degrees of freedom, accentuating its significance on expressiveness of diffusion models. Specifically, selecting an appropriate noise type enhances the model capacity as it fits the perturbed distributions at different timesteps more accurately <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b49">[50]</ref>. Additionally, different types offer varying degrees of freedom <ref type="bibr" target="#b46">[47]</ref>. This brings more flexibility in modeling distributions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise Type Visualization</head><p>Gaussian <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> Gamma <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b49">[50]</ref> Soft <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b61">[62]</ref> Different noise types have been developed based on empirical experiments. Inheriting from the denoising score matching <ref type="bibr" target="#b62">[63]</ref>, isotropic Gaussian noise is commonly used for its simplicity and compatibility <ref type="bibr">[1]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Several variants of isotropic Gaussian noise, such as mixture of Gaussian noise <ref type="bibr" target="#b46">[47]</ref> and non-isotropic Gaussian noise <ref type="bibr" target="#b63">[64]</ref>, have also been applied for increased expressiveness. When correlation exists in a data sample, e.g. frames of a video, the noise are designed to be correlated as well <ref type="bibr" target="#b64">[65]</ref>. Additionally, Gamma distribution is another feasible and promising alternative. It has one more degree of freedom and fits distributions better <ref type="bibr" target="#b49">[50]</ref>. Soft corruptions can be recognized as a generalized noise for perturbation. This type of noise is more than traditional statistical distribution and supports various operators like masking to perturb data <ref type="bibr" target="#b48">[49]</ref>. Such operators also destroy data structures as the aforementioned noise does. This greatly extends the expressive power as a wide variety of operators become available <ref type="bibr" target="#b61">[62]</ref>. Overall, these attempts on alternative types pave the way towards more generalized diffusion models. On the other hand, their re-formulations imposed by new noise type may be costly <ref type="bibr" target="#b46">[47]</ref>. Table <ref type="table" target="#tab_3">4</ref> visualizes different types of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Transition Chain</head><p>The chain of transitions controls the way of perturbing the given data distribution. Varying the terminal distribution in the forward process helps train the denoising network in the reverse process effectively and efficiently <ref type="bibr" target="#b65">[66]</ref>. The systematic method is an emerging transition design to increase expressiveness <ref type="bibr" target="#b66">[67]</ref>. The chain is also adapted for different data properties <ref type="bibr" target="#b67">[68]</ref>. We discuss all those, next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The Terminal Distribution</head><p>A large discrepancy between the original distribution p(x 0 ) and the terminal distribution p(x T ) may lead to a suboptimal learning outcome for diffusion models. Through the chain of transitions, p(x T ) is determined by adding noise to the original distribution p(x 0 ) after T timesteps. Their discrepancy is usually significant because x T is full of noise with almost no original structures remaining <ref type="bibr" target="#b68">[69]</ref>. A denoising network is trained to overcome the discrepancy by transforming x T ∼ p(x T ) back to x 0 ∼ p(x 0 ). Consequently, such a large discrepancy may lead to inefficiencies and slow convergence of optimization in the reverse process. In other words, it may require more timesteps to correct this large discrepancy through the denoising network <ref type="bibr" target="#b69">[70]</ref>. The chain, instead, seeks to maintain as many structures of x 0 as possible in the terminal distribution to reduce the discrepancy, as shown in Figure <ref type="figure" target="#fig_4">5</ref>. An isotropic Gaussian distribution has no information about the given data samples despite its simplicity to use <ref type="bibr">[1]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Instead, other approaches typically consider the statistics of the training dataset like the mean and variance to indicate data structures <ref type="bibr" target="#b70">[71]</ref>. This mitigates the potential discrepancy and improves the convergence <ref type="bibr" target="#b66">[67]</ref>. Such directly involving statistics still requires prior knowledge on the exact formulation of the terminal distribution <ref type="bibr" target="#b68">[69]</ref>, <ref type="bibr" target="#b71">[72]</ref>. An extra network is thereby developed to learn the distribution p(x t ) at an earlier timestep t &lt; T and p(x t ) is then recognized as the new terminal distribution. As t &lt; T , more data structures remain in p(x t ) where less noise has been added <ref type="bibr" target="#b72">[73]</ref>. The network is often pre-trained to avoid optimizing jointly with the denoising network for an easier optimization <ref type="bibr" target="#b73">[74]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">The Systematic Method</head><p>The systematic method involves more than one chain of transitions in the generic pipeline. It becomes increasingly popular for its impressive performance and flexibility <ref type="bibr" target="#b74">[75]</ref>. Multiple chains are jointly applied on flexible inputs. For example, inputs may be a pair of data and its label <ref type="bibr" target="#b4">[5]</ref>, or the decomposed data in subspace <ref type="bibr" target="#b75">[76]</ref>. Figure <ref type="figure" target="#fig_5">6</ref> shows an example of using two transition chains on decomposed data. The systematic method has various benefits. It increases the expressive power by supporting multiple data components and types in the forward process. With more than one chains, the given samples can be decomposed into several components that are compatible with the the generic pipeline <ref type="bibr" target="#b76">[77]</ref>. This increases the expressiveness, and avoids inaccurate high-dimensional extrapolation and high computational cost <ref type="bibr" target="#b77">[78]</ref>. Moreover, transitions are feasible to apply different speeds of perturbations in the forward process based on their properties <ref type="bibr" target="#b78">[79]</ref>, <ref type="bibr" target="#b79">[80]</ref>. Different data types are also supported by the systematic method. For instance, discrete and continuous data are both transformed using two different transitions simultaneously <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b80">[81]</ref>. Additionally, the systematic method enables incorporating conditions by perturbing the given condition with an extra chain. For example, label vectors are perturbed and learned jointly with data <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b81">[82]</ref>. Sometimes domain knowledge becomes applicable if the systematic method is used. For example, statistical mechanics in physics is suitable for multiple transition chains leading to better performance <ref type="bibr" target="#b47">[48]</ref>.</p><p>Despite those advantages, the systematic method may require to change the equations of the forward process, and thus, the reverse process and the sampling procedure. The generic pipeline may need to be re-derived <ref type="bibr" target="#b13">[14]</ref>, which is usually more complicated <ref type="bibr" target="#b77">[78]</ref> for computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Data Properties</head><p>Generalizing diffusion models to a wide range of applications requires adaptations according to data properties <ref type="bibr" target="#b29">[30]</ref>. Data in tasks such as text generation and speech generation are represented with different types <ref type="bibr" target="#b82">[83]</ref>. Furthermore, the data manifold itself is different in some areas like scientific computing <ref type="bibr" target="#b83">[84]</ref>. Latent features are also important in large scale tasks for more compacted representations <ref type="bibr" target="#b84">[85]</ref>.</p><p>Different data types require adaptations of the transition chain. Essentially, different data types have varying characteristics. For instance, categorical data are represented as discrete distributions, while continuous data are modeled as arbitrary values <ref type="bibr" target="#b85">[86]</ref>, <ref type="bibr" target="#b86">[87]</ref>. Although both discrete and continuous data are compatible with diffusion models, their generic pipeline has an inductive bias of continuous data <ref type="bibr" target="#b13">[14]</ref>. The inherent data difference requires effort to adapt the transition chain to improve the modeling accuracy for different data types <ref type="bibr" target="#b70">[71]</ref>, <ref type="bibr" target="#b87">[88]</ref>. Some efforts focus on converting discrete data to continuous representations before they are calculated <ref type="bibr" target="#b88">[89]</ref>, <ref type="bibr" target="#b89">[90]</ref>. This is straightforward but accuracy may be lost. Others concentrate on re-designing the transitions with discrete distributions <ref type="bibr" target="#b67">[68]</ref>, <ref type="bibr" target="#b90">[91]</ref>, <ref type="bibr" target="#b91">[92]</ref> such as the Bernoulli distribution. Despite their superior performance, their derivations sometimes are task-specific and expensive to be adapted to other tasks.</p><p>Data manifolds also demand modifications of the transition chain in the generic pipeline. Apart from the commonly used Euclidean manifold, the Riemannian manifold is also explored for handling some scientific data <ref type="bibr" target="#b92">[93]</ref>. Riemannian manifold-based diffusion models are motivated by their ability to preserve geometric structures of the underlying data, which are important in many scientific fields <ref type="bibr" target="#b93">[94]</ref>. Riemannian manifold-based diffusion models have shown promising results in various applications such as medical imaging and neuroscience <ref type="bibr" target="#b94">[95]</ref>. Latent representation is another feasible choice for transitions, as illustrated in Figure <ref type="figure" target="#fig_6">7</ref>. Despite positive generation results achieved in the original space, the high dimensionality of data often leads to considerable computational cost and redundancy <ref type="bibr" target="#b95">[96]</ref>. Empirical evidence has shown that some transitions in diffusion models are responsible for learning latent representations, which are usually in low-dimensional space <ref type="bibr" target="#b96">[97]</ref> and semantically meaningful <ref type="bibr" target="#b97">[98]</ref>, <ref type="bibr" target="#b98">[99]</ref>. They implicitly learn semantically meaningful features <ref type="bibr" target="#b99">[100]</ref>. Mapping to latent space also enables multimodality <ref type="bibr" target="#b100">[101]</ref>. A pre-trained encoder is developed to map x 0 into latent code z 0 ahead of diffusion models and its corresponding decoder maps the generated latent code z 0 back to x 0 <ref type="bibr" target="#b101">[102]</ref>. Usually latent features are more densely represented by filtering less relevant information. Therefore, all the capacity of diffusion models are encouraged to learn more abstract, semantical relationships effectively <ref type="bibr" target="#b84">[85]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE REVERSE PROCESS</head><p>The reverse process focuses on training a denoising network to remove noise <ref type="bibr" target="#b102">[103]</ref>. The denoising network is configured by its network architecture <ref type="bibr" target="#b103">[104]</ref> and its output parameterizations <ref type="bibr" target="#b104">[105]</ref>. To train the configured network, optimization designs are also developed <ref type="bibr" target="#b56">[57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Network Architectures</head><p>U-Net <ref type="bibr" target="#b105">[106]</ref> and Transformer <ref type="bibr" target="#b106">[107]</ref> are two commonly adapted architectures for denoising networks <ref type="bibr" target="#b107">[108]</ref>. The denoising network is trained to realize the reverse transitions (Eq. 3). It is theoretically flexible to incorporate a wide variety of architectures that keep the dimensionality unchanged during all transitions <ref type="bibr" target="#b108">[109]</ref>, <ref type="bibr" target="#b109">[110]</ref>. Both U-Net and Transformer become increasingly popular for their high capacity on modelling complex relationships in a wide range of applications. While other architectures may also theoretically be compatible without changing dimensions like <ref type="bibr">GAN [111]</ref>, they are often adopted for task-specific purposes, e.g., adopting GAN for fast generation <ref type="bibr" target="#b52">[53]</ref>, and may not be generally applicable to other purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">U-Net</head><p>From a theoretical standpoint, U-Net is a U-shaped encoderdecoder architecture for general purpose. It was originally proposed for image segmentation <ref type="bibr" target="#b105">[106]</ref> and later was adapted to a large variety of tasks. Its encoder extracts highlevel features from data and usually contains downsampling layers to compress data. Its decoder leverages such features for different purposes and usually upsamples back to the original dimensionality of the data. This architecture forms an information bottleneck <ref type="bibr" target="#b111">[112]</ref> and encourages the network to learn features effectively. Therefore, U-Net has been adopted for a wide variety of tasks.</p><p>Various architecture modifications are applied to adapt U-Net as the denoising network. One implementation, known as PixelCNN++ <ref type="bibr" target="#b112">[113]</ref> based on a Wide ResNet <ref type="bibr" target="#b113">[114]</ref>, is adapted as the denoising network by replacing weight normalization <ref type="bibr" target="#b114">[115]</ref> with group normalization <ref type="bibr" target="#b115">[116]</ref> for learning efficiency <ref type="bibr" target="#b18">[19]</ref>. Cross-attention <ref type="bibr" target="#b116">[117]</ref> is introduced for higher capacity <ref type="bibr" target="#b117">[118]</ref>. Normalization layers are also explored as the conditions in diffusion models <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b57">[58]</ref>. Although various architecture modifications are implemented, the overall architecture of U-Net remains intact <ref type="bibr" target="#b118">[119]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Transformer</head><p>Transformer is also an encoder-decoder architecture. Both its encoder and decoder are featured by self-attention functions, which differentially measure the significance between all inputs regardless of their spatial locations <ref type="bibr" target="#b106">[107]</ref>. This enables to better capture global dependencies in many tasks.</p><p>Transformer is increasingly adapted as an alternative architecture for the denoising network. In principle, a transformer can directly substitute U-Nets because it can also maintain the data dimensions <ref type="bibr" target="#b119">[120]</ref>. Nevertheless, direct substitution empirically does not yield better quality because transformers are known to model global relations and may suffer from losing short-range dependency <ref type="bibr">[121]</ref>. Therefore, some U-Net structures are usually added to transformers to retain the benefits of U-Net as much as possible <ref type="bibr" target="#b121">[122]</ref>. For example, extra long skipping connections in U-Net also play a central role in transformer-based denoising networks <ref type="bibr" target="#b122">[123]</ref>. Despite these improvements, not all U-Net structures are essential. For example, the downsampling and up-sampling operators are not necessary for transformer-based denoising networks <ref type="bibr" target="#b122">[123]</ref>.</p><p>Transformer-based denoising networks also exhibit extra desirable properties when compared with U-Net architectures. For example, the transformer-based denoising network achieves comparable performance in conditional image generation <ref type="bibr" target="#b123">[124]</ref>, <ref type="bibr" target="#b124">[125]</ref>, and better quality with less network complexity in unconditional image generation task <ref type="bibr" target="#b125">[126]</ref>. Graph transformers are also explored to capture graph relationships <ref type="bibr" target="#b126">[127]</ref>. Transformers also encourage scalability <ref type="bibr" target="#b127">[128]</ref>, <ref type="bibr" target="#b128">[129]</ref>, and multi-modality <ref type="bibr" target="#b129">[130]</ref> in diffusion models. The transformer encoder is also separately adopted with other task-specific decoders in the denoising network. This is enabled by the disentanglement in an encoder-decoder structure <ref type="bibr" target="#b103">[104]</ref>. For example, a strong transformer encoder is used to achieve better performance in image generation <ref type="bibr" target="#b103">[104]</ref> and motion synthesis <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameterizations of the Reverse Mean</head><p>The output of the denoising network is applied to parameterize the reverse mean µ θ (x t , t) in the reverse transition (Eq. 3). Different parameterization ways all center on the estimation of the original data x 0 . Specifically, the true value of the reverse mean, denoted as µ(x t , t), is formulated as:</p><formula xml:id="formula_15">µ(x t , t) := √ ᾱt-1 (1 -ᾱt-1 )x t + √ ᾱt-1 (1 -α t )x 0 1 -ᾱt ,<label>(13)</label></formula><p>where x 0 is the original data but is unavailable during the reverse process. Therefore, x 0 needs to be estimated from the observed purturbed data x t and timestep t by the network. One parameterization way is to directly output the estimation x0 by the denoising network and replace x 0 with x0 in Eq. 13. An indirect parameterization way designs the denoising network to predict the noise εt , which is the residual between the unknown x 0 and the observed x t <ref type="bibr" target="#b18">[19]</ref>. Another indirect parameterization way is based on the probabilistic viewpoint and predicts the score ŝt via the denoising network. ŝt is the gradient that points towards the unknown x 0 from the current position x t in data space.</p><p>Combinations among aforementioned ways are also proposed for special tasks. Figure <ref type="figure" target="#fig_4">5</ref> shows a comparison of different outputs and their corresponding parameterization ways. Different outputs are equivalent to each other <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b58">[59]</ref>. Please refer to Section 2 in supplementary material for a detailed explanation on the equivalence. While essentially equivalent, different outputs as well as corresponding parameterizations show unique characteristics in particular aspects. Using x0 mainly supports better accuracy in the initial stage of the reverse process while εt is preferable in the late stage. Employing ŝt avoids computing the normalizing constant, which is a common problem in the context of distribution modelling. Combining the aforementioned ones provides the flexibility to retain their benefits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Data</head><p>Predicting the original data x 0 provides a straightforward denoising direction. x0 indicates a denoising goal towards which x t should be changed. In particular, given the observation x t at timestep t, the parameterization is defined as:</p><formula xml:id="formula_16">µ θ (x t , t) := √ ᾱt-1 (1 -ᾱt-1 )x t + √ ᾱt-1 (1 -α t )x 0 1 -ᾱt ,<label>(14)</label></formula><p>where α t indicates the noise level as defined in Section 2.2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 5</head><p>Visualization of parameterization ways. Outputs are the values predicted by a denoising network. The parameterization is the formulation to use the corresponding output in the reverse process.</p><p>Each visualization is about the corresponding output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output Parameterization Visualization</head><formula xml:id="formula_17">Data x0 µ θ (xt, t) := √ ᾱt-1 (1-ᾱt-1 )x t + √ ᾱt-1 (1-α t )x 0 1-ᾱt Score ŝt dx := f (x, t) -g 2 (t)ŝt dt + g(t)dw Noise εt µ θ (xt, t) := 1 √ α t xt - 1-α t √ α t (1-ᾱt ) εt Combination ĉt µ θ (xt, t) := C(x 0 , ŝt, εt) N/A</formula><p>Parameterizing with x0 is advantageous at the beginning of the sampling procedure, while it leads to inaccuracy when approaching the end of the sampling procedure. Empirical results show that the estimated mean µ θ (x t , t), which is parameterized by x0 , is closer to the ground truth µ(x t , t) at the beginning of the sampling procedure <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b130">[131]</ref>. This is because x0 helps the denoising network with an overall understanding of the global structure <ref type="bibr" target="#b23">[24]</ref>. On the contrary, when approaching the end of the sampling procedure where substantial structures have already been formed and only small noise artifacts need to be removed, finer details are difficult to be recovered <ref type="bibr" target="#b131">[132]</ref>. In other words, the information brought by x0 becomes less effectiveness in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Score</head><p>Score is the gradient of the logarithm of a distribution <ref type="bibr" target="#b44">[45]</ref>. The gradient indicates the most possible changes between two timesteps <ref type="bibr" target="#b132">[133]</ref>. Therefore, as shown in Figure <ref type="figure" target="#fig_7">8</ref>, denoising samples by the score forms a trajectory in data space <ref type="bibr" target="#b133">[134]</ref>. In particular, given the observed x t and timestep t, the predicted score is defined as ŝt := ∇ x log p(x t ) and the corresponding parameterization is the reverse SDE:</p><formula xml:id="formula_18">dx := f (x, t) -g 2 (t)ŝ t dt + g(t)dw,<label>(15)</label></formula><p>where f (x, t) and g(t) are the coefficients as previously introduced in Section 2.2.2. Predicting score in the reverse process avoids the estimation of the constant for normalizing the probabilistic distributions. Instead of representing a probability distribution by probability <ref type="bibr" target="#b134">[135]</ref>, score computes the gradient of the logarithm of a distribution. This avoids estimating the normalizing constant, which is computationally expensive or sometimes infeasible <ref type="bibr" target="#b135">[136]</ref>. In particular, the predicted distribution is usually defined as:</p><formula xml:id="formula_19">p θ (x) = exp -f θ (x) Z θ ,<label>(16)</label></formula><p>where Z θ &gt; 0 is a normalizing constant to be estimated so that p θ (x)dx = 1. Predicting score avoids this problem:</p><formula xml:id="formula_20">∇ x log p t (x),<label>(17)</label></formula><formula xml:id="formula_21">= -∇ x f θ (x) -∇ x log Z θ ,<label>(18)</label></formula><formula xml:id="formula_22">= -∇ x f θ (x),<label>(19)</label></formula><p>where ∇ x log Z θ = 0 as Z θ is a constant with respect to x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Noise</head><p>Noise estimation predicts the noise added in the forward process. Generally, the predicted noise is scaled according to the noise schedule and then subtracted from the observation <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b136">[137]</ref>, as shown in Figure <ref type="figure" target="#fig_8">9</ref>. In particular, given the observation at a current timestep, the prediction of noise is denoted as εt and the parameterization is defined as:</p><formula xml:id="formula_23">µ θ (x t , t) := 1 √ α t x t - 1 -α t α t (1 -ᾱt ) εt ,<label>(20)</label></formula><p>where α t indicates the noise level at timestep t as previously defined in Section 2.2.1. The consistent magnitude and residual effect of εt are advantageous. The fixed statistics of noise, e.g. εt ∼ N (0, I), lead to a consistent magnitude to be predicted. This encourages the learning of the denoising network <ref type="bibr" target="#b58">[59]</ref>. Besides, the residual effect to preserve the input x t in x t-1 is available by predicting zero noise <ref type="bibr" target="#b137">[138]</ref>. This becomes increasingly beneficial towards the end of the reverse process where only minor modifications are needed <ref type="bibr" target="#b131">[132]</ref>.</p><p>A large deviation between the ground truth noise ϵ t and the predicted noise εt may occur at the beginning of the sampling procedure, and is hard to be corrected in the following timesteps. The sampling procedure starts from samples with large noise, with almost no clue for the denoising network to predict noise accurately <ref type="bibr" target="#b18">[19]</ref>. This potentially leads to a deviation <ref type="bibr" target="#b131">[132]</ref>. The deviation is scaled up by the noise schedule in Eq. 20. The scheduled level of noise is usually large at the beginning of the sampling procedure. Even for a small noise estimation error, the deviation will be sharply enlarged. Moreover, the denoising network is limited to predicting noise, which has a residual effect in the noise-based parameterization. The magnitude of potential correction at each timestep is relatively small, and thereby more timesteps are required to correct such a deviation <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Combinations</head><p>Combining two or more predictions is also possible for task-specific benefits. Abstractly, the combination is denoted as ĉt := C(x 0 , ŝt , εt ) where C stands for a combination operator. Therefore, the parameterization is:</p><formula xml:id="formula_24">µ θ (x t , t) = ĉt . (<label>21</label></formula><formula xml:id="formula_25">)</formula><p>This has a wide variety of feasible implementations. The output to be combined and the combination operators can be very diverse <ref type="bibr" target="#b21">[22]</ref>. Velocity prediction is one example that linearly combines x0 and εt [139], which is designed as:</p><formula xml:id="formula_26">µ θ (x t , t) := α t εt -σ t x0 ,<label>(22)</label></formula><p>where α t and σ t are the scaling factor and noise schedule respectively. Such a combination has better stability in the task of distilling diffusion models <ref type="bibr" target="#b104">[105]</ref>. Combination is also used to avoid noise existing in x0 [140] or to achieve higher likelihood <ref type="bibr" target="#b140">[141]</ref>. Dynamically alternating between x0 and εt is found to accelerate the generation <ref type="bibr" target="#b131">[132]</ref>, <ref type="bibr" target="#b141">[142]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimization Designs</head><p>Many optimization designs on the learning objectives are developed to train the denoising network <ref type="bibr" target="#b142">[143]</ref>, with the reverse variance and the learning weight being the two main factors. The semantic information reflected by overall performance like fidelity and diversity strongly depends on the training procedure <ref type="bibr" target="#b143">[144]</ref>. Optimizing over the reverse variance assists the fitting of the denoising network. The learning weight controls the attention of learning priorities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">The Reverse Variance</head><p>Modelling the reverse variance improves the training efficiency of diffusion models. An appropriate variance minimizes the discrepancy between the predicted reverse transition p θ (x t-1 |x t ) and the forward transition p(x t |x t-1 ), fitting the forward process better <ref type="bibr" target="#b144">[145]</ref>. This facilitates less timesteps to be used, and improves overall efficiency. Many efforts to model the reverse variance are attempted. Some empirically adopt a handcrafted value for each timestep. The noise schedule is a popular option for its simplicity and empirical performance <ref type="bibr" target="#b145">[146]</ref>. Scaling the schedule by a factor is also researched but does not lead to a large difference <ref type="bibr" target="#b18">[19]</ref>. Both choices are considered as upper and lower bounds on reverse process entropy <ref type="bibr">[1]</ref>, and the interpolation between them is learned for flexibility <ref type="bibr" target="#b57">[58]</ref>. Others find the optimal variance can be solved analytically. Its formulation is explicitly derived from the predicted score <ref type="bibr" target="#b144">[145]</ref>, and improves the efficiency of generation <ref type="bibr" target="#b146">[147]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">The Learning Weight</head><p>Learning priorities are balanced by weights in the learning objective to enhance the learning quality. The change of learning priorities is common in deep learning <ref type="bibr" target="#b147">[148]</ref> and has also been observed in the reverse process <ref type="bibr" target="#b148">[149]</ref>, <ref type="bibr" target="#b149">[150]</ref>. Generally, a diffusion model learns features with semantic correspondence <ref type="bibr" target="#b150">[151]</ref>, <ref type="bibr" target="#b151">[152]</ref>. In other words, it pays more attention to global structures at the beginning of the reverse process <ref type="bibr" target="#b152">[153]</ref> and then changes to local details when approaching its end <ref type="bibr" target="#b153">[154]</ref>. Beside, it is shown to understand high-level phenomena like compositionality <ref type="bibr" target="#b154">[155]</ref>, <ref type="bibr" target="#b155">[156]</ref>, concepts <ref type="bibr" target="#b156">[157]</ref>, and geometry <ref type="bibr" target="#b157">[158]</ref>. A balance is achievable through adjusting weights and beneficial for training <ref type="bibr" target="#b158">[159]</ref>. Weights are usually related with the noise schedule. Directly using the schedule as the weight emphasizes a better learning of global structure by a larger learning weight at the beginning of the reverse process <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b159">[160]</ref>. While it is simple to use, the pre-defined schedule is not flexible and may deviate away from the actual demands. A function of the noise schedule such as the signal-to-noise (SNR) ratio is designed to compute the weights. The actual remaining noise is measured rather than the scheduled one <ref type="bibr" target="#b58">[59]</ref>. It takes the data into account and better balances the learning of local details and global structures <ref type="bibr" target="#b153">[154]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SAMPLING PROCEDURE</head><p>The sampling procedure in a diffusion model usually follows the transitions in the reverse process but uses a trained denoising network. It moves backwards on the chain and is responsible to transform a sample x T from a terminal distribution p(x T ) to generate new data x0 ∼ p θ * (x 0 ) ≈ p(x 0 ).</p><p>Conditional and fast generation are two focused areas of the sampling procedure in diffusion models. Without modelling conditions, diffusion models usually do not generate data of high quality when data are considered to follow a conditional distribution <ref type="bibr" target="#b160">[161]</ref>, <ref type="bibr" target="#b161">[162]</ref>, e.g., images from LSUN <ref type="bibr" target="#b162">[163]</ref> with ten scene categories are considered to follow a conditional distribution. Effective mechanisms of guidance are designed to modify transitions in the sampling procedure to be compatible with conditions. Moreover, the sampling procedure is several times slower when compared with other generative models <ref type="bibr" target="#b163">[164]</ref>, <ref type="bibr" target="#b164">[165]</ref>. The long generation time is mainly attributed to the large number of timesteps <ref type="bibr" target="#b65">[66]</ref>. Thus, designs for acceleration are explored to reduce timesteps without heavily impairing quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Guidance Mechanisms</head><p>A guidance mechanism modifies the denoising direction. It corrects the unconditional direction based on the given conditions <ref type="bibr" target="#b165">[166]</ref>, and thereby reduces the discrepancy between the modified and true conditional distributions <ref type="bibr" target="#b166">[167]</ref>, <ref type="bibr" target="#b167">[168]</ref>. The condition c ∈ C can be diverse, e.g., images <ref type="bibr" target="#b168">[169]</ref>, texts <ref type="bibr" target="#b169">[170]</ref>, or 2D poses <ref type="bibr" target="#b170">[171]</ref>. Without loss of generality, guidance is discussed using score as the output.</p><p>A wide variety of mechanisms are proposed to incorporate condition c with diffusion models. As temporal conditions, i.e. timesteps t, are inherently compatible with diffusion models <ref type="bibr" target="#b18">[19]</ref>, vanilla guidance extends them to incorporate c through operations such as addition <ref type="bibr" target="#b40">[41]</ref>. Despite its convenience, such a guidance mechanism is weak and sometimes is not working well to modify the denoising direction <ref type="bibr" target="#b23">[24]</ref>. To achieve effective and adjustable strength of conditions, classifier guidance leverages an extra pre-trained classifier to change the denoising direction <ref type="bibr" target="#b40">[41]</ref>. The strength is adjusted by scaling the change with a weight. Nonetheless, training a classifier on data with noise leads to extra cost and training instability <ref type="bibr" target="#b171">[172]</ref>. To avoid such problems, classifier-free guidance combines the vanilla guidance and unconditional model for guidance. Moreover, learning the modification as guidance instead of manually deriving the guidance is emerging for its flexibility <ref type="bibr" target="#b170">[171]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Vanilla Guidance</head><p>Vanilla guidance incorporates the given conditions c jointly with timesteps t as the guidance. A timestep t itself is inherently taken as a condition by a denoising network <ref type="bibr" target="#b172">[173]</ref>, <ref type="bibr" target="#b173">[174]</ref>. A variety of operations such as addition <ref type="bibr" target="#b174">[175]</ref>, <ref type="bibr" target="#b175">[176]</ref>, <ref type="bibr" target="#b176">[177]</ref>, <ref type="bibr" target="#b177">[178]</ref>, and attention layer <ref type="bibr" target="#b178">[179]</ref>, <ref type="bibr" target="#b179">[180]</ref>, <ref type="bibr" target="#b180">[181]</ref>, <ref type="bibr" target="#b181">[182]</ref> are available for this guidance mechanism. Figure <ref type="figure" target="#fig_10">11</ref> shows the condition is added to a timestep in this mechanism. While vanilla guidance is simple, its effectiveness is undermined by the lack of adjustable conditional strength <ref type="bibr" target="#b171">[172]</ref>. Empirical evidence shows that a conditional diffusion model trained with vanilla guidance may not conform to the conditions or under-perform in conditional generation <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Classifier Guidance</head><p>For effective and adjustable strength of conditions, an extra classifier with a weight is trained for classifier guidance. The gradient of the classifier is scaled by the weight and then is used to modify the unconditional denoising direction, as shown in Figure <ref type="figure" target="#fig_11">12</ref>. In other words, the weight controls how much to encourage the gradient-based modification <ref type="bibr" target="#b182">[183]</ref>. To obtain the gradient as accurate as possible, the classifier is trained on data with noise at each timestep. In particular, classifier guidance is formulated as:</p><formula xml:id="formula_27">∇ x log p(x|c) = ∇ x log p(x) + w∇ x log p(c|x), (<label>23</label></formula><formula xml:id="formula_28">)</formula><p>where ∇ x log p(x|c) and ∇ x log p(x) are conditional and unconditional scores, respectively, ∇ x log p(c|x) is the gradient of a classifier, and w is the weight. When w = 0, this mechanism becomes unconditional. As the weight increases, the denoising network is more and more constrained to produce samples that satisfy conditions. Classifier guidance provides control in a similar way of gradient-based adversarial attack. A sample is updated to satisfy the classifier by using the classifier gradient <ref type="bibr" target="#b183">[184]</ref>, <ref type="bibr" target="#b184">[185]</ref>, which is a similar way in gradient-based adversarial attack <ref type="bibr" target="#b185">[186]</ref>, <ref type="bibr" target="#b186">[187]</ref>. Such updates increases the probability of the sample for which the classifier assigns high likelihood to the correct label <ref type="bibr" target="#b187">[188]</ref>. Furthermore, different pre-trained classifiers can be applied in a plug-and-play manner <ref type="bibr" target="#b188">[189]</ref>. Additionally learning a classifier may lead to extra cost and training instability. The extra expense is further scaled up because the classifier is trained on data with every scheduled noise level <ref type="bibr" target="#b171">[172]</ref>. Moreover, training the classifier on data with noise tends to be unstable <ref type="bibr" target="#b189">[190]</ref>, <ref type="bibr" target="#b190">[191]</ref>. The data structure is almost destroyed because more and larger noise is added according to the noise schedule. Therefore, the quality of classifier gradient may not be consistent <ref type="bibr" target="#b191">[192]</ref>. Sometimes its direction is arbitrary or even opposite <ref type="bibr" target="#b192">[193]</ref>, <ref type="bibr" target="#b193">[194]</ref> and leads to less effective or wrong guidance <ref type="bibr" target="#b194">[195]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Classifier-Free Guidance</head><p>To avoid the extra classifier, classifier-free guidance replaces the classifier by a mixture of unconditional model and vanilla guidance. It encourages the model in the direction of guidance and simultaneously discourages away from unconditional direction <ref type="bibr" target="#b195">[196]</ref>. As shown in Figure <ref type="figure" target="#fig_12">13</ref>, instead of training two models, a conditional model and an unconditional one are formulated uniformly by dropping out conditions c with a probability p <ref type="bibr" target="#b171">[172]</ref>. The two models are learned jointly as if they were a singular conditional model <ref type="bibr" target="#b23">[24]</ref>. In particular, classifier-free guidance is formulated as:</p><formula xml:id="formula_29">∇ x log p(x|c) = w∇ x log p(x|c) + (1 -w)∇ x log p(x), (<label>24</label></formula><formula xml:id="formula_30">)</formula><p>where w is the weight of conditions. The weight is slightly different from its counterpart in classifier guidance. When w = 0, the classifier-free guidance becomes unconditional models without vanilla guidance. The vanilla guidance is a special case when w = 1. In this case, the unconditional model is suppressed and conditions are incorporated through vanilla guidance <ref type="bibr" target="#b37">[38]</ref>. If w &gt; 1, the classifier-free guidance restrains the unconditional model and prioritizes conditions further by larger weights. The score from classifier-free guidance deviates quickly away from the unconditional score, and thus, samples that better satisfy the conditions will be generated <ref type="bibr" target="#b196">[197]</ref>.</p><p>Instead of removing classifiers, self-guidance <ref type="bibr" target="#b165">[166]</ref> reduces or removes the requirement of annotation by using internal values like activations, attention maps, and intermediate representations <ref type="bibr" target="#b197">[198]</ref>, <ref type="bibr" target="#b198">[199]</ref> to compute guidance. Such design helps finer-grained control and is compatible with aforementioned guidance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Learned Modifications</head><p>Modifications for guidance can be learned for more flexibility. A network is deployed to directly learning the modification on the output of unconditional networks <ref type="bibr" target="#b199">[200]</ref>. Thus, it is more flexible than the aforementioned ones because of fewer manual designs. For example, a pre-trained unconditional denoising network is commonly augmented by its identically copied network including the parameters. The outputs from the two networks are usually added and other complex operations are also possible. During training, only the copied network is updated to automatically learn suitable modifications to correct the output from the pretrained network. Although fixing the original network and copying its parameters to the identical one avoid completely retraining, learning the copied network may still be difficult due to the larger number of parameters <ref type="bibr" target="#b200">[201]</ref>. Nevertheless, this flexibility greatly encourages the pursuit of unified and multi-modality guidance <ref type="bibr" target="#b201">[202]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Acceleration Designs</head><p>Reducing the number of timesteps for generation is the main goal of acceleration. Generally, the denoising network needs to wait the results from the timestep t + 1 to accomplish the transition at the current timestep t <ref type="bibr" target="#b65">[66]</ref>. The inference speed is significantly slowed down especially when a large number of timesteps are required in the sampling procedure <ref type="bibr" target="#b52">[53]</ref>. Efforts have been contributed to reduce the timesteps. Truncation directly cuts the sampling procedure at a certain timestep <ref type="bibr" target="#b73">[74]</ref>. Knowledge distillation is adopted to learn a student model that has fewer timesteps in its sampling procedure <ref type="bibr" target="#b202">[203]</ref>. Selection strategies are also developed to select a subset of timesteps for fast generation <ref type="bibr" target="#b65">[66]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Truncation</head><p>Truncation involves a partial sampling procedure with an extra network. It usually selects an intermediate timestep t ′ , and obtains a sample from the corresponding distribution p(x t ′ ) for the generation <ref type="bibr" target="#b203">[204]</ref>, as shown in Figure <ref type="figure" target="#fig_14">15</ref>. In other words, the process truncates the whole chain at t ′ , and thereby fewer timesteps remain in the partial chain <ref type="bibr" target="#b204">[205]</ref>. An extra network needs to be additionally trained to model p(t ′ ) that may not be tractable <ref type="bibr" target="#b18">[19]</ref>. Overall, truncation is theoretically effective in acceleration <ref type="bibr" target="#b69">[70]</ref>, which is proved by the stochastic contraction theory <ref type="bibr" target="#b205">[206]</ref>. Truncation effects can be two-sided. One the one hand, truncation comes with several benefits. Not only inference, but also training can be accelerated <ref type="bibr" target="#b72">[73]</ref> as both the forward and reverse processes do not require computation at these truncated timesteps. Truncation also strikes a balance between acceleration and quality. It has an adaptable intercepting point to balance the generation quality and efficiency. The selection of such a point depends on the data complexity <ref type="bibr" target="#b72">[73]</ref> and the degree of corruptions <ref type="bibr" target="#b69">[70]</ref>. Besides, truncation takes advantage of the properties of the involved extra network, which is often another generative model <ref type="bibr" target="#b73">[74]</ref>. On the other hand, truncation may lead to an increased training expense because the extra network needs to learn p(t ′ ) as accurately as possible <ref type="bibr" target="#b73">[74]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Knowledge Distillation</head><p>Knowledge distillation is a network compression technique. It involves compressing an expensive but high-performing teacher model into a smaller student model <ref type="bibr" target="#b206">[207]</ref>. After the training, the student network can perform as well as the teacher with a smaller model size.</p><p>The same idea is applied to learn a new sampling procedure with fewer timesteps. In terms of diffusion models, it involves the original sampling procedure as the teacher model and a new one with fewer timesteps as the student model <ref type="bibr" target="#b207">[208]</ref>, <ref type="bibr" target="#b208">[209]</ref>. Figure <ref type="figure" target="#fig_15">16</ref> shows an example method of progressive distillation on the sampling procedure. Knowledge distillation is applied to merge several time steps into one single time step for the new sampling procedure. Directly distilling all timesteps in the teacher sampling procedure into a single timestep in the student one, theoretically reduces significantly generation time <ref type="bibr" target="#b209">[210]</ref>, <ref type="bibr" target="#b210">[211]</ref>. However, this relies on collecting a large dataset of samples from the teacher model for knowledge distillation, which itself is computationally expensive <ref type="bibr" target="#b211">[212]</ref>, <ref type="bibr" target="#b212">[213]</ref>. One popular observation is that the number of timesteps can be progressively reduced <ref type="bibr" target="#b104">[105]</ref>. For example, after the student sampling procedure is trained to merge two timesteps in the teacher sampling procedure, it becomes the teacher, and a new student procedure is trained to further reduce the number of sampling steps <ref type="bibr" target="#b213">[214]</ref>. Bootstrapping is another way to reduce the high demand of training data <ref type="bibr" target="#b214">[215]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Selection Strategies</head><p>Many strategies are developed to select a subset of timesteps without undermining quality, and thereby form a shorter sampling procedure <ref type="bibr" target="#b215">[216]</ref>, <ref type="bibr" target="#b216">[217]</ref>. Timesteps around the end of the sampling procedure influence quality less, and they are often dropped out <ref type="bibr" target="#b217">[218]</ref>. Figure <ref type="figure" target="#fig_16">17</ref> shows a shorter sampling procedure with selected timesteps. Some may not directly reduce the number of timesteps but select a subset of timesteps for parallel computation <ref type="bibr" target="#b218">[219]</ref>. In this way, each single processor deals with fewer timesteps.</p><p>Applying differential equation solvers is a popular strategy for those with continuous formulations. They are usually based on well-established mathematical solvers to handle adaptive step sizes and noise schedules. As a continuous formulation itself is based on SDEs, such solvers are straightforward to be adopted. Many existing SDE solvers are available for the sampling procedure like stochastic Runge-Kutta solver <ref type="bibr" target="#b4">[5]</ref>, Diffusion Exponential Integrator Sampler (DEIS) <ref type="bibr" target="#b219">[220]</ref>, and It ô-Taylor Sampling by higherorder numerical schemes <ref type="bibr" target="#b220">[221]</ref>. Solvers do not necessarily select timesteps uniformly <ref type="bibr" target="#b163">[164]</ref>. Dynamic step size is used in the Euler-Maruyama (EM) solver <ref type="bibr" target="#b4">[5]</ref>. The selection sometimes also brings improvement on quality <ref type="bibr" target="#b221">[222]</ref>. More general strategies are also developed for both formulations. They sometimes also modify the forward and reverse processes for fast inference, leading to retraining diffusion models. Some strategies leverage particular mathematical tools for acceleration. A non-Markovian reverse process is proposed for few-step sampling <ref type="bibr" target="#b145">[146]</ref>, which theoretically is equivalent with the probability flow sampler <ref type="bibr" target="#b4">[5]</ref>. An exact analytical solution of diffusion models are derived but stochasticity is sacrificed <ref type="bibr" target="#b222">[223]</ref>. A Taylor expansion process is applied to disregard non-contributory diffusion steps <ref type="bibr" target="#b223">[224]</ref>. Others rely on extra networks or algorithms for fast sampling. Some strategies conduct modifications based on noise schedules. If continuous noise levels are used, an extra network is used to adjust the noise levels of a fewstep discrete time reverse diffusion process <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b224">[225]</ref>. The selection of timesteps is directly learned by extra networks <ref type="bibr" target="#b225">[226]</ref>, <ref type="bibr" target="#b226">[227]</ref>. A Dynamic Programming algorithm <ref type="bibr" target="#b227">[228]</ref> was also designed to reduce the number of timesteps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">FUTURE TRENDS</head><p>We provide our insights on emerging or important trends in this field to encourage more studies in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Theory</head><p>The theory of diffusion models can inspire significant future research. Diffusion models are heavily based on mathematical formulations <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b228">[229]</ref>, which facilitate future improvements from mathematical perspectives. For example, deriving new formulations for destroying data dimensions <ref type="bibr" target="#b229">[230]</ref> leads to a generalized diffusion model. Building connections with well-established fields is also beneficial to achieve better understanding on the theory of diffusion models <ref type="bibr" target="#b230">[231]</ref>, <ref type="bibr" target="#b231">[232]</ref>, <ref type="bibr" target="#b232">[233]</ref>, <ref type="bibr" target="#b233">[234]</ref>. Explainable techniques can also assist with understanding on theories of diffusion models <ref type="bibr" target="#b234">[235]</ref>, <ref type="bibr" target="#b235">[236]</ref>. Besides, the success of diffusion models highlights the virtue of auto-regressive generation where a self-correction mechanism is enabled to achieve better quality <ref type="bibr" target="#b236">[237]</ref>, <ref type="bibr" target="#b237">[238]</ref>, <ref type="bibr" target="#b238">[239]</ref>. This will contributes to the theoretical designs of generative models in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Architecture</head><p>The improvement of the architecture in diffusion models has a lot of future potential. Current backbones of denoising networks are mainly U-Net <ref type="bibr" target="#b18">[19]</ref> and Transformer <ref type="bibr" target="#b123">[124]</ref>. They have achieved impressive results but still have inherent drawbacks in some applications. At the same time, a wide variety of well-established network architectures are available in machine learning with appealing advantages. Applying and adapting these network architectures as the denoising network will introduce additional benefits and unleash the potential for diffusion models <ref type="bibr" target="#b109">[110]</ref>, <ref type="bibr">[240]</ref>. Compression of the architecture with fewer parameters is actively being researched <ref type="bibr" target="#b240">[241]</ref>. The conditional mechanism is also developing fast for multi-grained guidance. Besides the backbone choice, the optimization is also a promising avenue. Deeper understanding on the model behaviours has been proposed as more experiments are conducted and more theories are developed <ref type="bibr" target="#b23">[24]</ref>. For example, the strategy of reinforcement learning has been explored to train diffusion models <ref type="bibr" target="#b241">[242]</ref> These understandings facilitate improving the training speed and efficiency in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Data</head><p>Developing data-efficient diffusion models is an important future trend. Conventionally, diffusion models implicitly assume abundant data to train on, especially labelled data for conditional models <ref type="bibr" target="#b242">[243]</ref>, <ref type="bibr" target="#b243">[244]</ref>. This assumption may be violated when acquiring data is expensive or sometimes impossible. Some research explores to improve the training on low quality data <ref type="bibr" target="#b244">[245]</ref>, <ref type="bibr" target="#b245">[246]</ref>, <ref type="bibr" target="#b246">[247]</ref>. Other research is seeking to combine few-shot learning to efficiently leverage the limited data for training <ref type="bibr" target="#b247">[248]</ref>, <ref type="bibr" target="#b248">[249]</ref>. Several pioneering explorations also consider one-shot <ref type="bibr" target="#b249">[250]</ref>, <ref type="bibr" target="#b250">[251]</ref> and zeroshot <ref type="bibr" target="#b251">[252]</ref>, <ref type="bibr" target="#b252">[253]</ref> learning with diffusion models, further reducing the dependency on abundant training data <ref type="bibr" target="#b253">[254]</ref>. These attempts highlight the possibility of applying diffusion models in the absence of data. Besides, changing the way of supervision will be helpful to train conditional models with limited labelled data. Currently, the unsupervised <ref type="bibr" target="#b254">[255]</ref>, self-supervised <ref type="bibr" target="#b255">[256]</ref> or semi-supervised <ref type="bibr" target="#b256">[257]</ref> manners have been explored to train conditional diffusion models. They have shown encouraging results in different areas and will facilitate future exploration in the absence of labelled data. Their success also indicates future opportunities of applying alternative supervision schemes like weakly supervised <ref type="bibr" target="#b257">[258]</ref> learning to conditional diffusion models.</p><p>Supporting multiple data modalities in a diffusion model also has broad prospects. Incorporating information from several modalities will greatly promote the generative power and applicable flexibility of diffusion models <ref type="bibr" target="#b129">[130]</ref>. Currently, many efforts focus on two modalities, usually leveraging text as an extra modality in addition to the data of interest <ref type="bibr" target="#b258">[259]</ref>, <ref type="bibr" target="#b259">[260]</ref>. Initial attempts have also supported other modalities from a wide variety like human pose for the guidance in conditional diffusion models <ref type="bibr" target="#b170">[171]</ref>. In the future, exploring other modalities is still worth more efforts for better flexibility. More importantly, finding an incorporation for three or more data modalities to be mixed in a single diffusion model is another potential boost for their generative power <ref type="bibr" target="#b260">[261]</ref>, <ref type="bibr" target="#b261">[262]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Applications</head><p>A wider range of applications beyond generation are promising. Since diffusion models were proposed, they have been applied in a large variety of tasks <ref type="bibr" target="#b262">[263]</ref> because of their powerful generative ability <ref type="bibr" target="#b263">[264]</ref>. For example, diffusion models are recently applied in policy representation in reinforcement learning <ref type="bibr" target="#b264">[265]</ref>, neural architecture searching <ref type="bibr" target="#b265">[266]</ref>, offline black-box optimization <ref type="bibr" target="#b266">[267]</ref>, and named entity recognition <ref type="bibr" target="#b267">[268]</ref>. Data generated by diffusion models are also employed as the proxy for training new models when the original data are limited <ref type="bibr" target="#b268">[269]</ref>, <ref type="bibr" target="#b269">[270]</ref>. Adapting pretrained diffusion models to another domain is also popular, e.g., applying an image model for video generation <ref type="bibr" target="#b270">[271]</ref>. Recent advances on diffusion models have also witnessed significant increase of successful interdisciplinary applications, especially AI for Science (AI4Science) <ref type="bibr" target="#b271">[272]</ref>. Diffusion models have increasingly been combined with Physics <ref type="bibr" target="#b272">[273]</ref>, <ref type="bibr" target="#b273">[274]</ref>, Chemistry <ref type="bibr" target="#b274">[275]</ref>, <ref type="bibr" target="#b275">[276]</ref>, etc. They are not only applying and adapting diffusion models to solve problems in these domains, but also leveraging knowledge in a disciplinary to theoretically improve diffusion models <ref type="bibr" target="#b276">[277]</ref>, <ref type="bibr" target="#b277">[278]</ref>, <ref type="bibr" target="#b278">[279]</ref>. Expanding the application scenarios of diffusion models will bring more opportunities to both academic and industrial fields.</p><p>Diffusion models are also actively investigated for or against adversarial attack. Diffusion models themselves are analysed against adversarial attack, which is usually measured by robustness. Diffusion models with higher robustness can work vigorously and consistently <ref type="bibr" target="#b279">[280]</ref>. Some are vulnerable to backdoor injection <ref type="bibr" target="#b280">[281]</ref>. Developing diffusion models with higher robustness have attracted more and more public attention to defend adversarial attacks <ref type="bibr" target="#b281">[282]</ref>, <ref type="bibr" target="#b282">[283]</ref>, <ref type="bibr" target="#b283">[284]</ref>. Diffusion models are also deployed to help other systems with defending adversarial attacks [285], <ref type="bibr" target="#b285">[286]</ref>, <ref type="bibr" target="#b286">[287]</ref>, <ref type="bibr" target="#b287">[288]</ref>. They are also employed to generate adversarial samples for attacking <ref type="bibr" target="#b288">[289]</ref>, <ref type="bibr" target="#b289">[290]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Societal Impacts</head><p>Despite many successful applications, the potential misuse of diffusion models needs to be regulated. Benefiting from academic and industrial efforts, diffusion models become more and more powerful to produce synthetic data, which may be increasingly difficult to be distinguished by realworld data. While synthetic data reduces the cost of obtaining real data in some fields, such an ability may be abused with harmful societal impacts <ref type="bibr" target="#b290">[291]</ref>. For example, misinformation and spam can be spread via manipulated data <ref type="bibr" target="#b291">[292]</ref>, <ref type="bibr" target="#b292">[293]</ref>. Distinguishing these manipulated data becomes more expensive and even more difficult <ref type="bibr" target="#b293">[294]</ref>. As training a large diffusion model requires high cost, the intellectual property of such models should also be protected <ref type="bibr" target="#b294">[295]</ref> as well as copyright of training data <ref type="bibr" target="#b295">[296]</ref>. This requires continuous investment of efforts on techniques and policies as diffusion models are also swiftly developing.</p><p>Pre-trained diffusion models may have a risk of data leakage. A concern of data privacy is quickly getting public attention by the possibility of recovering the training data from pre-trained diffusion models <ref type="bibr" target="#b296">[297]</ref>, <ref type="bibr" target="#b297">[298]</ref>. Diffusion models are prone to memorize training samples from simpler, smaller datasets <ref type="bibr" target="#b143">[144]</ref>. Such data may contain confidential/personal information <ref type="bibr" target="#b298">[299]</ref>, <ref type="bibr" target="#b299">[300]</ref>. Training on privacysensitive data requires additional safety considerations <ref type="bibr" target="#b300">[301]</ref> and efforts in the future <ref type="bibr" target="#b301">[302]</ref>, <ref type="bibr">[303]</ref>.</p><p>Reproducing or exacerbating biases by diffusion models is another concern. Diffusion models can be biased in data generation for various reasons such as biased datasets <ref type="bibr" target="#b303">[304]</ref>, <ref type="bibr" target="#b304">[305]</ref>. They are found prone to replicating their training data because such data usually have higher likelihoods <ref type="bibr" target="#b305">[306]</ref>, <ref type="bibr" target="#b306">[307]</ref>. This preference may lead to a systemically biased model when the training data themselves have bias <ref type="bibr" target="#b307">[308]</ref>. Biased models will bring users with unfair stereotypes on some concepts and lead to harmful societal impacts <ref type="bibr" target="#b308">[309]</ref>. For example, a diffusion model trained for face generation with FFHQ dataset <ref type="bibr" target="#b309">[310]</ref> (whose data are collected mainly from people between the ages of 21 and 40) will also be more inclined to generate results from that age group and less supportive of other age groups. More efforts are required in the future to encourage fair and unbiased diffusion models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Diffusion models are an emerging type of deep generative models involving three main components: a forward process and a reverse process for optimization, and a sampling procedure for generation. Diffusion models become popular for their high-quality results in various tasks. The success of diffusion models is closely related with various design fundamentals of the three components. The forward process focuses on perturbing p(x 0 ) to p(x T ) by gradually adding noise to x 0 by p(x t |x t-1 ). It is designed based on noise injection and the multi-step chain of transitions. The reverse process focuses on training a denoising network to remove noise. The reverse process includes network-related and optimization-related choices. The sampling procedure uses the trained denoising network for generation and mainly focuses on guidance and acceleration. To achieve conditional generation and fast sampling, guidance and acceleration techniques are designed for the sampling procedure. These designs have all contributed to the current powerful diffusion models. Several future trends that are emerging and important have been introduced to boost this field.</p><p>On the Design Fundamentals of Diffusion Models: A Survey -Supplementary Material Ziyi Chang, George Koulieris, Hubert P. H. Shum, Senior Member, IEEE ✦</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">DERIVATION OF THE FORWARD PROCESS</head><p>According to the definition of diffusion process, we have:</p><formula xml:id="formula_31">x t = √ α t x 0 + β t ϵ t<label>(1)</label></formula><p>where each ϵ t is an i.i.d. standard Gaussian. Then, by recursion, we have: </p><formula xml:id="formula_32">x t = √ α t α t-</formula><formula xml:id="formula_33">+ α t β t-1 ϵ t-1 + β t ϵ t • • • = √ ᾱt x 0 + α t α t-1 • • • α 2 β 1 ϵ 1 + • • • + α t β t-1 ϵ t-1 + β t ϵ t .<label>(2)</label></formula><p>As a result, q(x t |x 0 ) is still Gaussian. Its mean vector is √ ᾱt x 0 , and its covariance matrix is (α t α t-1 • • • α 2 β 1 + • • • + α t β t-1 + β t )I = (1ᾱt )I. Formally, we have:</p><formula xml:id="formula_34">x t = √ ᾱt x 0 + √ 1 -ᾱt ϵ t ,<label>(3)</label></formula><p>and in a probabilistic perspective:</p><p>q(x t |x 0 ) = N (x t ; √ ᾱt x 0 , (1ᾱt )I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROOF OF EQUIVALENT OUTPUTS</head><p>For completeness, we provide the proof of equivalent output representations. The original one can be found in <ref type="bibr">[1]</ref>.</p><p>The distribution formulation of q(x t |x 0 ) can be explicitly written as:</p><formula xml:id="formula_36">x t = √ ᾱt x 0 + √ 1 -ᾱt ϵ t ,<label>(5)</label></formula><p>and can be reorganized as:</p><formula xml:id="formula_37">x 0 = x t - √ 1 -ᾱt ϵ 0 √ ᾱt ,<label>(6)</label></formula><p>where x 0 is dependent on ϵ t when x t is given. This allows to predict ϵ t for an indirect estimation of x 0 . Therefore, we have:</p><formula xml:id="formula_38">x0 = x t - √ 1 -ᾱt ε0 √ ᾱt ,<label>(7)</label></formula><p>which shows the equivalence of predicting x 0 and ϵ t .</p><p>• The authors are with the Department of Computer Science, Durham University, Durham, DH1 3LE, United Kingdom. • Email: {ziyi.chang, georgios.a.koulieris, hubert.shum}@durham.ac.uk • Corresponding author: Hubert P. H. Shum Mathematically, the Tweedie's Formula for a Gaussian variable states that:</p><formula xml:id="formula_39">E[µ z |z] = z + Σ z ∇ z log p(z),<label>(8)</label></formula><p>where µ z and Σ z is the mean and variance of z, respectively. Taking DDPM as an example, we know its mean is:</p><formula xml:id="formula_40">µ xt = √ ᾱt x 0 ,<label>(9)</label></formula><p>and its variance is:</p><formula xml:id="formula_41">Σ xt = 1 -ᾱt .<label>(10)</label></formula><p>Then, by Tweedie's Formula, we have</p><formula xml:id="formula_42">√ ᾱt x 0 = x t + (1 -ᾱt )∇ xt log p(x t ),<label>(11)</label></formula><p>where x 0 is dependent on the score ∇ xt log p(x t ). Therefore, if the estimation of the score derives an estimation of x 0 :</p><formula xml:id="formula_43">x0 = x t + (1 -ᾱt )∇ x log p(x t ) √ ᾱt . (<label>12</label></formula><formula xml:id="formula_44">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EQUIVALENT OPTIMIZATION OBJECTIVES</head><p>For completeness, we provide the proof of equivalent optimization of two objectives. The original proof can be found in the Appendix of <ref type="bibr">[2]</ref>. Diffusion models should have been optimised by the unconditional form:</p><formula xml:id="formula_45">J uncon (θ) = E qσ(x) [||s θ (x) - ∂ log q σ (x) ∂ x || 2 ],<label>(13)</label></formula><p>where s θ is the prediction of our network with learnable parameters θ. However, they are usually optimized by the conditional form:</p><formula xml:id="formula_46">J con (θ) = E qσ(x,x) [||s θ (x) - ∂ log q σ (x|x) ∂ x || 2 ].<label>(14)</label></formula><p>We can prove that J uncon (θ) = J con (θ) -C 2 + C 1 where C 1 and C 2 are both constants that do not depend on θ.</p><p>Given the unconditional form J uncon (θ):</p><formula xml:id="formula_47">J uncon (θ) = E qσ(x) [||s θ (x) - ∂ log q σ (x) ∂ x || 2 ], = E qσ(x) [||s θ (x)|| 2 ] -2φ(θ) + C 1 ,<label>(15)</label></formula><p>where</p><formula xml:id="formula_48">C 1 = E qσ(x) [|| ∂ log qσ(x) ∂ x</formula><p>|| 2 ] is a constant that does not depend on θ and φ(θ) = E qσ(x) [&lt; s θ (x), ∂ log q σ (x) ∂</p><p>x &gt;],</p><p>= x q σ (x) &lt; s θ (x), ∂ log q σ (x) ∂ x &gt; dx, = x q σ (x) &lt; s θ (x), ∂qσ(x) ∂ x q σ (x) &gt; dx,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=</head><p>x &lt; s θ (x),</p><formula xml:id="formula_49">∂q σ (x) ∂ x &gt; dx, = x &lt; s θ (x), ∂ x q 0 (x)q σ (x|x)dx ∂ x &gt; dx, = x &lt; s θ (x), x q 0 (x) ∂q σ (x|x)dx ∂ x &gt; dx, = x &lt; s θ (x),</formula><p>x q 0 (x)q σ (x|x) ∂ log q σ (x|x)dx ∂ x &gt; dx,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=</head><p>x x q 0 (x)q σ (x|x) &lt; s θ (x), ∂ log q σ (x|x)</p><formula xml:id="formula_50">∂ x &gt; dxdx, = x x q σ (x, x) &lt; s θ (x), ∂ log q σ (x|x) ∂ x &gt; dxdx, = E qσ(x,x) [&lt; s θ (x), ∂ log q σ (x|x) ∂ x &gt;].<label>(16)</label></formula><p>Therefore, the unconditional form can be written as follows:</p><formula xml:id="formula_51">J uncon (θ) =E qσ(x) [||s θ (x)|| 2 ] -2E qσ(x,x) [&lt; s θ (x), ∂ log q σ (x|x) ∂ x &gt;] + C 1 .<label>(17)</label></formula><p>At the same time, the conditional form can be written as:</p><formula xml:id="formula_52">J con (θ) =E qσ(x,x) [||s θ (x) - ∂ log q σ (x|x) ∂ x || 2 ] =E qσ(x) [||s θ (x)|| 2 ] -2E qσ(x,x) [&lt; s θ (x), ∂ log q σ (x|x) ∂ x &gt;] + C 2 ,<label>(18)</label></formula><p>where</p><formula xml:id="formula_53">C 2 = E qσ(x,x) [|| ∂ log qσ(x|x) ∂ x || 2 ].</formula><p>In conclusion, the two objectives are equivalent in optimising θ because</p><formula xml:id="formula_54">J uncon (θ) = J con (θ) -C 2 + C 1 .<label>(19)</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Nθ</head><label></label><figDesc>(x; µ, Σ) Variable x follows the Gaussian distribution with mean µ and variance Σ Distribution p(x 0 ) Original distribution at timestep 0 p(xt) Perturbed distribution at timestep t p(x T ) Terminal distribution, i.e., data distribution at timestep T Parameters in denoising network θ * Optimal parameters in denoising network p θ (•) Predicted distribution by denoising network p(xt|x t-1 ) Forward transition p θ (x t-1 |xt) Reverse transition p θ * (x t-1 |xt) Sampling transition ∇x log p(•) Score, i.e., gradient of a log distribution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The forward process perturbs the original unknown distribution by gradually adding noise to a given set of data samples through a chain of distribution transitions with multiple time steps. Each time step of the chain is denoted by a circle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The reverse process trains a neural network θ to recursively remove the noise that has been previously added by the forward process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The sampling procedure uses the trained denoising network θ * and usually follows the same transitions as the reverse process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. The transition chain no longer seek an isotropic Gaussian distribution as the terminal distribution. The grey, dashed parts represent that the transition no longer approaches the isotropic Gaussian distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig.6. A systematic method allows the forward process to separately transform the original data in orthogonal subspace.</figDesc><graphic coords="6,54.30,185.75,239.40,67.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7. The transition chain in a latent space. ψ * is a pre-trained encoder. Data are no longer manipulated in the original space (dashed, grey). They are now transformed within the latent space (rounded rectangle).</figDesc><graphic coords="6,324.60,311.50,226.80,91.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Visualization of the trajectory by predicting score. A score is a direction for next timesteps. Samples are denoised in the direction at each position. Colors represent trajectories of different samples.</figDesc><graphic coords="8,73.20,575.44,201.60,96.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Visualization of the noise-based parameterization. means εt has a subtractive relationship with xt, and means this results in x t-1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Learning priority changes in the reverse process, which is denoted by different colours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Vanilla guidance merges the condition c with the denoising network θ * by adding to each timestep t.</figDesc><graphic coords="10,54.30,269.39,239.40,57.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Classifier guidance leverages an extra classifier network ξ * to compute a gradient ∇ as the modification on the denoising network θ * . The timestep condition t is omitted here for visualization.</figDesc><graphic coords="10,318.30,43.70,239.39,71.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Classifier-free guidance is based on a mixture of vanilla guidance and unconditional model θ * . A probability p controls whether to drop out the conditions during training.</figDesc><graphic coords="10,318.30,480.87,239.40,66.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 14 .</head><label>14</label><figDesc>Fig. 14. Applying an extra network ϑ to directly learn the required modification for guidance. Timestep condition is omitted here.</figDesc><graphic coords="11,54.30,325.18,239.40,68.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. The sampling procedure is truncated and starts from a selected timestep. The grey, dashed parts represent discarding for generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Knowledge distillation learns student denoising networks δ and η with fewer timesteps, based on the teacher denoising network θ * .</figDesc><graphic coords="11,318.30,458.56,239.40,108.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Selection strategies for the sampling procedure skip the selected time steps for generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 Notations</head><label>1</label><figDesc></figDesc><table /><note><p>and terminologies.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2</head><label>2</label><figDesc>Figure legends.</figDesc><table><row><cell>Notations</cell><cell>Meaning</cell></row><row><cell></cell><cell>Trainable network with parameters</cell></row></table><note><p>θ Fixed network with parameters ξ * Component not in use Data distributions The distribution at a timestep Condition c Timestep t</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3</head><label>3</label><figDesc>Comparison of several streams of noise schedules.</figDesc><table><row><cell>Noise Schedule</cell><cell>Visualization</cell></row><row><cell>Linear [19]</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 4 Comparison</head><label>4</label><figDesc></figDesc><table /><note><p>of several streams of noise types.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>1 x t-2 + α t β t-1 ϵ t-1 + β t ϵ t = √ α t α t-1 α t-2 x t-3 + α t α t-1 β t-2 ϵ t-2</figDesc><table /></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Palette: Image-to-image diffusion models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Hierarchical text-conditional image generation with clip latents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cascaded diffusion models for high fidelity image generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="47" to="48" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Score-based generative modeling through stochastic differential equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13456</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Diffusion Adversarial Representation Learning for Self-supervised Vessel Segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.14566</idno>
		<imprint>
			<date type="published" when="2022-09">Sep. 2022</date>
		</imprint>
	</monogr>
	<note>cs, eess</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Non-autoregressive conditional diffusion models for time series prediction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kwok</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">AudioLDM: Text-to-Audio Generation with Latent Diffusion Models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mandic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Plumbley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12503</idno>
		<imprint>
			<date type="published" when="2023-01">Jan. 2023</date>
		</imprint>
	</monogr>
	<note>cs, eess</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Symbolic music generation with diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hawthorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Simon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.16091</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A study on speech enhancement based on diffusion probabilistic model</title>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="659" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Khlifi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guerrero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.00842</idno>
		<imprint>
			<date type="published" when="2022-12">Dec. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Human motion diffusion model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tevet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shafir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Bermano</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.14916</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Mag-icVideo: Efficient Video Generation With Latent Diffusion Models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.11018[cs</idno>
		<imprint>
			<date type="published" when="2022-11">Nov. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Conditional diffusion based on discrete graph structures for molecular graph generation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.00427</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting molecular conformation via dynamic graph score matching</title>
		<author>
			<persName><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="19" to="784" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Language-guided traffic simulation via scene-level diffusion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rempe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Probabilistic mapping of dark matter by neural score matching</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rémy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lanusse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ramzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Starck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.08271</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.00364</idno>
		<title level="m">Elucidating the design space of diffusion-based generative models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On the mathematics of diffusion models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.11108</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.02646</idno>
		<title level="m">A survey on generative diffusion model</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Diffusion models: A comprehensive survey of methods and applications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.00796</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Understanding diffusion models: A unified perspective</title>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Generative diffusion models on graphs: Methods and applications</title>
		<author>
			<persName><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.02591</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Efficient diffusion models for vision: A survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ulhaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pogrebna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.09292</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Diffusion models in bioinformatics: A new wave of deep learning revolution in action</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10907</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Diffusion models for medical image analysis: A comprehensive survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kazerouni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Aghdam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Azad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hacihaliloglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Merhof</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.07804</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A survey on audio diffusion models: Text to speech synthesis and enhancement in generative ai</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13336</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A survey on generative diffusion models for structured data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Koo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Diffusion models in vision: A survey</title>
		<author>
			<persName><forename type="first">F.-A</forename><surname>Croitoru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hondru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.04747</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Text-toimage diffusion model in generative ai: A survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.07909</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Diffusion models in nlp: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.07576</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Franzese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Finamore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Filippone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michiardi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.05173</idno>
		<title level="m">How much is enough? a study on diffusion times in score-based generative models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Understanding Deep Learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Prince</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">On calibrating diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10688</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Vaes meet diffusion models: Efficient and high-fidelity generation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">G</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Fundamentals of Stochastic Models</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Diffusion models beat gans on image synthesis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8780" to="8794" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Exploring the optimal choice for generative processes in diffusion models: Ordinary vs stochastic differential equations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Maximum likelihood training of implicit nonlinear diffusion models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-C</forename><surname>Moon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.13699</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Reverse-time diffusion equation models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stochastic Processes and their Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="326" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Estimation of non-normalized statistical models by score matching</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">On the importance of noise scheduling for diffusion models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10972</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Non gaussian denoising diffusion models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.07582</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Score-based generative modeling with critically-damped langevin diffusion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dockhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.07068</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Daras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Delbracio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Talebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.05442</idno>
		<title level="m">Soft diffusion: Score matching for general corruptions</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Denoising diffusion gamma models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.05948</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">On the generalization of diffusion model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Convergence of denoising diffusion models under the manifold hypothesis</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.05314</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Tackling the generative learning trilemma with denoising diffusion gans</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.07804</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Learning energy-based models in high-dimensional spaces with multi-scale denoising score matching</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Sommer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07762</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Wavegrad: Estimating gradients for waveform generation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.00713</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Estimating high order gradients of the data distribution by denoising</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="25" to="359" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Improved techniques for training scorebased generative models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12" to="438" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Improved denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Q</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8162" to="8171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Variational diffusion models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="21" to="696" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Scalable adaptive computation for iterative generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.11972</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Noise2music: Textconditioned music generation with diffusion models</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">I</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frank</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.03917</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Cold diffusion: Inverting arbitrary image transforms without noise</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Borgnia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geiping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.09392</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Score-based denoising diffusion with non-isotropic gaussian noise models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Voleti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oberman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.12254</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Preserve your own correlation: A noise prior for video diffusion models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10474</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">On fast sampling of diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ping</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.00132</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Priorgrad: Improving conditional denoising diffusion models with data-driven adaptive prior</title>
		<author>
			<persName><forename type="first">H</forename><surname>S.-G. Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.06406</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">A reparameterized discrete diffusion model for text generation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05737</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Truncated diffusion probabilistic models and diffusion-based adversarial autoencoders</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="12" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Grad-tts: A diffusion probabilistic model for text-to-speech</title>
		<author>
			<persName><forename type="first">V</forename><surname>Popov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gogoryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sadekova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8599" to="8608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Diffsinger: Singing voice synthesis via shallow diffusion mechanism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="11" to="020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Truncated diffusion probabilistic models and diffusion-based adversarial autoencoders</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.09671</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Accelerating diffusion models via early stop of the diffusion process</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12524</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Dirichlet diffusion score model for biological sequence generation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Avdeyev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dudnyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10699</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Domain-specific denoising diffusion probabilistic models for brain dynamics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-T</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04200</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Dddm-vc: Decoupled denoising diffusion models with disentangled representation and prior mixup for verified robust voice conversion</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Subspace diffusion generative models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berlinghieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01490</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Nonuniform diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Batzolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stanczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-B</forename><surname>Sch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Etmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.09786</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Compositional visual generation with composable diffusion models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.01714</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Score-based generative modeling of graphs via the system of stochastic differential equations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.02514</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Batzolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stanczuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-B</forename><surname>Sch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Etmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.13606</idno>
		<title level="m">Conditional image generation with score-based diffusion models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.04559</idno>
		<title level="m">Clip-diffusion-lm: Apply diffusion model on image captioning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Riemannian score-based generative modeling</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.02763</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Argmax flows and multinomial diffusion: Learning categorical distributions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jaini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Forré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12" to="454" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-E</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.00527</idno>
		<title level="m">Diffusion probabilistic models for scene-scale 3d categorical data</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">R</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lubbers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11089</idno>
		<title level="m">Blackout diffusion: Generative diffusion models in discrete-state spaces</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Analog bits: Generating discrete data using diffusion models with self-conditioning</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.04202</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Diffuseq: Sequence to sequence text generation with diffusion models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.08933</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Continuous diffusion for categorical data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sartran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roshannai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Strudel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Durkan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.15089</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Diffuser: Diffusion via edit-based reconstruction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Hellendoorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Unsupervised discovery of semantic latent directions in diffusion models</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Uh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.12469</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.03024</idno>
		<title level="m">Riemannian diffusion schr\&quot; odinger bridge</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aghajohari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Panangaden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.07949</idno>
		<title level="m">Riemannian diffusion models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Diffusion-Based Representation Learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Abstreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrjou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.14257[cs</idno>
		<imprint>
			<date type="published" when="2022-08">Aug. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Diffusevae: Efficient, controllable and high-fidelity generation from lowdimensional latents</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.00308</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Diffusion autoencoders: Toward a meaningful and decodable representation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Preechakul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chatthee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wizadwongsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Suwajanakorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Diffusion Models already have a Semantic Latent Space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Uh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.10960[cs</idno>
		<imprint>
			<date type="published" when="2022-10">Oct. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Emergent correspondence from image diffusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Phoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Multi-modal latent diffusion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bounoua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Franzese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michiardi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Unifying diffusion models&apos; latent space, with applications to cyclediffusion and guidance</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torre</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2210.05559</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Soft truncation: A universal training technique of score-based diffusion model for high precision score estimation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-C</forename><surname>Moon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Exploring vision transformers as diffusion learners</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.13771</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Progressive distillation for fast sampling of diffusion models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.00512</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Wavelet diffusion models are fast and scalable image generators</title>
		<author>
			<persName><forename type="first">H</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Introduction to diffusion models for machine learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>O'connor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022-09">Sep 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Multiarchitecture multi-expert diffusion models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="139" to="144" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Deep learning and the information bottleneck principle</title>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zaslavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 ieee information theory workshop (itw)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">Pix-elcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05517</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Wide residual networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Crossvit: Cross-attention multi-scale vision transformer for image classification</title>
		<author>
			<persName><forename type="first">C.-F</forename><forename type="middle">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Panda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="357" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title level="m" type="main">Photorealistic text-to-image diffusion models with deep language understanding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K S</forename><surname>Ghasemipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Ayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Mahdavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Lopes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.11487</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Diffusion probabilistic fields</title>
		<author>
			<persName><forename type="first">P</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Susskind</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Á</forename><surname>Bautista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">Vdt: An empirical study on video diffusion with transformers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">Your vit is secretly a hybrid discriminative-generative diffusion model</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-M</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.07791</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Triantafyllopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Schuller</surname></persName>
		</author>
		<title level="m">U-dit tts: U-diffusion vision transformer for text-tospeech</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">All are worth words: a vit backbone for score-based diffusion models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.12152</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Exploring transformer backbones for image diffusion models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chahal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14678</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Unleashing transformers: parallel token prediction with discrete absorbing diffusion for fast high-resolution image generation from vector-quantized codes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bond-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hessey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Willcocks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2022: 17th European Conference</title>
		<meeting><address><addrLine>Tel Aviv, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">October 23-27, 2022. 2022</date>
			<biblScope unit="volume">XXIII</biblScope>
			<biblScope unit="page" from="170" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title level="m" type="main">Scalable diffusion models with transformers</title>
		<author>
			<persName><forename type="first">W</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09748</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Positional diffusion: Ordering unordered sets with diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Giuliari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scarpellini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Del Bue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.11120</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">Vit-tts: Visual text-to-speech with scalable diffusion transformer</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">One transformer fits all distributions in multi-modal diffusion at scale</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.06555</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">3d equivariant diffusion for target-aware molecule generation and affinity prediction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03543</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Dynamic dual-output diffusion models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Sliced score matching: A scalable approach to density and score estimation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="574" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">A geometric perspective on diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">How to train your energy-based models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.03288</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">Geodiff: A geometric diffusion model for molecular conformation generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.02923</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">A variational perspective on diffusion-based generative models and score matching</title>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="22" to="863" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Imagen video: High definition video generation with diffusion models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gritsenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.02303</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title level="m" type="main">Common diffusion noise schedules and sample steps are flawed</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08891</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Improved techniques for maximum likelihood estimation for diffusion odes</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03935</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Boosting fast and high-quality speech synthesis with linear diffusion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Diffusion models are minimax optimal distribution estimators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Oko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Akiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.01861</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Cresswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hosseinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Villecroze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Caterini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E T</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Loaiza-Ganem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title level="m" type="main">Analytic-dpm: an analytic estimate of the optimal reverse variance in diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.06503</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<title level="m" type="main">Denoising diffusion implicit models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02502</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Estimating the optimal covariance with imperfect mean in diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.07309</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">High-Fidelity Guided Image Synthesis with Latent Diffusion Models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.17084</idno>
		<imprint>
			<date type="published" when="2022-11">Nov. 2022</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Unsupervised semantic correspondence using stable diffusion</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hedlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Isack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tagliasacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Yi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">On analyzing generative and denoising capabilities of diffusion-based deep generative models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuzina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Trzci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.00070</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title level="m" type="main">A tale of two features: Stable diffusion complements dino for zero-shot semantic correspondence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Cabrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Addp: Learning general representations for image recognition and generation with alternating denoising diffusion process</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Diffusion hyperfeatures: Searching through time and space for semantic correspondence</title>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dunlap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Perception prioritized training of diffusion models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">Are diffusion models vision-and-language reasoners?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Krojer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Poole-Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Voleti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Training-free structured diffusion guidance for compositional text-to-image synthesis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Akula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Narayana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<monogr>
		<title level="m" type="main">Conceptbed: Evaluating concept learning abilities of text-to-image diffusion models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gokhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Baral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">Beyond surface statistics: Scene representations in a latent diffusion model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Score-based generative modeling in latent space</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11" to="287" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">Maximum likelihood training of score-based diffusion models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Durkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1415" to="1428" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<monogr>
		<title level="m" type="main">Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chewi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.11215</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title level="m" type="main">Controlling text-to-image diffusion by orthogonal finetuning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<monogr>
		<title level="m" type="main">Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b163">
	<monogr>
		<title level="m" type="main">Gotta go fast when generating data with scorebased models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Piché-Taillefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.14080</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b164">
	<monogr>
		<title level="m" type="main">Fast diffusion model</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<monogr>
		<title level="m" type="main">Self-guided diffusion models</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Burghouts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Snoek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.06462</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b166">
	<monogr>
		<title level="m" type="main">Towards enhanced controllability of diffusion models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Khuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Inouye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.14368</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b167">
	<monogr>
		<title level="m" type="main">Learning Data Representations with Joint Diffusion Models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Deja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Trzcinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13622</idno>
		<imprint>
			<date type="published" when="2023-01">Jan. 2023</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b168">
	<monogr>
		<title level="m" type="main">Diffcap: Exploring continuous diffusion on image captioning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.12144</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b169">
	<monogr>
		<title level="m" type="main">Raphael: Text-to-image generation via large mixture of diffusion paths</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Adding conditional control to textto-image diffusion models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.05543</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b171">
	<monogr>
		<title level="m" type="main">Classifier-free diffusion guidance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.12598</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b172">
	<monogr>
		<title level="m" type="main">Universal guidance for diffusion models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwarzschild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geiping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.07121</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b173">
	<monogr>
		<title level="m" type="main">A simple and effective positional encoding for transformers</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Ferng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08698</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b174">
	<monogr>
		<title level="m" type="main">Blended latent diffusion</title>
		<author>
			<persName><forename type="first">O</forename><surname>Avrahami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.02779</idno>
		<imprint>
			<date type="published" when="2022-06">Jun. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">3d shape generation and completion through point-voxel diffusion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5826" to="5835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.03530</idno>
		<title level="m">A conditional point diffusion-refinement paradigm for 3d point cloud completion</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b177">
	<monogr>
		<title level="m" type="main">Unifying human motion synthesis and style transfer with denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Findlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Shum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08526</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b178">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Chefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Alaluf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Vinker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13826</idno>
		<title level="m">Attend-and-excite: Attention-based semantic guidance for textto-image diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Directed diffusion: Direct control of object placement through attention guidance</title>
		<author>
			<persName><forename type="first">W.-D</forename><forename type="middle">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.13153</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b180">
	<monogr>
		<title level="m" type="main">Improving sample quality of diffusion models using self-attention guidance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.00939</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b181">
	<monogr>
		<title level="m" type="main">Towards performant and reliable undersampled mr reconstruction via diffusion model sampling</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.04292</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">Conditional diffusion with less explicit guidance via model predictive control</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hajiramezanali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scalia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diamant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Biancalani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Loukas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.12192</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b183">
	<monogr>
		<title level="m" type="main">Syncdiffusion: Coherent montage via synchronized joint diffusions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<monogr>
		<title level="m" type="main">Improving diffusion-based image translation using asymmetric gradient guidance</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">Simple black-box adversarial attacks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2484" to="2493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">Gradient-based adversarial attacks against text transformers</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13733</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b187">
	<monogr>
		<title level="m" type="main">Enhancing diffusion-based image synthesis with robust classifier guidance</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kawar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ganz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.08664</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b188">
	<analytic>
		<title level="a" type="main">Plug &amp; play generative networks: Conditional iterative generation of images in latent space</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4467" to="4477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b189">
	<analytic>
		<title level="a" type="main">A study and comparison of human and deep learning recognition performance under visual distortions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Karam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 26th international conference on computer communication and networks (ICCCN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b190">
	<analytic>
		<title level="a" type="main">Google&apos;s cloud vision api is not robust to noise</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Poovendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 16th IEEE international conference on machine learning and applications (ICMLA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="101" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b191">
	<monogr>
		<title level="m" type="main">End-to-end diffusion latent optimization improves classifier guidance</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gokul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.13703</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b192">
	<analytic>
		<title level="a" type="main">Suboptimal behavior of bayes and mdl in classification under misspecification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning Theory: 17th Annual Conference on Learning Theory, COLT 2004</title>
		<meeting><address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">July 1-4, 2004. 2004</date>
			<biblScope unit="page" from="331" to="347" />
		</imprint>
	</monogr>
	<note>Proceedings 17</note>
</biblStruct>

<biblStruct xml:id="b193">
	<monogr>
		<title level="m" type="main">Rethinking the role of gradient-based attribution methods for model interpretability</title>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.09128</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b194">
	<monogr>
		<title level="m" type="main">Denoising likelihood score matching for conditional score-based data generation</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14206</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b195">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06710</idno>
		<title level="m">Null-text guidance in diffusion models is secretly a cartoon-style creator</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b196">
	<monogr>
		<title level="m" type="main">Imitating human behaviour with diffusion models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rashid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kanervisto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bignell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Macua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.10677</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b197">
	<monogr>
		<title level="m" type="main">Diffusion self-guidance for controllable image generation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holynski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b198">
	<monogr>
		<title level="m" type="main">Conditional generation from unconditional diffusion models using denoiser representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yellapragada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Samaras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b199">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.08453</idno>
		<title level="m">T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b200">
	<monogr>
		<title level="m" type="main">A closer look at parameter-efficient tuning in diffusion models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.18181</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b201">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-Y</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<title level="m">Uni-controlnet: All-in-one control to text-to-image diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b202">
	<monogr>
		<title level="m" type="main">Norespeech: Knowledge distillation based conditional diffu-sion model for noise-robust expressive tts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.02448</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b203">
	<analytic>
		<title level="a" type="main">Theoretical guarantees for sampling and inference in generative models with latent diffusions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raginsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3084" to="3114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b204">
	<monogr>
		<title level="m" type="main">Accelerating diffusion models for inverse problems through shortcut sampling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b205">
	<analytic>
		<title level="a" type="main">Generative adversarial networks for markovian temporal dynamics: Stochastic continuous data generation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8413" to="8421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b206">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b207">
	<monogr>
		<title level="m" type="main">Accelerating diffusion sampling with classifier-based feature distillation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.12039</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b208">
	<monogr>
		<title level="m" type="main">Knowledge diffusion for distillation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b209">
	<monogr>
		<title level="m" type="main">Knowledge distillation in iterative generative models for improved sampling speed</title>
		<author>
			<persName><forename type="first">E</forename><surname>Luhman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Luhman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02388</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b210">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.13449</idno>
		<title level="m">Fast sampling of diffusion models via operator learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b211">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03142</idno>
		<title level="m">On distillation of guided diffusion models</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b212">
	<monogr>
		<title level="m" type="main">Consistency models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.01469</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b213">
	<monogr>
		<title level="m" type="main">A comprehensive survey on knowledge distillation of diffusion models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.04262</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b214">
	<monogr>
		<title level="m" type="main">Boot: Data-free distillation of denoising diffusion models with bootstrapping</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Susskind</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b215">
	<analytic>
		<title level="a" type="main">Denoising diffusion samplers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b216">
	<analytic>
		<title level="a" type="main">Learning fast samplers for diffusion models by differentiating through sample quality</title>
		<author>
			<persName><forename type="first">D</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b217">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Golnari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09847</idno>
		<title level="m">Selective guidance: Are all the denoising steps of guided diffusion important?</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b218">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belkhale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sadigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Anari</surname></persName>
		</author>
		<title level="m">Parallel sampling of diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b219">
	<monogr>
		<title level="m" type="main">Fast sampling of diffusion models with exponential integrator</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.13902</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b220">
	<monogr>
		<title level="m" type="main">It\ˆ{o}-taylor sampling scheme for denoising diffusion probabilistic models using ideal derivatives</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tachibana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Katayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Watanabe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.13339</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b221">
	<monogr>
		<title level="m" type="main">Alleviating exposure bias in diffusion models through sampling with shifted time steps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-F</forename><surname>Moens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b222">
	<monogr>
		<title level="m" type="main">Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.00927</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b223">
	<monogr>
		<title level="m" type="main">Structural pruning for diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10924</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b224">
	<monogr>
		<title level="m" type="main">Image super-resolution via iterative refinement</title>
		<author>
			<persName><forename type="first">C</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.07636</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b225">
	<monogr>
		<title level="m" type="main">Noise estimation for generative diffusion models</title>
		<author>
			<persName><forename type="first">R</forename><surname>San-Roman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nachmani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.02600</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b226">
	<monogr>
		<title level="m" type="main">Optimal linear subspace search: Learning to construct fast and highquality schedulers for diffusion models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b227">
	<monogr>
		<title level="m" type="main">Learning to efficiently sample from diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03802</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b228">
	<monogr>
		<title level="m" type="main">Latent dynamical implicit diffusion processes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Rezaei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b229">
	<monogr>
		<title level="m" type="main">Trans-dimensional generative modeling via jump diffusion models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Weilbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b230">
	<monogr>
		<title level="m" type="main">Unifying gans and score-based diffusion as generative particle models</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gartrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Issenhuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>De Bézenac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b231">
	<monogr>
		<title level="m" type="main">Expressiveness remarks for denoising diffusion models and samplers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerekes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09605</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b232">
	<monogr>
		<title level="m" type="main">Variational gaussian process diffusion processes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Solin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b233">
	<monogr>
		<title level="m" type="main">Phoenix: A federated generative diffusion model</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V S</forename><surname>Jothiraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mashhadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b234">
	<monogr>
		<title level="m" type="main">Diffusion explainer: Visual explanation for text-to-image stable diffusion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03509</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b235">
	<monogr>
		<title level="m" type="main">Interpretable style transfer for text-to-speech with controlvae and diffusion bridge</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b236">
	<monogr>
		<title level="m" type="main">Amd autoregressive motion diffusion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09381</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b237">
	<monogr>
		<title level="m" type="main">Ar-diffusion: Auto-regressive diffusion model for text generation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.09515</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b238">
	<monogr>
		<title level="m" type="main">Diffpack: A torsional diffusion model for autoregressive protein side-chain packing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b239">
	<monogr>
		<title level="m" type="main">Diffwave: A versatile diffusion model for audio synthesis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09761</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b240">
	<monogr>
		<title level="m" type="main">On architectural compression of text-to-image diffusion models</title>
		<author>
			<persName><forename type="first">B.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b241">
	<monogr>
		<title level="m" type="main">Training diffusion models with reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Janner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b242">
	<monogr>
		<title level="m" type="main">Few-shot diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Giannone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.15463</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b243">
	<monogr>
		<title level="m" type="main">Training data attribution for diffusion models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Gifford</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.02174</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b244">
	<monogr>
		<title level="m" type="main">Gsure-based diffusion model training with corrupted data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kawar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b245">
	<monogr>
		<title level="m" type="main">Ambient diffusion: Learning clean distributions from corrupted data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Daras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gollakota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Klivans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b246">
	<monogr>
		<title level="m" type="main">Label-retrieval-augmented diffusion models for learning from noisy labels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b247">
	<monogr>
		<title level="m" type="main">Meta-dm: Applications of diffusion models on few-shot learning</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08092</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b248">
	<monogr>
		<title level="m" type="main">Few-shot image generation with diffusion models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.03264</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b249">
	<monogr>
		<title level="m" type="main">Dinar: Diffusion inpainting of neural textures for one-shot human avatars</title>
		<author>
			<persName><forename type="first">D</forename><surname>Svitov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gudkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bashirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lemptisky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.09375</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b250">
	<monogr>
		<title level="m" type="main">Relightify: Relightable 3d faces from a single image via diffusion models</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Papantoniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lattas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moschoglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06077</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b251">
	<monogr>
		<title level="m" type="main">Zero-shot-learning cross-modality data translation through mutual information guided stochastic diffusion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sermesant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Delingette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13743</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b252">
	<monogr>
		<title level="m" type="main">Zero-shot medical image translation via frequencyguided diffusion models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.02742</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b253">
	<monogr>
		<title level="m" type="main">Zet-speech: Zeroshot adaptive emotion-controllable text-to-speech synthesis with diffusion and style-based models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b254">
	<monogr>
		<title level="m" type="main">Exploring diffusion models for unsupervised video anomaly detection</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dall'asen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Beyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.05841</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b255">
	<monogr>
		<title level="m" type="main">Dds2m: Selfsupervised denoising diffusion spatio-spectral model for hyperspectral image restoration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.06682</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b256">
	<monogr>
		<title level="m" type="main">Diffusion models and semi-supervised learners benefit mutually with few labels</title>
		<author>
			<persName><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.10586</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b257">
	<analytic>
		<title level="a" type="main">A brief introduction to weakly supervised learning</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National science review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b258">
	<monogr>
		<title level="m" type="main">Llm-grounded diffusion: Enhancing prompt understanding of text-to-image diffusion models with large language models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b259">
	<monogr>
		<title level="m" type="main">3ddesigner: Towards photorealistic 3d object generation and editing with text-guided diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.14108</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b260">
	<monogr>
		<title level="m" type="main">Anyto-any generation via composable diffusion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11846</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b261">
	<monogr>
		<title level="m" type="main">Unicontrol: A unified diffusion model for controllable visual generation in the wild</title>
		<author>
			<persName><forename type="first">C</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.11147</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b262">
	<monogr>
		<title level="m" type="main">Card: Classification and regression diffusion models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.07275</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b263">
	<monogr>
		<title level="m" type="main">The surprising effectiveness of diffusion models for optical flow and monocular depth estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b264">
	<monogr>
		<title level="m" type="main">Policy representation via diffusion probability model for reinforcement learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b265">
	<monogr>
		<title level="m" type="main">Diffusionnag: Taskguided neural architecture generation with diffusion models</title>
		<author>
			<persName><forename type="first">S</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b266">
	<monogr>
		<title level="m" type="main">Diffusion models for black-box optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mashkaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b267">
	<monogr>
		<title level="m" type="main">Diffusionner: Boundary diffusion for named entity recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b268">
	<monogr>
		<title level="m" type="main">Is synthetic data from diffusion models ready for knowledge distillation?</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b269">
	<monogr>
		<title level="m" type="main">Synthetic ct generation from mri using 3d transformer-based denoising diffusion model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Abouei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wynne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Roper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b270">
	<monogr>
		<title level="m" type="main">Towards consistent video editing with text-to-image diffusion models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b271">
	<monogr>
		<title level="m" type="main">A survey on graph diffusion models: Generative ai in science for molecule, protein and material</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.01565</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b272">
	<monogr>
		<title level="m" type="main">Diffusion models for high-resolution solar forecasts</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hatanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Galgon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Torri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sadowski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.00170</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b273">
	<monogr>
		<title level="m" type="main">End-to-end latent variational diffusion models for inverse problems in high energy physics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shmakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fenton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whiteson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10399</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b274">
	<monogr>
		<title level="m" type="main">Geometry-complete diffusion for 3d molecule generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Morehead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.04313</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b275">
	<monogr>
		<title level="m" type="main">A latent diffusion model for protein structure generation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mcthrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Komikado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Maruhashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uchino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04120</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b276">
	<monogr>
		<title level="m" type="main">Spontaneous symmetry breaking in generative diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Raya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ambrogioni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b277">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.07508</idno>
		<title level="m">Moldiff: Addressing the atom-bond inconsistency problem in 3d molecule diffusion generation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b278">
	<monogr>
		<title level="m" type="main">Se (3) diffusion model with application to protein backbone generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Trippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">De</forename><surname>Bortoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.02277</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b279">
	<monogr>
		<title level="m" type="main">Mask, stitch, and re-sample: Enhancing robustness and generalizability in anomaly detection through automatic diffusion models</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Bercea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumayr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b280">
	<monogr>
		<title level="m" type="main">Villandiffusion: A unified backdoor attack framework for diffusion models</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Ho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b281">
	<monogr>
		<title level="m" type="main">Text-toimage diffusion models can be easily backdoored through multimodal data poisoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04175</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b282">
	<monogr>
		<title level="m" type="main">Densepure: Understanding diffusion models towards adversarial robustness</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2211.00322</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b283">
	<monogr>
		<title level="m" type="main">Stable diffusion is unstable</title>
		<author>
			<persName><forename type="first">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b284">
	<monogr>
		<title level="m" type="main">On enhancing the robustness of vision transformers: Defensive diffusion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Imam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huzaifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename></persName>
		</author>
		<author>
			<persName><forename type="first">-A</forename><surname>Azz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08031</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b285">
	<monogr>
		<title level="m" type="main">Robust evaluation of diffusion-based adversarial purification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.09051</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b286">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Altstidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eskofier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schwinn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.10388</idno>
		<title level="m">Raising the bar for certified adversarial robustness with diffusion models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b287">
	<monogr>
		<title level="m" type="main">Diffusion theory as a scalpel: Detecting and purifying poisonous dimensions in pre-trained language models caused by backdoor or bias</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.04547</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b288">
	<monogr>
		<title level="m" type="main">Diffusion models for imperceptible and transferable adversarial attack</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08192</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b289">
	<monogr>
		<title level="m" type="main">Diffusion-based adversarial sample generation for improved stealthiness and controllability</title>
		<author>
			<persName><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b290">
	<analytic>
		<title level="a" type="main">Sex, lies, and videotape: Deep fakes and free speech delusions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Franks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Waldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Md. L. Rev</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page">892</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b291">
	<monogr>
		<title level="m" type="main">Level up the deepfake detection: a method to effectively discriminate images generated by gan architectures and diffusion models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Guarnera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Giudice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Battiato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.00608</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b292">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zannettou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<title level="m">Unsafe diffusion: On the generation of unsafe images and hateful memes from text-to-image models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b293">
	<monogr>
		<title level="m" type="main">Detecting images generated by diffusers</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Coccomini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Falchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Amato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.05275</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b294">
	<monogr>
		<title level="m" type="main">Protecting the intellectual property of diffusion models by the watermark diffusion process</title>
		<author>
			<persName><forename type="first">S</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b295">
	<monogr>
		<title level="m" type="main">Diffusionshield: A watermark for copyright protection against generative diffusion models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b296">
	<monogr>
		<title level="m" type="main">Extracting training data from diffusion models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Balle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.13188</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b297">
	<monogr>
		<title level="m" type="main">A reproducible extraction of training images from diffusion models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Webster</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08694</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b298">
	<monogr>
		<title level="m" type="main">Diffprotect: Generate adversarial examples with diffusion models for facial privacy protection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b299">
	<monogr>
		<title level="m" type="main">Privacy distillation: Reducing reidentification risk of multimodal diffusion models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H L</forename><surname>Pinaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jacenk Ów</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Tsaftaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cardoso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b300">
	<monogr>
		<title level="m" type="main">Prisampler: Mitigating property inference of diffusion models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b301">
	<monogr>
		<title level="m" type="main">Differentially private latent diffusion models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vinaroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b302">
	<monogr>
		<title level="m" type="main">Unlearnable examples for diffusion models: Protect data from unauthorized exploitation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b303">
	<monogr>
		<title level="m" type="main">Analyzing bias in diffusion-based face generation models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.06402</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b304">
	<monogr>
		<title level="m" type="main">Don&apos;t play favorites: Minority guidance for diffusion models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Um</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12334</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b305">
	<analytic>
		<title level="a" type="main">Generating high fidelity data from low-density regions using diffusion models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Sehwag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ozgenel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Canton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b306">
	<monogr>
		<title level="m" type="main">Understanding and mitigating copying in diffusion models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Somepalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Goldblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geiping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b307">
	<monogr>
		<title level="m" type="main">Diversify your vision datasets with automatic diffusion-based augmentation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dunlap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Umino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b308">
	<monogr>
		<title level="m" type="main">Stable bias: Analyzing societal representations in diffusion models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Akiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.11408</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b309">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<publisher>REFERENCES</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b310">
	<monogr>
		<title level="m" type="main">Understanding diffusion models: A unified perspective</title>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b311">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
