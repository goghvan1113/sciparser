<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment</title>
				<funder ref="#_Gc2NCkX">
					<orgName type="full">Innovate UK</orgName>
				</funder>
				<funder ref="#_We58wCx #_RXFqQ4B">
					<orgName type="full">UK Engineering and Physical Sciences Research Council</orgName>
					<orgName type="abbreviated">EPSRC</orgName>
				</funder>
				<funder ref="#_Gt3YTzk">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Big Data Computing Center of Southeast University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-12-17">17 Dec 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Congzhi</forename><surname>Zhang</surname></persName>
							<email>zhangcongzhi@seu.edu.cnlinhai.zhang</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Linhai</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jialong</forename><surname>Wu</surname></persName>
							<email>jialongwu@seu.edu.cnlinhai.zhang</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
							<email>yulan.he@kcl.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">King&apos;s College London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Alan Turing Institute</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
							<email>d.zhou@seu.edu.cnlinhai.zhang</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Ministry of Education</orgName>
								<orgName type="laboratory">Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-12-17">17 Dec 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">255D08F0585EFADC0CE85CB8C845A2B1</idno>
					<idno type="arXiv">arXiv:2403.02738v3[cs.CL]</idno>
					<note type="submission">What year was a joint venture between RLJ Companies and this film studio founded in 2005, Companies and this film studio (TWC) was founded. We know that The Weinstein Company was founded in 2005, and Our Stories Films was a joint venture between RLJ Companies and The Weinstein Company. We can conclude that the joint venture was also founded in 2005. The answer is 2005 neutral Correct Answer: 2006</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-01-20T09:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the notable advancements of existing prompting methods, such as In-Context Learning and Chain-of-Thought for Large Language Models (LLMs), they still face challenges related to various biases. Traditional debiasing methods primarily focus on the model training stage, including approaches based on data augmentation and reweighting, yet they struggle with the complex biases inherent in LLMs. To address such limitations, the causal relationship behind the prompting methods is uncovered using a structural causal model, and a novel causal prompting method based on front-door adjustment is proposed to effectively mitigate LLMs biases. In specific, causal intervention is achieved by designing the prompts without accessing the parameters and logits of LLMs. The chain-of-thought generated by LLM is employed as the mediator variable and the causal effect between input prompts and output answers is calculated through front-door adjustment to mitigate model biases. Moreover, to accurately represent the chain-of-thoughts and estimate the causal effects, contrastive learning is used to fine-tune the encoder of chain-of-thought by aligning its space with that of the LLM. Experimental results show that the proposed causal prompting approach achieves excellent performance across seven natural language processing datasets on both open-source and closed-source LLMs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large Language Models (LLMs) have shown remarkable emergent abilities, including In-Context Learning (ICL) <ref type="bibr">(Brown et al. 2020;</ref><ref type="bibr" target="#b26">Peng et al. 2024;</ref><ref type="bibr" target="#b63">Yang et al. 2024)</ref> and Chain-of-Thought (CoT) prompting <ref type="bibr" target="#b47">(Wei et al. 2022;</ref><ref type="bibr" target="#b44">Wang et al. 2022)</ref>, which allow LLMs to perform natural language tasks based on only a few instances without weight updating. These prompting methods have achieved significant results across many traditional natural language processing tasks, including sentiment analysis, natural language inference, and machine reading comprehension <ref type="bibr">(Kojima et al. 2022;</ref><ref type="bibr" target="#b76">Zhou et al. 2022;</ref><ref type="bibr" target="#b7">Liu et al. 2023)</ref>.</p><formula xml:id="formula_0">IO standard ICL CoT CoT-SC Original ReverseTarget ReverseNonTarge AddDiff</formula><p>Figure <ref type="figure" target="#fig_7">1</ref>: Performance of different prompting methods on ABSA <ref type="bibr" target="#b27">(Pontiki et al. 2016</ref>) and its adversarial datasets on LLaMA-7b. ReverseTarget, ReverseNonTarget, and Ad-dDiff denote three different adversarial transformations by TextFlint <ref type="bibr" target="#b43">(Wang et al. 2021)</ref>. IO denotes the zero-shot setting where only the input question outputs the answer.</p><p>However, recent studies have shown that these advanced prompting methods are not robust enough <ref type="bibr" target="#b69">(Ye et al. 2023)</ref> and can lead LLMs to produce hallucinatory results with incorrect or unfaithful intermediate reasoning steps <ref type="bibr" target="#b10">(Lyu et al. 2023;</ref><ref type="bibr" target="#b42">Wang et al. 2023b;</ref><ref type="bibr">Bao et al. 2024;</ref><ref type="bibr" target="#b39">Turpin et al. 2024)</ref>.</p><p>Some studies <ref type="bibr" target="#b14">(Mallen et al. 2023;</ref><ref type="bibr" target="#b46">Wang et al. 2023d</ref>) believe that this phenomenon is due to the a conflict between the internal knowledge bias of LLMs and the external knowledge. Therefore, an effective solution is to interact with an external knowledge base to validate and adjust the reasoning process of LLMs <ref type="bibr" target="#b42">(Wang et al. 2023b;</ref><ref type="bibr">Zhang et al. 2023)</ref>. Moreover, recent work debiases the chain-of-thoughts of LLMs by incorporating counterfactual knowledge and causal interventions <ref type="bibr">(Wu et al. 2024a</ref>). However, these methods are specifically tailored for knowledge-intensive tasks. Bias problems are also observed in other NLP tasks. As shown in Figure <ref type="figure">2</ref>, in aspects-based sentiment analysis, mathematical reasoning, and multi-hop question-answering tasks, LLMs sometimes overly depend on certain text spans in the prompts, leading to wrong reasoning and answers. Notably, the first two tasks mentioned are not knowledge-intensive. We argue that LLMs fail to capture the true causal effect between ques-Figure <ref type="figure">2</ref>: LLMs suffer from bias in the pertaining corpus, leading them to rely on irrelevant text spans in prompts and generating incoherent chain-of-thoughts that harm the logical reasoning capability of the model. These examples were obtained by using the CoT prompting <ref type="bibr" target="#b47">(Wei et al. 2022</ref>) on the LLaMA3-8B model. tions and reasoning results and instead establish spurious correlations between certain text spans and answers.</p><p>In addition to the above qualitative analysis, our quantitative experiments also show that the current prompting methods are ineffective in addressing the bias issue. As shown in Figure <ref type="figure" target="#fig_7">1</ref>, the performance of all prompting methods drops significantly when evaluated on the corresponding adversarial dataset compared to the original dataset, indicating that LLMs may suffer from bias in the pertaining corpus. Moreover, it has been demonstrated that LLMs exhibit label bias, recency bias, and entity bias from context <ref type="bibr" target="#b74">(Zhao et al. 2021;</ref><ref type="bibr">Wang et al. 2023a;</ref><ref type="bibr">Fei et al. 2023)</ref>.</p><p>Traditional debiasing methods mitigate the bias issue mainly during the model training stage, utilizing approaches such as data augmentation-based <ref type="bibr" target="#b48">(Wei and Zou 2019;</ref><ref type="bibr" target="#b1">Lee et al. 2021</ref>) and reweighting <ref type="bibr" target="#b31">(Schuster et al. 2019;</ref><ref type="bibr" target="#b13">Mahabadi, Belinkov, and Henderson 2019)</ref>. Data augmentation-based methods face challenges due to the cost and complexity of annotating bias cases, particularly limited by context length. Reweight-based methods encounter difficulties in assigning weights to each sample in prompt-based learning scenarios. Recently, debias methods based on causal inference <ref type="bibr" target="#b25">(Pearl et al. 2000;</ref><ref type="bibr" target="#b22">Pearl 2022</ref>) have become popular because of their strict theoretical guarantees and good generalization. Causal inference-based methods only need to calibrate model prediction results during the inference stage <ref type="bibr" target="#b17">(Niu et al. 2021;</ref><ref type="bibr" target="#b36">Tian et al. 2022;</ref><ref type="bibr">Guo, Gong, and Lai 2022;</ref><ref type="bibr" target="#b61">Xu et al. 2023;</ref><ref type="bibr">Chen et al. 2023a)</ref>, which makes them well-suited for promptbased learning scenarios. However, counterfactual inference requires accessing LLM output logits, while back-door ad-justment requires specific confounding variable values.</p><p>To address the aforementioned challenge, we propose to debias prompting methods through causal intervention using front-door adjustment <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref>. Front-door adjustment enables causal intervention without the need to access confounding variable values or LLM output logits. As shown in Figure <ref type="figure" target="#fig_0">3</ref>(a), the causal relationship behind the prompting method is uncovered using a structural causal model. Here X denotes the input prompt, comprising demonstrations and test examples.</p><p>A denotes the predicted answer generated by the LLM. U is the unobservable confounder that introduces various biases in the pertaining corpus.</p><p>The debiasing process involves measuring the causal effect between the treatment X and the outcome A. However, as U absorbs complex biases of LLMs that are difficult to model or detect, back-door adjustment is not feasible for calculating the causal effect between X and A. To address this issue, as shown in Figure <ref type="figure" target="#fig_0">3</ref>(b), we use the chain-of-thought generated by LLM as the mediator variable R between X and A.</p><p>As Figure <ref type="figure">2</ref> illustrates, while LLMs initially reason correctly, biases often confuse the final step of answer derivation. To simplify, we ignore the edges between U and R, aligning our causal graph with the front-door criterion <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref>. By this way, we can use the front-door adjustment to estimate the causal effect between X and A without accessing U .</p><p>Therefore, in this paper, we propose Causal Prompting, a novel prompting method for debiasing based on front-door adjustment. Unlike previous causal inference-based methods, causal intervention is implemented by modifying prompts without accessing the parameters and logits of LLMs. Specifically, to estimate the causal effect between X and R, we leverage self-consistency (SC) <ref type="bibr" target="#b44">(Wang et al. 2022)</ref> of LLMs and a clustering algorithm to compute the probability of the chain-of-thought R. To measure the causal effect between R and A, we use the normalized weighted geometric mean (NWGM) approximation <ref type="bibr" target="#b59">(Xu et al. 2015)</ref> to select the optimal demonstration set, which can help the model to generate an unbiased answer. Overall, CoT, SC, and ICL are effectively combined through front-door adjustment to mitigate LLM biases in NLP tasks. Note that in the clustering and NWGM algorithms, an Encoder is needed to obtain the representations of chain-of-thoughts. Since Encoder and LLMs have different semantic understanding of the chain-of-thought, we use contrastive learning <ref type="bibr">(Chen et al. 2020)</ref> to fine-tune the Encoder to align its representation space with LLMs to estimate causal effects more accurately.</p><p>The contributions of this work are summarized as follows: • Our work aims to identify and analyze the bias problem in LLM prompting methods from the perspective of causal inference, adhering more closely to the principles of the field. Moreover, the front-door adjustment is proposed to theoretically address the bias problem in prompting. • Contrastive learning is proposed to fine-tune the Encoder of the chain-of-thoughts, aligning the space of the Encoder with LLMs to accurately capture representations of chain-of-thoughts and estimate causal effects. • The proposed approach achieves excellent performance across seven natural language processing datasets using both open-source and closed-source LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Structural Causal Model and Causal Intervention</head><p>A Structural Causal Model (SCM) <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016</ref>) is used to describe the causal relationships between variables. In SCM, we typically use a directed acyclic graph G = {V, E}, where V represents the set of variables and E represents the set of direct causal relationships. As shown in Figure <ref type="figure" target="#fig_0">3</ref>(a), X denotes the input prompt, including demonstrations and test examples. A denotes the predicted answer generated by the LLMs. LLMs generate answers based on prompt, so we have X → A, which means that X is the direct cause of A. LLMs might learn spurious correlations between text patterns and answers from pre-trained corpora or instruction-supervised fine-tuning datasets <ref type="bibr" target="#b58">(Xing et al. 2020;</ref><ref type="bibr" target="#b3">Li et al. 2024;</ref><ref type="bibr">Bao et al. 2024</ref>), leading to bias in downstream tasks. Previous work argues that the reason for this bias is that LLMs tend to follow a certain latent concept <ref type="bibr" target="#b57">(Xie et al. 2021)</ref> or an implicit reasoning results <ref type="bibr" target="#b3">(Li et al. 2024)</ref> in the reasoning process, rather than following the explicitly generated chain-of-thought. This leads to the final answer does not necessarily follow from the generated chain-of-thought, specifically, there is no actual causal relationship between the chain-of-thought and the answer <ref type="bibr" target="#b10">(Lyu et al. 2023;</ref><ref type="bibr">Bao et al. 2024)</ref>. To accurately calculate the causal effect between X and A, we use the unob- servable variable U to describe this latent concept or implicit reasoning results, using the back-door path X ← U → A denotes that the causality of X and A is confounded by U .</p><p>In SCM, if we want to compute the true causal effect between two variables X and A, we should block every backdoor path between them <ref type="bibr" target="#b24">(Pearl and Mackenzie 2018)</ref>. For example, as shown in Figure <ref type="figure" target="#fig_0">3</ref>(a), we should block X ← U → A to obtain the true causal effect between X and A. We typically use causal interventions for this purpose, which use the do operation to estimate the causal effect between X and A. In the causal graph satisfying Figure <ref type="figure" target="#fig_0">3</ref>(a), the dooperation can be computed by back-door adjustment <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref>:</p><formula xml:id="formula_1">P (A|do(X)) = u P (A|X, u)P (u) (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Front-door Adjustment</head><p>Since confounding factor U is inaccessible, back-door adjustment cannot be performed. Fortunately, the front-door adjustment <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref> does not require access to the values of the confounding factor U to calculate the causal effect between X and A. As shown in Figure <ref type="figure" target="#fig_0">3</ref>(b), we use the chain-of-thought generated by LLM as a mediator variable R between X and A.</p><p>In practice, as depicted in Figure <ref type="figure">2</ref>, LLM can perform correct reasoning at the beginning, but it is often easily confused by bias in the last step of deriving the answer. Consequently, we decided to start with the simple SCM and focus on the confounder between X and A. In order to simplify the causal graph, we ignore the confounder of R with other variables, aligning our causal graph with the front-door criterion <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref>. According to the front door adjustment, P (A|do(X)) can be formulated as:</p><formula xml:id="formula_2">P (A|do(X)) = r P (A|do(r))P (r|do(X)) (2)</formula><p>where r ∈ R is the chain-of-thought generated by LLMs in response to the prompt X. The causal effect between X and A is decomposed into two partially causal effects P (r|do(X)) and P (A|do(r)).</p><p>Next, we discuss how to estimate these two components separately. The first component is P (r|do(X)), represents the probability distribution of the chain-of-thought r given the intervention do(X). To compute P (r|do(X)), we need to block the backdoor path X ← U → A ← R between X and R. Since there exists a collision structure U → A ← R, the backdoor path has been blocked <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref> and we can get: P (r|do(X)) = P (r|X)</p><p>(3) Now, we focus on the computation of the second component P (A|do(r)), represents the probability distribution of the answer A given the intervention do(r). To compute P (A|do(r)), we need to block the backdoor path R ← X ← U → A between R and A. Since we do not have access to the details of U , we implement back-door adjustments with the help of prompt X:</p><formula xml:id="formula_3">P (A|do(r)) = x P (x)P (A|r, x)<label>(4)</label></formula><p>where x ∈ X denotes the input prompt, including demonstrations and test examples.</p><p>Finally, substituting Equations ( <ref type="formula">3</ref>) and ( <ref type="formula" target="#formula_3">4</ref>) into Equation (2) after we obtain the estimation of P (r|do(X)) and P (A|do(r)). Hence, the final P (A|do(X)) can be represented as follows:</p><formula xml:id="formula_4">P (A|do(X)) = r P (r|do(X))P (A|do(r)) = r P (r|X) CoT -SC x P (x)P (A|r, x) ICL<label>(5)</label></formula><p>where the first component r P (r|do(X)) can be estimated by combining the CoT and SC prompting methods, and the second component P (A|do(r)) can be computed by selecting the demonstration examples in ICL prompting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>As shown in Figure <ref type="figure">4</ref>, Causal Prompting aims to estimate the causal effect between input X and answer A. The estimation is achieved using the front-door adjustment, which divides the causal pathway into two distinct parts: the causal effect between X and chain-of-thought r, and the causal effect between r and A.</p><p>First, the causal effect between X and chain-of-thought r, P (r|do(X)) is estimated by combining the Chain-of-Thought prompting with a Encoder-based clustering algorithm. Second, the causal effect between r and A, P (A|do(r)) is estimated by combining the In-Context Learning prompting with the normalized weighted geometric mean (NWGM) approximation algorithm. The final answer is aggregated by performing a weighted voting algorithm. <ref type="bibr">Moreover, contrastive learning(Chen et al. 2020;</ref><ref type="bibr">Gao et al. 2022;</ref><ref type="bibr" target="#b72">Zhang, Zhang, and Zhou 2023</ref>) is employed to align the representation space of the Encoder and the LLMs for more precise estimation.</p><p>We will first introduce the estimation of P (r|do(X)) and P (A|do(r)), respectively, then combine them to derive P (A|do(X)). Finally, we will discuss how we align the representation space between the Encoder and the LLM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Estimation of P (r|do(X))</head><p>We firstly undertake the estimation of P (r|do(X)). P (r|do(X)) measures the causal effect between input X and chain-of-thought r. As shown in Equation ( <ref type="formula">3</ref>), the estimation of P (r|do(X)) is equivalent to the estimation of P (r|X). However, P (r|X) is still intractable for LLMs. On the one hand, the output probability is often inaccessible for most closed-source LLMs; on the other hand, the chain-ofthoughts r are challenging to enumerate comprehensively. Therefore, to estimate the causal effect P (r|do(X)) for both open-source and closed-source LLMs, we employ the CoT prompting and integrate it with a clustering algorithm. To be more specific, we initially prompt the LLMs to generate multiple CoTs based on the input. The prompts for CoTs generation are detailed in Appendix H.1. Subsequently, the CoTs are projected into embeddings. The embeddings are then clustered to form distinct groups based on their similarity. Finally, the centroid of each cluster is selected as the optimal and representative chain-of-thought. The probability associated with each representative chain-of-thought is then estimated based on the size of its respective cluster.</p><p>To enhance the quality of generated CoTs, n in-context demonstrations d are selected from training set based on question similarity. These demonstrations are then concatenated with the test question q test to form the final prompt. Thus, the final prompt P is structured as follows:</p><formula xml:id="formula_5">P = [d 1 , ..., d n , q test ]<label>(6)</label></formula><p>where each d i = (q demo i , r demo i ) contain the demonstration question q demo i and its corresponding demonstration chain-ofthought r demo i . Where i ∈ {1, ..., n}, n denotes the number of demonstration examples in few-shot prompt method. In the practical implementation, we use prompt P, which is fed into the LLMs to represent X in the structural causal model.</p><p>Based on the input prompt P, LLMs are prompted to generate m distinct CoTs c by increasing the temperature parameter of LLMs. This adjustment encourages more diverse outputs, where the same procedure is also employed in selfconsistency prompting of LLMs <ref type="bibr">(Wang et al. 2023c)</ref>. In this way, we can obtain the set of chain-of-thoughts as follows:</p><formula xml:id="formula_6">{c i |i = 1, ..., m} = LLM(P)<label>(7)</label></formula><p>To perform the distance-based clustering method, the gen- Based on the clusters, K representative chain-of-thoughts r are selected by searching the closest chain-of-thought to the cluster center. The causal effect between input X and chain-of-thought r k is estimated based on the cluster size as follows:</p><formula xml:id="formula_7">r k = Center(C k ), k = 1, ..., K<label>(10)</label></formula><formula xml:id="formula_8">P (r k |do(X)) ≈ |C k | m<label>(11)</label></formula><p>where |C k | denotes the size of cluster C k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Estimation of P (A|do(r))</head><p>Based on the K chain-of-thoughts selected by Equation (10) in Section 3.1, we estimate P (A|do(r k )) for each chain-of-thought r k . For convenience, we omit the subscript k and use P (A|do(r)) to denote P (A|do(r k )) in the following. P (A|do(r)) measures the causal effect between the chain-of-thought r and the answer A. Based on the discussion in Equation (4), P (A|do(r)) can be calculated with backdoor adjustment as follows:</p><formula xml:id="formula_9">P (A|do(r)) = x∈X P (x)P (A|r, x) = Ex∈X [P (A|r, x)]<label>(12)</label></formula><p>where P (A|r, x) denotes the probability of the final answer A generated by LLM based on the given prompt x and the chain-of-thought r.</p><p>However, the value space of X is inexhaustible in most of the cases, and previous work employs the normalized weighted geometric mean (NWGM) approximation <ref type="bibr" target="#b59">(Xu et al. 2015;</ref><ref type="bibr" target="#b36">Tian et al. 2022;</ref><ref type="bibr">Chen et al. 2023a)</ref> to tackle this problem, where a confounder embedding x ′ is estimated to approximate the expectation of variable X.</p><formula xml:id="formula_10">Ex∈X [P (A|r, x)] ≈ P (A|r, Ex∈X [x]) ≈ P (A|concat(r, x ′ )) (13)</formula><p>where concat(•, •) denotes vector concatenation, x ′ denotes the confounder embedding of X.</p><p>Inspired by the previous works <ref type="bibr" target="#b59">(Xu et al. 2015;</ref><ref type="bibr" target="#b36">Tian et al. 2022;</ref><ref type="bibr">Chen et al. 2023a;</ref><ref type="bibr" target="#b71">Zhang, Zhang, and Zhou 2024)</ref>, we propose a prompting version of NWGM approximation to perform the backdoor adjustment for LLMs prompting by combining a Encoderbased intervention and In-Context Learning (ICL) prompting. The original idea of NWGM is to augment the representation of the chain-of-thought r with an embedding x ′ that contains all sample information as much as possible. However, at the prompting level, we cannot include all samples in context due to the limited context length, so we use only those samples that are most useful for improving the current chain-of-thought r.</p><p>Specifically, we use the Encoder to obtain the embedding r k of the k-th chain-of-thought r k . Subsequently, ICL demonstrations are selected by searching the entire training set based on the chainof-thought embedding r k to approximate the effect of taking expectations on input X. Finally, we rank the ICL demonstrations according to their similarity weights to indicate the importance of different samples.</p><p>Note that, as shown in Equation ( <ref type="formula" target="#formula_5">6</ref>), the input prompt P includes demonstrations d and test question q test . Directly modifying the certain text span of test examples will change the semantics of question q test . Therefore, we only modify the demonstrations d and implement the NWGM approximation by In-Context Learning. In fact, the goal of our prompting version of the NWGM algorithm is to enable the LLMs to learn from the demonstrations how to improve the chain-of-thought r of the test example. As shown in the prompt template in Appendix H.2, we introduce both wrong and correct chain-of-thoughts of demonstrations. </p><formula xml:id="formula_11">r k = Encoder([CLS], r k , [SEP]) dj = Encoder([CLS], r wrong j , [SEP])<label>(14)</label></formula><p>Previous works <ref type="bibr" target="#b15">(Margatina et al. 2023;</ref><ref type="bibr" target="#b6">Liu et al. 2022</ref>) have shown that using demonstration examples that are semantically similar to the test examples allows better performance for In-Context Learning. Therefore, the back-door intervention is approximated by searching the most similar instance based on chain-of-thought embedding r k . Specifically, we sort the training set D from largest to smallest according to the cosine similarity between r k and dj.</p><formula xml:id="formula_12">{d ↑ j } N j=1 = Sort(D, r k , {dj} N j=1 )<label>(15)</label></formula><p>where d ↑ j denotes the sorted demonstration example, Sort means that, given a predefined cosine similarity function cos, the samples are ordered so that cos(r k , di) ≥ cos(r k , dj) when i &lt; j.</p><p>Then the l most similar demonstration examples are selected to concatenate into prompt, where l ≪ N . Note that, unlike the KATE <ref type="bibr" target="#b5">(Liu et al. 2021</ref>) method, we put the most similar demonstration samples closer to the test samples because this order is more beneficial for our NWGM algorithm to learn information for improving the chain-of-thoughts from the demonstration based on practical experiments, detailed in Appendix E.2. For each chain-ofthought r k of a test sample, the final input prompt after intervention is given as follows:</p><formula xml:id="formula_13">P iter r k = [d ↑ l , ..., d ↑ 1 , q test ]<label>(16)</label></formula><p>Subsequently, we query the LLMs T times, obtaining T answers and T improved chain-of-thoughts using the prompt</p><formula xml:id="formula_14">P iter r k and chain-of-thought r k . {(r ip k,t , a k,t )|t = 1, ..., T } = LLM(P iter r k , r k )<label>(17)</label></formula><p>where r ip k,t denotes the t-th improved chain-of-thought for chain-ofthought r k .</p><p>We then use majority voting to estimate the probability of the answer as follows:</p><formula xml:id="formula_15">P (A|do(r k )) ≈ T t=1 I(A = a k,t ) T (18)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Estimation of P (A|do(X))</head><p>Based on the results of Equation ( <ref type="formula" target="#formula_8">11</ref>) in Section 3.1 and Equation (18) in Section 3.2, the final answer is obtained by performing a weighted voting as follows:</p><formula xml:id="formula_16">P (A|do(X)) = r k P (r k |do(X))P (A|do(r k )) = K k=1 |C k | m • T t=1 I(A = a k,t ) T (19)</formula><p>Finally, we chose the answer with the largest weight as the final answer. In this way, with the front-door adjustment, we calibrate the probability distribution P (A|X) obtained by the CoT-SC method to P (A|do(X)) obtained by the Causal Prompting method. Algorithm 1 in Appendix B shows the overall prompting process. Cases in Appendix G show the overall flow and intermediate step output of Causal Prompting on mathematical reasoning and multi-hop question answering datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Representation Space Alignment</head><p>In the clustering discussed in Section 3.1 and NWGM algorithm presented in Section 3.2, an Encoder is needed to derive the representations of chain-of-thoughts. However, the semantic representation of Encoder and LLM differ significantly. Two chain-of-thoughts that LLM considers similar may not be close in the representation space of the Encoder. As illustrated in Figure <ref type="figure" target="#fig_6">7</ref> in Appendix A, the chain-of-thoughts generated by LLM are not distinctly separable in the representation space of the vanilla Encoder.</p><p>To align the representation spaces of the Encoder and the LLMs, we take each chain-of-thought r in the training dataset D as an anchor, use LLM to generate the corresponding positive samples, use the other samples within the batch as negative samples, and then use contrastive learning to fine-tune the Encoder. The prompt template used to generate positive samples is detailed in Appendix H.3.</p><p>For chain-of-thought r, we prompt the LLM to generate a similar sentence r + as the positive sample. Following previous works <ref type="bibr">(Gao et al. 2022;</ref><ref type="bibr" target="#b72">Zhang, Zhang, and Zhou 2023)</ref>, we use the InfoNCE loss (Chen et al. 2020) to fine-tune the Encoder :</p><formula xml:id="formula_17">rp∈P os(r) -log g(r, rp) g(r, rp) + j∈N eg(r) g(r, rj)<label>(20)</label></formula><p>where the r and rp are the representations of r and its positive samples. P os(r) and N eg(r) refer to the positive set and the negative set for the chain-of-thought r. P os(r) = {rp1, rp2}, where rp1 is augmented representation of the same chain-of-thought r, obtained with different dropout masks, and rp2 is the representation of positive sample r + . j ∈ N eg(r) is the index of in-batch negative samples. g is a function: g(r, rp) = exp(r T rp/temp), where temp is a positive value of temperature in the contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate the effectiveness of our approach on three tasks: For the NLU tasks, we use the original datasets (in-distribution, ID) and the corresponding adversarial datasets (out-of-distribution, OOD) to verify the robustness of our method. Further details regarding the datasets are provided in Appendix C.4. The details regarding the evaluation can be found in Appendix C.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We compare our approach with three other few-shot prompting approaches to evaluate its effectiveness: Standard ICL, CoT and CoT-SC. Their detailed settings are presented in Appendix C.1. Detailed settings and implementations of our method Causal Prompting can be found in Appendix C.2 and Appendix C.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head><p>Table <ref type="table" target="#tab_2">1</ref> shows the comparison results between causal prompting and the aforementioned baselines. Expectedly, the performance of Standard ICL, CoT, and CoT-SC improves progressively, as each subsequent method is an enhanced version of its predecessor. It not only confirms the effectiveness of integrating CoT into ICL, consistent with <ref type="bibr">(Brown et al. 2020;</ref><ref type="bibr" target="#b47">Wei et al. 2022;</ref><ref type="bibr" target="#b76">Zhou et al. 2022</ref>), but also validates the efficacy of employing multiple sampling and voting strategies <ref type="bibr" target="#b44">(Wang et al. 2022)</ref>  delivers the best results across all metrics and datasets. It indicates that our prompting method can comprehensively improve the ability of LLM in all three tasks. Specifically, our method exhibits a more pronounced improvement in Math Reasoning and Multi-hop Question Answering tasks, with an average performance enhancement of approximately 5%-10%. This substantial increase underscores our method's greater efficacy in tackling more challenging problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Robustness Study</head><p>Recent causal-based works ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">More Experimental Results</head><p>For details on robustness studies, ablation experiments and hyperparameter experiments, please refer to the appendix:</p><p>• In Appendix E.1, we report the robustness study results of LLaMA2 and GPT3.5. • In Appendix E.2, we perform a detailed ablation analysis to evaluate three pivotal aspects: (1) the effectiveness of the NWGM approximation, (2) the impact of incorporating contrastive learning, (3) the impact of K-means clustering and weighting mechanism. • In Appendix E.3, we conduct additional hyperparameter experiments to explore the impact of the number of clusters K and the number of CoTs m on the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussion</head><p>In Appendix D, we discuss related works on the topics of prompting strategies and debiasing with causal inference. In Appendix A, we delve into five critical discussion questions (DQs) that are essential for understanding the contributions and limitations of our approach: (DQ1) In-depth analyses regarding the optimization of computational costs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We introduced Causal Prompting, a novel method for debiasing LLMs in NLP tasks by utilizing front-door adjustment in this work. The CoT generated by LLMs is employed as a mediator variable in the causal graph. Specifically, the causal effect between input prompt and output answer is decomposed into two distinct components, the causal effect from the input prompt to CoTs and from</p><p>CoTs to the answer. The former component is estimated by combining the CoT prompting with a Encoder-based clustering algorithm. The latter component is estimated by combining the ICL prompting with the NWGM approximation algorithm. Moreover, Contrastive learning is used to fine-tune the Encoder so that the representation space of the Encoder is aligned with the LLM to estimate the causal effect more accurately. Our experimental results demonstrate that Causal Prompting significantly improves performance across seven NLP tasks on both open-source and closed-source LLMs.</p><p>Causal Prompting addresses inherent biases in LLMs by scaling up during the inference phase, building upon the theory of frontdoor adjustment. This approach, which both enhances performance and yields debiased responses, aligns with the trend of obtaining optimal results at test time <ref type="bibr" target="#b32">(Snell et al. 2024;</ref><ref type="bibr" target="#b20">OpenAI 2024;</ref><ref type="bibr" target="#b29">Qu et al. 2024;</ref><ref type="bibr" target="#b4">Lightman et al. 2023)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Discussion</head><p>In this section, we will address the following Discussion Questions (DQ) to elucidate our contributions more clearly.</p><p>DQ1: How can we reduce computational costs incurred by additional operations?</p><p>We acknowledge that our proposed method requires more cost than CoT-SC or direct prompting. Compared to CoT-SC, Causal Prompting involves numerous additional operations, resulting in increased cost overhead. However, our approach is relatively cost-effective and the improved performance potentially leads to more faithful outcomes. Importantly, not every test instance necessitates a front-door adjustment. To determine whether a a front-door adjustment is needed for a given example, we employ a self-consistency metric, defined as the proportion of answers receiving the majority of votes. A front-door adjustment is executed if the self-consistency metric falls below a predefined threshold s. As shown in Figure <ref type="figure" target="#fig_4">5</ref>, adjusting the threshold s allows us to control the cost of the entire test dataset. In our experiments, the computational cost is quantified in terms of Floating Point Operations per Second (FLOPs). For a test set containing 1000 samples with an average sample length of 500, the inference time on LLaMA3 is approximately two hours using the vLLM framework <ref type="bibr">(Kwon et al. 2023</ref>). All computations using open-source LLMs were executed on an NVIDIA A100 80GB GPU. The value of the threshold s ranges from 0 to 1; a smaller s results in more samples requiring front-door adjustment and consequently increases the cost of FLOPs. To facilitate a fair comparison of equivalent costs, we set the number of votes for CoT-SC at m = 1, 5, 8, 10, 40, 80, 100. Our method achieves superior performance at equivalent costs. As computational costs increase, the performance of CoT-SC gradually reaches its upper limit, whereas the performance of our proposed method continues to rise. It indicates Causal Prompting has more potential to scale effectively with increased computational costs. DQ2: How does adjusting the threshold s affect performance?</p><p>We also explored the effect of the threshold s on different tasks on LLaMA3. As shown in Figure <ref type="figure" target="#fig_5">6</ref>, the performance of mathematical reasoning and multi-hop question answering tasks keeps improving as the threshold s increases. On the other hand, the performance on the NLU task first increases and then decreases, and when we apply the front-door adjustment to all samples (i.e., s = 1.0), the performance drops significantly. This is because we introduce the wrong and correct chain-of-thoughts in the NWGM algorithm part, and the labels of the two chain-of-thoughts are usually opposite, which is easy to cause LLM to change the correct answer into the wrong one, especially in classification tasks such as NLU. The best threshold s across different backbone LLMs and different datasets are shown in Table <ref type="table" target="#tab_7">3</ref>. Table <ref type="table" target="#tab_2">1</ref> of the submitted manuscript reports the model's performance when the threshold s takes the best value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DQ3: What are the effects of employing contrastive learning methods?</head><p>To better explore the importance of contrastive learning, we present a visualization of the embeddings of the chain-of-thought obtained by the vanilla Encoder and the Encoder trained by contrastive learning with T-SNE (Van der Maaten and Hinton 2008). As shown in Figure <ref type="figure" target="#fig_6">7</ref>, the vanilla Encoder fails to distinctly separate different categories, blending multiple chain-of-thoughts into indistinct representations. In contrast, the Encoder that is trained by contrastive learning exhibits a clear delineation between different categories. This shows that contrastive learning can align the representation spaces of the encoder and LLMs, allowing the encoder to learn how to distinguish the semantics between different chain-of-thoughts generated by the LLMs. In Appendix E.2, we present quantitative analyses to further substantiate the effectiveness of contrastive learning.  The test sample n</p><p>The number of demonstration examples in the prompt m</p><p>The number of CoTs generated by LLM K</p><p>The number of clusters for the K-means clustering algorithm T</p><p>The query times to LLM for each intervention prompt  DQ4: Why do we not need any additional baselines?</p><p>See Appendix C.1, where we list all the baselines used to compare with our proposed method. However, numerous other prompting strategies such as ToT <ref type="bibr" target="#b67">(Yao et al. 2024)</ref> or <ref type="bibr">GoT (Besta et al. 2024)</ref> have not been explored as baselines. We do not conclude these strategies based on the following three primary considerations: First, we focus on solving the more fundamental problem of prompting methods: the estimation of the causal effect between the input prompt and the response of the LLM. The efficacy of our causal prompting approach is substantiated by the experimental results presented. Second, more complex prompting methods require the construction of intricate causal graphs. In other words, building causal graphs for these advanced prompting methods is challenging due to their involvement with cycles and numerous mediating variables. As an early work on combining causal inference with LLM, we start with the basic prompting method. Finally, our approach is not specifically intended to improve the ability of LLMs to solve complex problems, but rather to hope that LLMs generate more causal, faithful and unbiased answers. Therefore, we only experimented on the most commonly used tasks and did not compare them with other prompting methods designed for complex tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DQ5: Why not consider the new bias from the CoTs generated by LLMs?</head><p>In fact, we cannot guarantee that the CoTs generated by LLM do not introduce new biases. In SCM, it is possible that U points to R, and there is even the possibility of the X -R link and the R -A link being confounded by U1 and U2 respectively. However, it is very difficult to deal with such SCM, and following previous works <ref type="bibr">(Wu et al. 2024a;</ref><ref type="bibr" target="#b59">Xu et al. 2015;</ref><ref type="bibr" target="#b36">Tian et al. 2022;</ref><ref type="bibr">Chen et al. 2023a;</ref><ref type="bibr" target="#b71">Zhang, Zhang, and Zhou 2024;</ref><ref type="bibr">Yang, Zhang, and Cai 2021;</ref><ref type="bibr" target="#b77">Zhu et al. 2023;</ref><ref type="bibr">Wang et al. 2023a;</ref><ref type="bibr" target="#b61">Xu et al. 2023;</ref><ref type="bibr" target="#b17">Niu et al. 2021)</ref>, we only make the assumption of a single confounder. We focus on the confounder between X and A and ignore the confounder of R with other variables, aligning our causal graph with the front-door criterion. In practice, as shown in Figure <ref type="figure" target="#fig_7">1</ref> of the main body of the submitted manuscript, we observe that LLM can perform correct reasoning at the beginning, but it is often easily confused by bias in the last step of deriving the answer. This shows the rationality of our assumed SCM.</p><p>Additionally, our approach clusters multiple CoTs to capture diverse reasoning paths. This diversity acts as a buffer, reducing the likelihood that any single biased pathway dominates the model's final decision. This is consistent with the principles of the front-door criterion, which relies on mediating variables to isolate the effect of the causal variable of interest.</p><p>To further mitigate the confounder of R with other variables, we implement the NWGM approximation by In-Context Learning. Our NWGM algorithm enables LLM to improve the quality of the chain of thoughts by using ground truth demonstrations and maximally prevents the introduction of new bias when LLM generates the chain of thoughts.</p><p>In the future, we will try more complex SCM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Causal Prompting Algorithm B.1 Notations</head><p>The notations used in the approach are shown in </p><formula xml:id="formula_18">{d ↑ j } N j=1 ← Sort(D, r k , {d j } N j=1 )</formula><p>13:</p><formula xml:id="formula_19">P iter r k ← [d ↑ l , ..., d ↑ 1 , q test ] 14: {(r ip k,t , a k,t )|t = 1, ..., T } ← LLM(P iter r k , r k ) 15: P (A|do(r k )) ← T t=1 I(A=a k,t ) T 16: end for 17: P (A|do(X)) ← K k=1 |C k | m • T t=1 I(A=a k,t ) T</formula><p>18: return argmax A (P (A|do(X)))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Algorithm Details</head><p>As shown in Algorithm 1, we describe the operation flow of Causal Prompting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Experimental Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Settings</head><p>Demonstration Construction For the GSM8K and MATH datasets, we directly use the gold rationale in the dataset as the chain-ofthought for the demonstration. For multi-hop question answering and NLU tasks without gold rationale, we use a few manually constructed demonstrations to prompt the LLM to generate chain-of-thoughts and answers for all examples in the dataset. For the samples with wrong answers, we provide the LLM with the correct answers and then ask the LLM to generate the correct chain-of-thoughts. See Appendix H.4 for the prompt template used to generate the demonstration examples. Finally, we retain the wrong and correct chain-of-thoughts and use them to construct the training set. Note that to better evaluate the debiasing effect of our method, we only use the original dataset to build demonstration examples without including the adversarial dataset, and evaluate on both original and adversarial datasets.</p><p>Demonstration Selection To fair comparison, the same demonstration samples are utilized across all few-shot prompting methods. For each instance, the most relevant demonstration samples are selected based on the similarity of their embeddings with the question. These selected demonstration samples are then concatenated into the prompt, as exemplified in the Appendix H.1 for CoT prompting. Specifically, for Math Reasoning and Multi-hop QA tasks, 4-shot and 2-shot settings are employed, respectively, corresponding to n = 4 and n = 2 in Equation 6 of the submitted manuscript. For NLU tasks, we maintain a balanced label space by including one demonstration sample for each category. For ABSA and NLI, which are 3-way classification tasks, n = 3 is adopted, while for FV, a 2-way task, n = 2 is used. After the application of NWGM-based causal intervention, as described in Section 3.2, and l different demonstration samples are selected to be incorporated into the prompt as shown in the prompt templates of CoT Improvement based on NWGM approximation in Appendix H.2. For the mathematical reasoning task, l = 2 in Equation 16 of the submitted manuscript. For the multi-hop question answering task, l = 1. For the ABSA and NLI tasks, l = 3. For the FV task, we set l = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Adversarial Category Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ReverseTarget</head><p>Reverse the sentiment of the target aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ReverseNonTarget</head><p>Reverse the sentiment of the non-target aspects with originally the same sentiment as target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AddDiff</head><p>Add aspects with the opposite sentiment from the target aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NLI AddSent</head><p>Add some meaningless sentence to premise, which do not change the semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NumWord</head><p>Find some num words in sentences and replace them with different num word. SwapAnt Find some keywords in sentences and replace them with their antonym.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FV Symmetric</head><p>For each claim-evidence pair, generating a synthetic pair that holds the same relation (e.g. SUPPORTS or REFUTES) but expressing a different, contrary, fact.</p><p>Table <ref type="table">5</ref>: Multiple adversarial categories for ABSA, NLI, and FV tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Implementation Details</head><p>Details of LLM We evaluate our prompting method on the open-source LLaMA-2-7B-Chat <ref type="bibr" target="#b37">(Touvron et al. 2023</ref>) 1 and LLaMA-3-8B-Instruct (AI@Meta 2024) 2 using Transformer <ref type="bibr" target="#b50">(Wolf et al. 2019</ref>) library, as well as the closed-source GPT-3.5-turbo-0125 (OpenAI 2022) 3 . The generation hyperparameters remain consistent across all prompting methods: temperature is set to 0.7, and top_p is set to 0.9. Following previous work <ref type="bibr" target="#b10">(Lyu et al. 2023)</ref>, we set the number of votes in COT-SC is 40. In our method, the number of chain-of-thoughts generated in the first part is m = 40, and then these chain-of-thoughts are clustered into K = 8. For each chain-of-thought representing the cluster center, we generated T = 10 answers based on the prompt modified by intervention. Finally, the K • T = 80 answers were weighted voting to get the final answer. Multi-hop Question Answering For the HotpotQA <ref type="bibr" target="#b66">(Yang et al. 2018</ref>) dataset, to reduce the experimental cost, we randomly selected 5000 samples from the official training set 7 as our training set and 1000 samples from the official validation set 8 as our test set. For the MuSiQue <ref type="bibr" target="#b38">(Trivedi et al. 2022</ref>) dataset, we use the official dataset split of MuSiQue-Answerable version 9 , and we experiment on the more challenging part of the dataset with hop ≥ 3. After extracting the data with a hop ≥ 3, the number of training sets is 5562 and the number of test sets is 1165. For both datasets above, we extract the support documents to form the paragraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details of Encoder</head><p>Natural Language Understanding For the Aspect-based Sentiment Analysis (ABSA) and Natural Language Inference (NLI) tasks, we use SemEval2014-Laptop <ref type="bibr" target="#b27">(Pontiki et al. 2016</ref>) and MNLI-m <ref type="bibr" target="#b49">(Williams, Nangia, and Bowman 2017)</ref> as the original datasets (in-distribution, ID) and the corresponding transformation data generated by TextFlint <ref type="bibr" target="#b43">(Wang et al. 2021)</ref> as the adversarial datasets (out-of-distribution, OOD).</p><p>For the FV task, we use FEVER <ref type="bibr" target="#b35">(Thorne et al. 2018)</ref> as the ID dataset and its adversarial dataset Symmetric FEVER <ref type="bibr" target="#b31">(Schuster et al. 2019)</ref> as the OOD dataset. To reduce the experimental cost, we randomly sample a certain number of samples from these NLU datasets for experiments. See Table <ref type="table">5</ref> and Table <ref type="table" target="#tab_11">6</ref> for details of the adversarial dataset generation method and data statistics for the NLU dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Evaluation</head><p>Following previous works <ref type="bibr" target="#b69">(Ye et al. 2023;</ref><ref type="bibr" target="#b10">Lyu et al. 2023)</ref>, for Math Reasoning and NLU tasks, we adopt the label classification accuracy (Acc) as the evaluation metric, and for Multi-hop QA tasks, we adopt the Exact Match (EM) and F1 <ref type="bibr" target="#b66">(Yang et al. 2018)</ref> as the evaluation metric. Following previous work <ref type="bibr" target="#b10">(Lyu et al. 2023)</ref>, we extract the text span following the keyword "answer is" as the answer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Related Works D.1 Prompting Strategies</head><p>The performance of LLMs on downstream tasks is largely influenced by the employed prompting strategy <ref type="bibr" target="#b30">(Sahoo et al. 2024)</ref>. Current prompting strategies primarily improve the quantity and robustness through two approaches. On one hand, incorporating a few labeled examples within the instruction can significantly enhance the performance of LLM, occasionally even better than fine-tuned models <ref type="bibr">(Brown et al. 2020;</ref><ref type="bibr">Chung et al. 2022;</ref><ref type="bibr">Dong et al. 2022)</ref>. This method is referred to as In-Context Learning (ICL). Several works involve the modification of instruction examples to address the issue of LLMs being particularly sensitive to the designing of demonstration examples, including example selection <ref type="bibr" target="#b5">(Liu et al. 2021)</ref>, example format (Dong et al. 2022), example label <ref type="bibr" target="#b16">(Min et al. 2022;</ref><ref type="bibr" target="#b70">Yoo et al. 2022)</ref>, and example order <ref type="bibr" target="#b8">(Lu et al. 2021)</ref>. Following this way, recent works have suggested that including chain-of-thoughts (CoTs) in the context of these examples can further augment the quality of LLM's responses <ref type="bibr" target="#b18">(Nye et al. 2021;</ref><ref type="bibr" target="#b0">Lampinen et al. 2022;</ref><ref type="bibr" target="#b47">Wei et al. 2022)</ref>. On the other hand, to tackle the instability in the outputs of LLMs, attributable to the "multinomial sampling" (Holtzman et al. 2019), some works involve enhancement by employing multiple sampling and voting mechanisms to determine the final answer <ref type="bibr" target="#b5">(Chen et al. 2021;</ref><ref type="bibr" target="#b44">Wang et al. 2022;</ref><ref type="bibr" target="#b2">Li et al. 2022)</ref>, which is referred to as self-consistency (SC). Moreover, for more complex tasks, many other prompting methods based on multiple sampling have been proposed, such as React <ref type="bibr" target="#b68">(Yao et al. 2022)</ref>, ToT <ref type="bibr" target="#b67">(Yao et al. 2024), and</ref><ref type="bibr">GoT (Besta et al. 2024)</ref>.</p><p>In this work, we primarily combine these two directions by modeling front-door adjustments to address bias issues in LLM prompting. CoT is utilized as a mediator variable. In such scenarios, we further employ NWGM approximation to select the demonstration, which can represent the expectation of the entire dataset and help the model generate an unbiased answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Debiasing with Causal Inference</head><p>Causal inference uses scientific methods to identify causal relationships between variables <ref type="bibr" target="#b23">(Pearl, Glymour, and Jewell 2016)</ref>. Because of its rigorous theoretical guarantees and mature causal modeling tools <ref type="bibr" target="#b21">(Pearl 2019)</ref>, causal inference has advantages in debiasing work. Recently, causal inference has been widely used in natural language processing <ref type="bibr">(Feder et al. 2022;</ref><ref type="bibr">Chen et al. 2023b</ref>) and computer vision <ref type="bibr">(Yang, Zhang, and Cai 2021;</ref><ref type="bibr">Wu et al. 2024d,e,c;</ref><ref type="bibr" target="#b28">Qin, Fang, and Xue 2024)</ref>.</p><p>Some works apply counterfactual reference to remove the bias of the model <ref type="bibr" target="#b61">(Xu et al. 2023;</ref><ref type="bibr">Guo et al. 2023;</ref><ref type="bibr" target="#b17">Niu et al. 2021;</ref><ref type="bibr" target="#b62">Xu et al. 2024</ref>). For instance, <ref type="bibr" target="#b17">Niu et al. (2021)</ref> debias the visual question answering task by subtracting the predictions of the language-only model from the predictions of the vision-language model to reduce linguistic biases in the integrated system. Other work uses causal interventions for debiasing, including backdoor adjustment <ref type="bibr" target="#b36">(Tian et al. 2022;</ref><ref type="bibr" target="#b77">Zhu et al. 2023;</ref><ref type="bibr">Wang et al. 2023a;</ref><ref type="bibr">Wu et al. 2024b</ref>) and front-door adjustment <ref type="bibr">(Yang et al. 2021;</ref><ref type="bibr">Yang, Zhang, and Cai 2021;</ref><ref type="bibr" target="#b71">Zhang, Zhang, and Zhou 2024)</ref>. In the era of LLMs, several studies have integrated LLMs with causal inference techniques <ref type="bibr">(Jin et al. 2023a;</ref><ref type="bibr" target="#b12">Lyu et al. 2024;</ref><ref type="bibr">Jin et al. 2023b;</ref><ref type="bibr" target="#b33">Stolfo et al. 2023)</ref>. However, some of these studies do not fully adhere to the structural causal model, relying excessively on heuristic methods <ref type="bibr" target="#b9">(Lu et al. 2022;</ref><ref type="bibr">Wang et al. 2023a;</ref><ref type="bibr">Zhang et al. 2023;</ref><ref type="bibr" target="#b34">Tang et al. 2023)</ref>; others employ overly simplistic causal diagrams, which are inadequate for complex tasks <ref type="bibr">(Abdali et al. 2023;</ref><ref type="bibr" target="#b12">Lyu et al. 2024)</ref>. Overall, counterfactual inference necessitates the acquisition of logits from LLM outputs, whereas back-door adjustment demands modeling of specific values of confounding variables. In contrast, front-door adjustment allows causal intervention without access to the values of confounding variables or logits of LLM outputs. This makes front-door adjustment particularly apt for application in LLM scenarios.</p><p>Therefore, we propose to debias the prompting methods by causal intervention based on front-door adjustment. The work most closely related to ours is DeCOT <ref type="bibr">(Wu et al. 2024a</ref>); DeCoT <ref type="bibr">(Wu et al. 2024a</ref>) debiases the chain-of-thoughts of LLMs by incoroporating counterfactual knowledge and front-door adjustment. Both our work and DeCoT use the front-door adjustment on LLMs. Howerver, DeCoT requires the introduction of instrumental variables to model counterfactual knowledge, limiting its applicability to knowledge-intensive tasks. In contrast, our approach is versatile and can be applied to a wide range of tasks. Our approach, on one hand, adapts the traditional front-door adjustment to make it suitable for the task of LLM prompting. On the other hand, it adheres more closely to the established principles of the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E More Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Robustness Study</head><p>We also provide robustness studies on LLaMA2 and GPT3.5 in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Ablation Study</head><p>In the ablation study presented in Table <ref type="table" target="#tab_14">8</ref>, we perform a detailed ablation analysis to evaluate three pivotal aspects: (1) the effectiveness of the NWGM approximation, (2) the impact of incorporating contrastive learning, (3) the impact of K-means clustering and weighting mechanism. This analysis spans four datasets, including GSM8K, MATH, HotpotQA, and MuSiQue, utilizing the LLaMA3-8B model. The comparison results between Causal Prompting and the baselines (Table <ref type="table" target="#tab_2">1</ref> of the submitted manuscript) and the results of robustness studies (Tables 2 of the submitted manuscript) demonstrate that the Causal Prompting method consistently exhibits superior performance across GPT-3.5, LLaMA3, and LLaMA2, showing high performance across various test metrics. This indicates that the Causal Prompting method possesses excellent generalizability and stability. Since GPT-3.5 and LLaMA3 perform consistently, we only perform ablation experiments on LLaMA3 in order to reduce the economic cost.</p><p>Effectiveness of the NWGM The NWGM approximation is employed in the Estimation of P (A|do(r)) to perform the back-door adjustment, where we select the ICL demonstration that is most similar to the query and put the most similar demonstration samples closer to the test samples, as detailed in Section 3.2. We evaluate the impact of the NWGM approximation by comparing the standard setup against two variants of NWGM-Reverse and NWGM-Random, respectively. NWGM-Reverse means that we reverse the order of standard ICL demonstrations, that is,</p><formula xml:id="formula_20">P iter r k = [d ↑ 1 , ..., d ↑ n , q test ]</formula><p>with the same order of KATE <ref type="bibr" target="#b5">(Liu et al. 2021</ref>) method. NWGM-Random denotes that ICL demonstrations are selected at random from the training set D. The performance decline observed in these two variants validates the effectiveness of our approach in selecting the most relevant samples, thereby enabling a more accurate estimation of P (A|do(r)).</p><p>Impact of contrastive learning The second aspect of our ablation study is to assess the role of contrastive learning. By removing contrastive learning, we can observe a decline in performance metrics compared to Causal Prompting. For example, there is a decrease of 1.37% in accuracy on GSM8K and 3.20% on MATH. It indicates that contrastive learning facilitates the alignment of feature representations between the Encoder and LLMs.</p><p>Impact of K-means clustering and weighting The third aspect of our ablation study is to explore the contribution of K-means clustering, and the weighting mechanism. w/o K-means means that K chain-of-thoughts are randomly selected in the first stage of front-door adjustment, and P (r|do(X)) = 1/K is set. w/o Weighting means that instead of using P (r|do(X)) and P (A|do(r)) to weighted sum the final K * T answers, a majority vote is taken on these answers. Regarding the influence of K-means clustering, removing the K-means clustering will destroy the estimate of P (r|do(X)) in the front-door adjustment, leading to a decrease in model performance. Removing weighting destroys both the estimation of P (r|do(X)) and P (A|do(r)) in the front-door adjustment, leading to a significant decrease in model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Hyperparameter Study</head><p>We conduct additional hyperparameter experiments to explore the impact of the number of clusters K and the number of CoTs m on the performance. Impcat of the number of clusters K As shown in Table <ref type="table" target="#tab_15">9</ref>, we conducted further experiments with varying cluster numbers and included an analysis of how the choice of cluster number influences the results. It can be observed that when the number of clusters increases from 1 to 8, the performance improvement is obvious, and from 8 to 20, the performance remains stable or even decreases. Since the number of chain-of-thoughts m is limited, P (r|do(X)) cannot be accurately estimated when the number of clusters is too small or too large. Therefore, considering both performance and cost, we choose the number of clusters K = 8.</p><p>Impact of the number of CoTs m As shown in Table <ref type="table" target="#tab_16">10</ref>, we show the performance with different numbers of chain-of-thoughts. It can be found that when the number of CoTs increases from 8 to 40, the performance improvement is significant, and when the number of CoTs increases from 40 to 100, the performance improvement is slight. It demonstrates that the number of chain of thought m = 40 is already sufficient to estimate P (r|do(X)). Therefore, considering the cost issue, we choose the number of CoTs m = 40.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Limitations</head><p>Although our results already outperform baselines overall, our work still suffers from the following limitations.</p><p>• We evaluate the effectiveness of our approach on three tasks: Math Reasoning, Multi-hop Question Answering, and Natural Language Understanding. We need to test the effectiveness of Causal Prompting on other more complex tasks. • As mentioned in Appendix A, although our method outperforms baselines at the same cost, how to reduce the cost of prompt remains an important issue. • We only evaluated the effectiveness of Causal Prompting on three Large Language Models, LLaMA2-7B, LLaMA3-8B and GPT-3.5, and we need to evaluate our method on more Large Language Models of different kinds and scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Case Study</head><p>In this section, we provide two running samples from GSM8K and HotpotQA with intermediate output for each module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 Case on GSM8K</head><p>Intermediate output details of a GSM8K example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head><p>A merchant wants to make a choice of purchase between 2 purchase plans: jewelry worth $5,000 or electronic gadgets worth $8,000. His financial advisor speculates that the jewelry market will go up 2.5% while the electronic gadgets market will rise 1.2% within the same month. If the merchant is looking to maximize profit at the end of this month by making a choice, how much profit would this be? (The correct answer is 125) Outputs from CoT-SC The number of chain-of-thoughts m=40. Answer voting results: P (A = 96|X) = 19/40 = 0.475 P (A = 125|X) = 18/40 = 0.45 ... (Omit answers with fewer votes) Therefore, the final answer obtained according to the COT-SC method is 96.</p><p>An example of an error is shown:</p><p>Let's calculate the future value of each option: Option 1: Jewelry Current value = $5,000 Expected increase = 2.5% of $5,000 = $125 Future value = $5,000 + $125 = $5,125 Option 2: Electronic Gadgets Current value = $8,000 Expected increase = 1.2% of $8,000 = $96 Future value = $8,000 + $96 = $8,096 Since the merchant wants to maximize profit, they should choose the option with the higher future value. In this case, it's Option 2: Electronic Gadgets with a future value of $8,096. The profit would be the difference between the future value and the current value: $8 ,096 -$8,000 = $96.</p><p>Therefore, the answer is $96.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cluster results</head><p>The number of chain-of-thoughts selected from clustering results k=8. <ref type="figure">--------------------</ref>CoT-1: P (r1|X) = 0.375 <ref type="figure">--------------------</ref>Let's calculate the profit for each option: Option 1: Jewelry * Current value: $5,000 * Expected increase: 2.5% of $5,000 = $125 * Future value: $5,000 + $125 = $5,125 * Profit: $5,125 -$5,000 = $125 Option 2: Electronic Gadgets * Current value: $8,000 * Expected increase: 1.2% of $8,000 = $96 * Future value: $8,000 + $96 = $8,096 * Profit: $8,096 -$8,000 = $96 Comparing the profits, the merchant would make a higher profit by choosing the jewelry option, which is $125. Therefore, the answer is $125.</p><p>--------------------CoT-2: P (r2|X) = 0.025 --------------------Let's analyze the situation step by step: 1. The merchant has to choose between jewelry worth $5,000 and electronic gadgets worth $8,000. 2. The financial advisor predicts that the jewelry market will go up 2.5% within the same month. This means that the value of the jewelry will increase by 2.5% of $5,000, which is: $5,000 x 0.025 = $125 So, the value of the jewelry will become: $5,000 + $125 = $5,125 3. The financial advisor predicts that the electronic gadgets market will rise 1.2% within the same month. This means that the value of the electronic gadgets will increase by 1.2% of $8,000, which is: $8,000 x 0.012 = $96 So, the value of the electronic gadgets will become: $8,000 + $96 = $8,096 4. Now, let's compare the profit from each option: Option 1: Jewelry ($5,125 -$5,000) = $125 Option 2: Electronic Gadgets ($8,096 -$8,000) = $96 Since $125 is greater than $96, the merchant would make a maximum profit by choosing the jewelry option, which is $125.</p><p>--------------------CoT-3: P (r3|X) = 0.075 --------------------Let's analyze the situation: Option 1: Jewelry worth $5,000 * The jewelry market will go up 2.5%, so the value will increase by 2.5% of $5,000 = $125 * The merchant will sell the jewelry for $5,000 + $125 = $5,125 * The profit = Selling price -Cost price = $5,125 -$5,000 = $125 Option 2: Electronic gadgets worth $8,000 * The electronic gadgets market will go up 1.2%, so the value will increase by 1.2% of $8,000 = $96 * The merchant will sell the electronic gadgets for $8,000 + $96 = $8,096 * The profit = Selling price -Cost price = $8,096 -$8,000 = $96 Comparing the profits, we can see that the merchant would make a profit of $125 if they choose the jewelry option, and a profit of $96 if they choose the electronic gadgets option. Since $125 is greater than $96, the merchant would maximize their profit by choosing the jewelry option.</p><p>- <ref type="figure">-------------------</ref>CoT-4: P (r4|X) = 0.025 <ref type="figure">--------------------Let'</ref>s analyze the situation step by step: 1. If the merchant chooses to buy jewelry worth $5,000, its value will increase by 2.5% in the next month. To find the increase in value, multiply the current value by the percentage increase: $5,000 x 2.5% = $5,000 x 0.025 = $125 The total value of the jewelry after the increase will be: $5,000 + $125 = $5,125 2. If the merchant chooses to buy electronic gadgets worth $8,000, its value will increase by 1.2% in the next month. To find the increase in value, multiply the current value by the percentage increase: $8,000 x 1.2% = $8,000 x 0.012 = $96 The total value of the electronic gadgets after the increase will be: $8,000 + $96 = $8,096 3. To maximize profit, the merchant should choose the option that results in the highest total value. In this case, the merchant should choose to buy electronic gadgets worth $8,096, which is $976 more than the value of the jewelry. The profit will be the difference between the increased value of the electronic gadgets and their original price: $8,096 -$8,000 = $96 So, the maximum profit the merchant can make is $96.</p><p>--------------------CoT-5: P (r5|X) = 0.15 --------------------Let's calculate the value of the jewelry after the market goes up 2.5%: Initial value: $5,000 Percentage increase: 2.5% Value after increase: $5,000 + (2.5% of $5,000) = $5,000 + $125 = $5,125 Now, let's calculate the value of the electronic gadgets after the market goes up 1.2%: Initial value: $8,000 Percentage increase: 1.2% Value after increase: $8,000 + (1.2% of $8,000) = $8,000 + $96 = $8,096 Since the merchant wants to maximize profit, he should choose the option that gives him the highest value after the market increase. In this case, the electronic gadgets option is worth $8,096, which is higher than the jewelry option worth $5,125. The profit would be the difference between the value of the chosen option and its initial value: Profit = $8,096 -$8,000 = $96 Therefore, the answer is $96.</p><p>--------------------CoT-6: P (r6|X) = 0.025 --------------------Let's analyze the situation step by step: 1. The merchant has two options: purchasing jewelry worth $5,000 or electronic gadgets worth $8,000. 2. The financial advisor predicts that the jewelry market will rise by 2.5%, which means the value of the jewelry will increase by 2.5% of $5,000 = $125. 3. The value of the jewelry will then become $5,000 + $125 = $5,125. 4. The financial advisor also predicts that the electronic gadgets market will rise by 1.2%, which means the value of the electronic gadgets will increase by 1.2% of $8,000 = $96. 5. The value of the electronic gadgets will then become $8,000 + $96 = $8,096. 6. The merchant wants to maximize profit, which means they should choose the option that results in the highest profit. Comparing the two options: * Jewelry: $5,125 (new value) -$5,000 (original value) = $125 profit * Electronic gadgets: $8,096 (new value) -$8,000 (original value) = $96 profit The merchant should choose the jewelry option, as it results in a higher profit of $125 compared to $96 for the electronic gadgets. Therefore, the answer is $125.</p><p>- <ref type="figure">-------------------</ref>CoT-7: P (r7|X) = 0.15 <ref type="figure">--------------------</ref>Let's calculate the profit for each option: Option 1: Jewelry worth $5,000 The jewelry market will rise 2.5%, so the value of the jewelry will increase to: $5,000 x (1 + 0.025) = $5,000 x 1.025 = $5,125 Profit = Selling price -Purchase price = $5,125 -$5,000 = $125 Option 2: Electronic gadgets worth $8,000 The electronic gadgets market will rise 1.2%, so the value of the gadgets will increase to: $8,000 x (1 + 0.012) = $8,000 x 1.012 = $8,096 Profit = Selling price -Purchase price = $8,096 -$8,000 = $96 Since the merchant is looking to maximize profit, they should choose Option 1, which yields a profit of $125.</p><p>--------------------CoT-8: P (r8|X) = 0.175 --------------------Let's analyze the situation step by step: 1. Jewelry worth $5,000 with a 2.5% increase: New value = $5,000 + (2.5% of $5,000) = $5,000 + $125 = $5,125 Profit = New value -Original value = $5,125 -$5,000 = $125 2. Electronic gadgets worth $8,000 with a 1.2% increase: New value = $8,000 + (1.2% of $8,000) = $8,000 + $96 = $8,096 Profit = New value -Original value = $8,096 -$8,000 = $96 Comparing the profits, the merchant would make a profit of $125 if they choose the jewelry plan and a profit of $96 if they choose the electronic gadgets plan. Since the merchant wants to maximize profit, they should choose the jewelry plan, which would yield a profit of $125.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intervention results</head><p>For the above eight chain-of-thoughts, we use the NWGM algorithm to perform causal intervention operations on them respectively. We can then compute the causal effect between the chain-of-thought and the answer.</p><p>P (A = 125|do(r1)) = 9/10 = 0.9 P (A = 96|do(r1)) = 0/10 = 0.0 P (A = 125|do(r2)) = 10/10 = 1.0 P (A = 96|do(r2)) = 0/10 = 0.0 P (A = 125|do(r3)) = 10/10 = 1.0 P (A = 96|do(r3)) = 0/10 = 0.0 P (A = 125|do(r4)) = 0/10 = 0.0 P (A = 96|do(r4)) = 8/10 = 0.8 P (A = 125|do(r5)) = 0/10 = 0.0 P (A = 96|do(r5)) = 10/10 = 1.0 P (A = 125|do(r6)) = 9/10 = 0.9 P (A = 96|do(r6)) = 1/10 = 0.1 P (A = 125|do(r7)) = 8/10 = 0.8 P (A = 96|do(r7)) = 0/10 = 0.0 P (A = 125|do(r8)) = 10/10 = 1.0 P (A = 96|do(r8)) = 0/10 = 0.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Final results</head><p>The final answer is obtained by performing a weighted voting as follows: P (A = 125|do(X)) = 0.375 * 0.9 + 0.025 * 1.0 + 0.075 * 1.0 + 0.025 * 0.0 + 0.15 * 0.0 + 0.025 * 0.9 + 0.15 * 0.8 + 0.175 * 1.0 = 0.755 P (A = 96|do(X)) = 0.375 * 0.0 + 0.025 * 0.0 + 0.075 * 0.0 + 0.025 * 0.8 + 0.15 * 1.0 + 0.025 * 0.1 + 0.15 * 0.0 + 0.175 * 0.0 = 0.1725 Finally, we chose the answer with the largest weight as the final answer. Therefore, the final answer obtained according to the Causal Prompting method is 125.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 Case on HotpotQA</head><p>Intermediate output details of a HotpotQA example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>The Walton family is an American family whose collective fortune makes them among the richest families in the world. The majority of their wealth derives from the heritage of Bud and Sam Walton, who were the co-founders of the world's largest retailer, Walmart. The three most prominent living members (Jim, Rob and Alice) have consistently been in the top ten of the "Forbes" 400 since 2001, as were John ( 2005) and Helen <ref type="bibr">(d. 2007)</ref> prior to their deaths. Christy Walton took her husband John's place after his death. Helen Robson Kemper Walton <ref type="bibr">(December 3, 1919</ref><ref type="bibr">-April 19, 2007)</ref>  An example of an error is shown:</p><p>Step 1: Identify the prominent Walton family member who died after John died in 2005. Helen Robson Kemper Walton died in 2007.</p><p>Step 2: Determine who Helen was married to. Helen was the wife of Sam Walton.</p><p>Step 3: Identify who took Helen's place after her death. Christy Walton took her husband John's place after his death.</p><p>Step 4: Determine who John is. John is the husband of Christy Walton.</p><p>Step 5: Combine the information to answer the question. The husband of the prominent Walton family member who died after John died in 2005 is John.</p><p>Therefore, the answer is: John.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cluster results</head><p>The number of chain-of-thoughts selected from clustering results k=8.</p><p>--------------------CoT-1: P (r1|X) = 0.325 <ref type="figure">--------------------</ref>Step 1: Identify the prominent Walton family member who died after John died in 2005. According to the text, Helen Robson Kemper Walton died in 2007.</p><p>Step 2: Determine who Helen's husband was. According to the text, Helen was the wife of Sam Walton.</p><p>Step 3: Determine who John's wife was. According to the text, John's wife was Christy Walton.</p><p>Step 4: Combine the information to answer the question. Since Helen was Sam's wife and Christy is John's wife, it means that John is not Helen's husband. Therefore, the answer is: Sam Walton.</p><p>--------------------CoT-2: P (r2|X) = 0.25 <ref type="figure">--------------------</ref>Step 1: Identify the prominent Walton family member who died after John died in 2005. The prominent Walton family member who died after John died in 2005 is Helen (d. 2007).</p><p>Step 2: Determine who Helen was married to. Helen was married to Sam Walton, the founder of Walmart and Sam's Club.</p><p>Step 3: Identify the current spouse of Helen. Christy Walton took her husband John's place after his death.</p><p>Step 4: Determine who John is. John is Christy Walton's husband.</p><p>Step 5: Combine the information to answer the question. Helen's husband after John died in 2005 is John, who is also Christy Walton's husband.</p><p>Therefore, the answer is: John.</p><p>--------------------CoT-3: P (r3|X) = 0.075 --------------------Step 1: Identify the prominent Walton family member who died after John died in 2005. The prominent Walton family member who died after John died in 2005 is Helen Robson Kemper Walton.</p><p>Step 2: Determine the husband of Helen Robson Kemper Walton. Helen Robson Kemper Walton was the wife of Sam Walton.</p><p>Step 3: Combine the information to answer the question. Since John died in 2005, it is likely that the question is asking about the husband of Helen Robson Kemper Walton after John's death. Since Helen was married to Sam Walton, the correct answer is that there is no husband of Helen Robson Kemper Walton after John's death, as Sam Walton passed away before John.</p><p>Therefore, the answer is: There is no answer (as Helen Robson Kemper Walton was already married to Sam Walton and John had passed away).</p><p>--------------------CoT-4: P (r4|X) = 0.125 <ref type="figure">--------------------</ref>Step 1: Identify the prominent Walton family member who died after John died in 2005. The prominent Walton family member who died after John died in 2005 is Helen Robson Kemper Walton.</p><p>Step 2: Determine who Helen's husband was. Helen's husband was Sam Walton, the founder of Walmart and Sam's Club.</p><p>Step 3: Since John died in 2005, it is likely that Helen's husband John is referring to John Walton, who died in 2005. This means Christy Walton took John's place after his death, as stated in the context.</p><p>Step 4: Therefore, the husband of the prominent Walton family member who died after John died in 2005 is John Walton.</p><p>Therefore, the answer is: John Walton.</p><p>--------------------CoT-5: P (r5|X) = 0.125 --------------------</p><p>Step 1: Identify the prominent Walton family member who died after John died in 2005. Helen Robson Kemper Walton died in 2007, after John Walton's death in 2005.</p><p>Step 2: Determine who Helen Robson Kemper Walton was married to. Helen Robson Kemper Walton was married to Sam Walton.</p><p>Step 3: Determine who took Sam Walton's place after his death. Sam Walton's wife Helen took her husband's place after his death.</p><p>Step 4: Identify who took John Walton's place after his death. Christy Walton took her husband John's place after his death.</p><p>Step 5: Combine the information to answer the question. Since Christy Walton took John' s place after his death, it can be inferred that John was Christy's husband.</p><p>Step 6: Therefore, the answer is: John Walton.</p><p>--------------------CoT-6: P (r6|X) = 0.025 --------------------</p><p>Step 1: Identify the Walton family member who died after John died in 2005. The Walton family member who died after John died in 2005 is Helen Robson Kemper Walton.</p><p>Step 2: Determine who Helen Robson Kemper Walton was married to. According to the context, Helen was the wife of Sam Walton, the founder of Walmart and Sam's Club.</p><p>Step 3: Since John is mentioned as dying in 2005, it implies that Helen's husband is not John, but rather Sam Walton. However, the question asks about the husband of the prominent Walton family member who died after John died in 2005, which would be Helen.</p><p>Step 4: Since Helen is the only prominent Walton family member mentioned as dying after John died in 2005, it can be inferred that her husband is the one being asked about. However, the question is asking about the husband of the prominent Walton family member who died after John died in 2005, not Helen herself. This implies that the question is actually asking about the husband of Christy Walton, who took her husband John's place after his death.</p><p>Step 5: Therefore, the answer is: John Walton, who was Christy Walton's husband.</p><p>--------------------CoT-7: P (r7|X) = 0.05 --------------------Step 1: Identify the Walton family member who died after John died in 2005. Helen Robson Kemper Walton died in 2007, after John's death in 2005.</p><p>Step 2: Determine who Helen's husband was. Helen's husband was Sam Walton, the cofounder of Walmart.</p><p>Step 3: However, the question asks for the husband of the prominent Walton family member who died after John died in 2005. Since Helen died in 2007, it cannot be her.</p><p>Step 4: The question does not provide the exact date of Christy Walton's husband John's death, but it mentions that Christy took her husband John's place after his death. Therefore, it can be inferred that Christy Walton's husband is the answer to the question.</p><p>Step 5: Combine the information to answer the question. The husband of the prominent Walton family member who died after John died in 2005 is John Walton's husband, which is Christy Walton's husband, also named John.</p><p>Therefore, the answer is: John.</p><p>--------------------CoT-8: P (r8|X) = 0.025 <ref type="figure">--------------------</ref>Step 1: Identify the prominent Walton family member who died after John died in 2005. Helen Robson Kemper Walton died in 2007.</p><p>Step 2: Determine the relationship between Helen and John. Helen was the wife of John.</p><p>Step 3: Identify the question being asked. The question is asking for the husband of the prominent Walton family member who died after John died in 2005.</p><p>Step 4: Combine the information to answer the question. Since Helen died after John in 2005, John is the husband of the prominent Walton family member who died after John died in 2005.</p><p>Therefore, the answer is: John.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intervention results</head><p>For the above eight chain-of-thoughts, we use the NWGM algorithm to perform causal intervention operations on them respectively. We can then compute the causal effect between the chain-of-thought and the answer. Therefore, the final answer obtained according to the Causal Prompting method is Sam Walton.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Structural causal model for the prompting method. (a) The causality of prompt and answer is confounded by unobservable variable. (b) The chain-of-thought generated by LLMs as a mediator variable between prompt and answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Given a training set D = {dj = (qj, r wrong j of-thought r k of test example, where qj denotes the question of j-th training sample, r wrong j and r correct j denote the wrong and correct chain-of-thoughts of demonstration dj, N denotes the size of the training set, r k refers to the k-th chain-of-thought selected by Equation (10) in Section 3.1. The embedding r k of chain-of-thought r k and the embedding dj of demonstration dj are obtained by the following:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Math Reasoning (GSM8K (Cobbe et al. 2021), MATH (Hendrycks et al. 2021)), Multi-hop Question Answering (HotpotQA (Yang et al. 2018), MuSiQue<ref type="bibr" target="#b38">(Trivedi et al. 2022</ref>)), and Natural Language Understanding (Aspect-based Sentiment Analysis (ABSA)<ref type="bibr" target="#b27">(Pontiki et al. 2016)</ref>, Natural Language Inference (NLI)<ref type="bibr" target="#b49">(Williams, Nangia, and Bowman 2017)</ref>, and Fact Verification (FV)<ref type="bibr" target="#b35">(Thorne et al. 2018)</ref>).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(DQ2) The impact of performance threshold adjustments. (DQ3) The effects of contrastive learning. (DQ4) The rationale behind baseline selection. (DQ5) The new bias from the CoT generated by LLMs is not considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparison of FLOPs cost between Causal Prompting and CoT-SC method on LLaMA3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The impact of threshold s on LLaMA3-8B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Visualization of the embeddings of chain-of-thought obtained by the original Encoder (left) and the Encoder trained through contrastive learning (right) on the GSM8K dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>C. 1</head><label>1</label><figDesc>BaselinesStandardICL (Brown et al. 2020): Prompt LLMs with some demonstration examples containing only questions and their corresponding answers, without any additional explanatory context or reasoning.CoT<ref type="bibr" target="#b47">(Wei et al. 2022</ref>): Unlike Standard ICL, CoT method enhances the prompt with demonstration examples that include detailed chain-of-thoughts. These chain-of-thoughts guide the LLMs through the steps required to reach an answer.CoT-SC<ref type="bibr" target="#b44">(Wang et al. 2022</ref>): Extent the CoT methods by having the LLMs generate multiple different chain-of-thoughts for the same query and use majority voting to determine the final answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>was the wife of Wal-Mart and Sam's Club founder Sam Walton. At one point in her life, she was the richest American and the eleventh-richest woman in the world. Question Who was the husband of the prominent Walton family member who died after John died in 2005? (The correct answer is Sam Walton) Outputs from CoT-SC The number of chain-of-thoughts m=40. Answer voting results: P (A = John|X) = 13/40 = 0.325 P (A = SamW alton|X) = 12/40 = 0.3 P (A = JohnW alton|X) = 9/40 = 0.225 ... (Omit answers with fewer votes) Therefore, the final answer obtained according to the COT-SC method is John.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>P</head><label></label><figDesc>(A = John|do(r1)) = 1/10 = 0.1 P (A = SamW alton|do(r1)) = 6/10 = 0.6 P (A = JohnW alton|do(r1)) = 2/10 = 0.2 P (A = John|do(r2)) = 3/10 = 0.3 P (A = SamW alton|do(r2)) = 4/10 = 0.4 P (A = JohnW alton|do(r2)) = 1/10 = 0.1 P (A = John|do(r3)) = 4/10 = 0.4 P (A = SamW alton|do(r3)) = 0/10 = 0.0 P (A = JohnW alton|do(r3)) = 1/10 = 0.1 P (A = John|do(r4)) = 0/10 = 0.0 P (A = SamW alton|do(r4)) = 2/10 = 0.2 P (A = JohnW alton|do(r4)) = 8/10 = 0.8 P (A = John|do(r5)) = 0/10 = 0.0 P (A = SamW alton|do(r5)) = 0/10 = 0.0 P (A = JohnW alton|do(r5)) = 5/10 = 0.5 P (A = John|do(r6)) = 0/10 = 0.0 P (A = SamW alton|do(r6)) = 0/10 = 0.0 P (A = JohnW alton|do(r6)) = 8/10 = 0.8 P (A = John|do(r7)) = 8/10 = 0.8 P (A = SamW alton|do(r7)) = 0/10 = 0.0 P (A = JohnW alton|do(r7)) = 2/10 = 0.2 P (A = John|do(r8)) = 6/10 = 0.6 P (A = SamW alton|do(r8)) = 0/10 = 0.0 P (A = JohnW alton|do(r8)) = 1/10 = 0.1 Final results The final answer is obtained by performing a weighted voting as follows: P (A = John|do(X)) = 0.325 * 0.1 + 0.25 * 0.3 + 0.075 * 0.4 + 0.125 * 0.0 + 0.125 * 0.0 + 0.025 * 0.0 + 0.05 * 0.8 + 0.025 * 0.6 = 0.1925 P (A = SamW alton|do(X)) = 0.325 * 0.6 + 0.25 * 0.4 + 0.075 * 0.0 + 0.125 * 0.2 + 0.125 * 0.0 + 0.025 * 0.0 + 0.05 * 0.0 + 0.025 * 0.0 = 0.32 P (A = JohnW alton|do(X)) = 0.325 * 0.2 + 0.25 * 0.1 + 0.075 * 0.1 + 0.125 * 0.8 + 0.125 * 0.5 + 0.025 * 0.8 + 0.05 * 0.2 + 0.025 * 0.1 = 0.2925 Finally, we chose the answer with the largest weight as the final answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The overall framework of Causal Prompting. Firstly, based on the input prompt X consisting of the demonstration examples and a question of the test example, we query the LLM to generate m distinct CoTs . Then, these CoTs are clustered into K clusters by an Encoder-based clustering algorithm. Subsequently, K representative CoTs are selected by searching the closest CoT to the cluster center. Secondly, the optimal demonstration examples are retrieved for each representative CoT through the Encoder-based intervention algorithm, and then the input prompt P iter r k after the intervention is obtained. Finally, we query the LLM T times, obtaining T improved CoTs and T answers for each representative CoT . The final answer is obtained by performing a weighted voting.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>LLM</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Contrastive Learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Encoder</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>𝑐 1</cell><cell></cell><cell>𝑟 1</cell><cell>𝑑 𝑙 ↑</cell><cell>…</cell><cell>𝑑 1 ↑</cell><cell>𝑞 𝑟 1</cell><cell></cell><cell>𝑟 1,1 𝑖𝑝</cell><cell>𝑎 1,1</cell></row><row><cell>𝑑 1 𝑑 𝑛 …</cell><cell>𝑞</cell><cell>LLM-based prompting</cell><cell>𝑐 2</cell><cell>Encoder-based clustering</cell><cell>𝐶 1 …</cell><cell>Encoder-based intervening</cell><cell cols="3">𝒫 𝑟1 𝑖𝑡𝑒𝑟 , 𝑟 1 …</cell><cell>LLM-based prompting</cell><cell>𝑎 1,𝑇 … 𝑖𝑝 𝑟 1,𝑇</cell><cell>𝐴</cell></row><row><cell>𝑋</cell><cell></cell><cell></cell><cell>𝑐 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>…</cell><cell></cell><cell>𝑟 𝐾</cell><cell>𝑑 𝑙 ↑</cell><cell>…</cell><cell>𝑑 1 ↑</cell><cell>𝑞 𝑟 𝐾</cell><cell></cell><cell>𝑟 𝐾,1 𝑖𝑝</cell><cell>𝑎 𝐾,1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>𝑐 𝑚</cell><cell></cell><cell>𝐶 𝐾</cell><cell></cell><cell cols="3">𝒫 𝑟𝐾 𝑖𝑡𝑒𝑟 , 𝑟 𝐾</cell><cell></cell><cell>𝑟 𝐾,𝑇 𝑖𝑝</cell><cell>𝑎 𝐾,𝑇</cell></row><row><cell></cell><cell></cell><cell cols="2">𝑃(𝑟|𝑑𝑜(𝑋))</cell><cell></cell><cell></cell><cell></cell><cell cols="3">𝑃(𝐴|𝑑𝑜(𝑟))</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">𝑃 𝐴 𝑑𝑜 𝑋 =</cell><cell cols="2">𝑃(𝑟|𝑑𝑜(𝑋))𝑃 𝐴 𝑑𝑜 𝑟</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>𝑟</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Figure 4:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The comparison results of Causal Prompting against baselines across different backbone LLMs, including LLaMA2, LLaMA3 and GPT-3.5, on seven datasets. The best results are in bold.</figDesc><table><row><cell>. Causal Prompting consistently</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The results of the robustness study on LLaMA3.</figDesc><table /><note><p>Ori denotes the original dataset (ID) and Adv denotes the adversarial dataset (OOD). The best results are in bold.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc><ref type="bibr" target="#b36">Tian et al. 2022;</ref><ref type="bibr" target="#b71">Zhang, Zhang, and Zhou 2024;</ref><ref type="bibr" target="#b77">Zhu et al. 2023;</ref> Wang et al. 2023a;<ref type="bibr" target="#b61">Xu et al. 2023;</ref><ref type="bibr" target="#b17">Niu et al. 2021;</ref><ref type="bibr" target="#b31">Schuster et al. 2019;</ref> Wu et al. 2024b) have shown that using symmetric and adversarial (out-of-distribution) datasets can evaluate the debiasing ability of models. Following their practice, we evaluate Causal Prompting on both original data and adversarial data of the NLU tasks, respectively. Tables 2 show the performance comparison results of our method and baselines on LLaMA3 model. Although the performance of Causal Prompting decreases on Ori of ABSA, the improvement is larger on Adv data, resulting in the</figDesc><table /><note><p><p><p><p><p>highest overall performance, see in 1. This phenomenon aligns with findings reported in previous work on causal inference</p><ref type="bibr" target="#b36">(Tian et al. 2022;</ref> Wang et al. 2023a</p>). It can be observed that the Adv of Causal Prompting is the highest on all datasets. This shows that our method generalizes well for both synthetic adversarial data in ABSA and NLI generated by TextFlint</p><ref type="bibr" target="#b43">(Wang et al. 2021</ref></p>) and human-annotated real adversarial data in FV. This further validates the robustness of our model in handling datasets with significant bias.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>. It can be extended to a broader range of scenarios, such as safety or alignment, under theoretical guidance. Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B.2 Algorithm Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.2 Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.3 Implementation Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.4 Dataset Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.5 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Demonstration Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc><table><row><cell></cell><cell>88 86</cell><cell>COT-SC Ours</cell><cell></cell><cell></cell><cell>Technical Appendix Contents</cell></row><row><cell>A Discussion</cell><cell>84</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">B Causal Prompting Algorithm 0 200 C.1 F Limitations 74 76 78 B.1 C Experimental Details 80 82 Accuracy</cell><cell>400</cell><cell>600 FLOPs</cell><cell>800</cell><cell>1000</cell></row><row><cell>G Case Study</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>D Related Works D.1 Prompting Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D.2 Debiasing with Causal Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E More Experimental Results E.1 Robustness Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.2 Ablation Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . E.3 Hyperparameter Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.1 Case on GSM8K . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.2 Case on HotpotQA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H Prompt Templates H.1 Chain-of-thought prompting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.2 CoT Improvement based on NWGM approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.3 Samples generation for Contrastive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . H.4</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Threshold s GSM8K MATH HotpotQA MuSiQue ABSA NLI FV</figDesc><table><row><cell>LLaMA2</cell><cell>1.0</cell><cell>0.2</cell><cell>0.5</cell><cell>1.0</cell><cell>0.4</cell><cell>0.4</cell><cell>0.6</cell></row><row><cell>LLaMA3</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>0.6</cell><cell>0.6</cell><cell>0.5</cell></row><row><cell>GPT-3.5</cell><cell>1.0</cell><cell>0.3</cell><cell>1.0</cell><cell>0.1</cell><cell>0.6</cell><cell>0.9</cell><cell>1.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>The best threshold s across different backbone LLMs, including LLaMA2, LLaMA3 and GPT-3.5, on seven datasets.</figDesc><table><row><cell>Notation</cell><cell>Description</cell></row><row><cell>Encoder</cell><cell>The encoder-only model for generating text embedding</cell></row><row><cell>LLM</cell><cell>The large language model for text generation</cell></row><row><cell>Sort</cell><cell>The function to sort the training set</cell></row><row><cell>D</cell><cell>The training set</cell></row><row><cell>d</cell><cell>The demonstration examples in the prompt</cell></row><row><cell>q test</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Notations used in our proposed method Causal Prompting.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Table 4 to clarify their usage and significance throughout the algorithm. Encoder, LLM, Sort, D, d, q test , n, m, K, T 1:P ← [d 1 , ..., d n , q test ] 2: {c i |i = 1, ..., m} ← LLM(P) 3: c i ← Encoder([CLS], c i , [SEP]) 4: {C 1 , ..., C K } ← K-means(c 1 , ..., c m ) 5: for k = 1 to K:</figDesc><table><row><cell cols="2">Algorithm 1: Causal Prompting</cell></row><row><cell>Input: 6:</cell><cell>r k ← Center(C k )</cell></row><row><cell cols="2">7: 8: end for P (r k |do(X)) ← |C k | m</cell></row><row><cell cols="2">9: for k = 1 to K:</cell></row><row><cell>10: 11:</cell><cell>r k ← Encoder([SEP], r k , [SEP]) d j ← Encoder([CLS], r wrong j , [SEP])</cell></row><row><cell>12:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>We useBERT-base (Devlin et al. 2018)  4 as the Encoder in computing sentence similarity, clustering algorithm, and NWGM algorithm following<ref type="bibr" target="#b36">(Tian et al. 2022;</ref><ref type="bibr" target="#b71">Zhang, Zhang, and Zhou 2024)</ref>. We independently fine-tune an Encoder for each LLM, as well as for each specific task, employing a contrastive learning approach. During training, we set the batch size is 128. The learning rate is 1e -4. The temperature temp is set to 0.3. The max length of Encoder is 512. The total training epochs are 20.</figDesc><table /><note><p><p>C.4 Dataset Details</p>Math Reasoning For the GSM8K (Cobbe et al. 2021) dataset, we use its official dataset split 5 . The number of samples in the training set is 7473 and the number of samples in the test set is 1319. For the MATH (Hendrycks et al. 2021) dataset, we only use algebra type data due to limited computational resources. We use the official dataset split 6 , the training set of MATH-algebra includes 1744 samples, and the test set includes 1187 samples.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Details of all datasets used in the experiments.</figDesc><table><row><cell>Tasks</cell><cell>Datasets</cell><cell>Train</cell><cell cols="2">Test Ori Adv</cell><cell>Measure</cell></row><row><cell>Math Reasoning</cell><cell>GSM8K MATH</cell><cell>7473 1744</cell><cell>1319 1187</cell><cell>--</cell><cell>Accuracy Accuracy</cell></row><row><cell>Multi-hop Question Answering</cell><cell>HotpotQA MuSiQue</cell><cell>5000 5562</cell><cell>1000 1165</cell><cell>--</cell><cell>F1 &amp; EM F1 &amp; EM</cell></row><row><cell></cell><cell>ABSA</cell><cell>2358</cell><cell>638</cell><cell cols="2">1239 Accuracy</cell></row><row><cell>Natural Language Understanding</cell><cell>NLI</cell><cell>5000</cell><cell>810</cell><cell>754</cell><cell>Accuracy</cell></row><row><cell></cell><cell>FV</cell><cell>5000</cell><cell>500</cell><cell cols="2">1000 Accuracy</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 .</head><label>7</label><figDesc>The findings are consistent with experiments conducted on LLaMA3 in Section 4.4, demonstrating that our method possesses a distinct advantage on adversarial robustness datasets.</figDesc><table><row><cell></cell><cell cols="2">ABSA</cell><cell>NLI</cell><cell></cell><cell>FV</cell><cell></cell></row><row><cell>Methods</cell><cell>Ori</cell><cell>Adv</cell><cell>Ori</cell><cell>Adv</cell><cell>Ori</cell><cell>Adv</cell></row><row><cell></cell><cell></cell><cell cols="2">LLaMA2</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Standard ICL</cell><cell cols="6">71.63 34.71 36.42 19.36 72.00 49.30</cell></row><row><cell>CoT</cell><cell cols="6">66.14 40.36 29.51 25.46 76.60 66.80</cell></row><row><cell>CoT-SC</cell><cell cols="6">75.24 42.62 36.91 29.97 77.80 69.40</cell></row><row><cell cols="7">Causal Prompting 73.04 64.73 55.06 46.29 89.00 77.10</cell></row><row><cell></cell><cell></cell><cell>GPT-3.5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Standard ICL</cell><cell cols="6">75.24 66.18 74.32 31.17 88.20 68.90</cell></row><row><cell>CoT</cell><cell>70.69</cell><cell>63.2</cell><cell cols="4">74.07 52.25 89.60 76.20</cell></row><row><cell>CoT-SC</cell><cell cols="6">79.94 71.83 76.91 56.10 91.00 78.60</cell></row><row><cell cols="7">Causal Prompting 82.29 79.02 80.74 62.47 94.60 82.50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 :</head><label>7</label><figDesc>Results of the robustness study on LLaMA2 and GPT-3.5. Ori denotes the original dataset (in-distribution) and Adv denotes the adversarial dataset (out-of-distribution). The best results are in bold.</figDesc><table><row><cell></cell><cell cols="2">GSM8K MATH</cell><cell cols="2">HotpotQA</cell><cell cols="2">MuSiQue</cell></row><row><cell>Methods</cell><cell>Acc</cell><cell>Acc</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell>Causal Prompting</cell><cell>87.95</cell><cell>62.76</cell><cell cols="4">58.5 78.18 48.07 64.23</cell></row><row><cell>NWGM-Reverse</cell><cell>87.72</cell><cell>62.26</cell><cell cols="4">57.7 77.97 47.81 63.48</cell></row><row><cell>NWGM-Random</cell><cell>86.13</cell><cell>52.99</cell><cell cols="4">56.9 77.23 47.38 61.60</cell></row><row><cell>w/o Contrastive Learning</cell><cell>86.58</cell><cell>59.56</cell><cell cols="4">57.9 77.88 47.47 62.45</cell></row><row><cell>w/o K-means</cell><cell>84.46</cell><cell>56.7</cell><cell>56.4</cell><cell>77.2</cell><cell cols="2">47.12 61.63</cell></row><row><cell>w/o Weighting</cell><cell>81.35</cell><cell>45.07</cell><cell cols="4">55.1 75.98 41.29 56.83</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>The results of ablation study on LLaMA3. The best results are in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9 :</head><label>9</label><figDesc>The results of hyperparameters for the number of clusters. The chain of thoughts generated in the first stage is 40. The best results are in bold.</figDesc><table><row><cell></cell><cell cols="2">GSM8K MATH</cell><cell cols="2">HotpotQA</cell><cell cols="2">MuSiQue</cell></row><row><cell>Cluster Num</cell><cell>Acc</cell><cell>Acc</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell>1</cell><cell>83.4</cell><cell>44.14</cell><cell cols="4">55.6 76.18 32.19 50.11</cell></row><row><cell>4</cell><cell>86.35</cell><cell>47.77</cell><cell cols="4">56.4 77.06 43.18 59.43</cell></row><row><cell>8</cell><cell>87.95</cell><cell>62.76</cell><cell cols="4">58.50 78.18 48.07 64.23</cell></row><row><cell>12</cell><cell>88.55</cell><cell>62.26</cell><cell cols="4">58.7 78.49 48.07 63.02</cell></row><row><cell>16</cell><cell>88.25</cell><cell>59.56</cell><cell cols="4">58.1 78.15 48.67 62.7</cell></row><row><cell>20</cell><cell>88.32</cell><cell>58.3</cell><cell cols="4">58.50 78.45 49.79 63.81</cell></row><row><cell></cell><cell cols="2">GSM8K MATH</cell><cell cols="2">HotpotQA</cell><cell cols="2">MuSiQue</cell></row><row><cell>CoT Num</cell><cell>Acc</cell><cell>Acc</cell><cell>EM</cell><cell>F1</cell><cell>EM</cell><cell>F1</cell></row><row><cell>8</cell><cell>82.11</cell><cell>54.84</cell><cell cols="4">56.1 76.83 42.4 58.17</cell></row><row><cell>20</cell><cell>84.61</cell><cell>56.19</cell><cell cols="4">56.8 77.53 46.35 60.49</cell></row><row><cell>40</cell><cell>87.95</cell><cell>62.76</cell><cell cols="4">58.50 78.18 48.07 64.23</cell></row><row><cell>60</cell><cell>87.87</cell><cell>62.34</cell><cell cols="4">58.1 78.44 48.33 62.78</cell></row><row><cell>80</cell><cell>88.4</cell><cell>62.68</cell><cell cols="4">58.6 78.67 48.07 62.3</cell></row><row><cell>100</cell><cell>88.93</cell><cell>61.75</cell><cell cols="3">58.6 78.86 49.1</cell><cell>64.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 10 :</head><label>10</label><figDesc>The results of hyperparameters for the number of chain of thoughts. The cluster num in the second stage is 8. The best results are in bold.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to thank the anonymous reviewers for their insightful comments. This work is funded by the <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">62176053</rs>). This work was supported in part by the <rs type="funder">UK Engineering and Physical Sciences Research Council (EPSRC)</rs> through a <rs type="grantName">Turing AI Fellowship</rs> (grant no. <rs type="grantNumber">EP/V020579/1</rs>, <rs type="grantNumber">EP/V020579/2</rs>) and <rs type="funder">Innovate UK</rs> through the <rs type="programName">Accelerating Trustworthy AI programme</rs> (grant no. <rs type="grantNumber">10093055</rs>). This work is supported by the <rs type="funder">Big Data Computing Center of Southeast University</rs>. <rs type="person">References Abdali</rs>, <rs type="person">S.</rs>; <rs type="person">Parikh</rs>, A.; <rs type="person">Lim</rs>, S.; and Kiciman, E. 2023. Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning. arXiv preprint arXiv:2312.06820. AI@Meta. 2024. Llama 3 Model Card. Bao, G.; <rs type="person">Zhang</rs>, <rs type="person">H.</rs>; <rs type="person">Yang</rs>, L.; <rs type="person">Wang</rs>, C.; and <rs type="person">Zhang</rs>, <rs type="person">Y. 2024. LLMs</rs> with Chain-of-Thought Are Non-Causal Reasoners. arXiv preprint arXiv:2402.16048. Besta, <rs type="person">M.</rs>; <rs type="person">Blach</rs>, <rs type="person">N.</rs>; <rs type="person">Kubicek</rs>, <rs type="person">A.</rs>; <rs type="person">Gerstenberger</rs>, <rs type="person">R.</rs>; <rs type="person">Podstawski</rs>, <rs type="person">M.</rs>; <rs type="person">Gianinazzi</rs>, <rs type="person">L.</rs>; <rs type="person">Gajda</rs>, <rs type="person">J.</rs>; <rs type="person">Lehmann</rs>, <rs type="person">T.</rs>; <rs type="person">Niewiadomski</rs>, H.; Nyczyk, P.; et al. 2024. Graph of thoughts: Solving elaborate problems with large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, 17682-17690. Brown, <rs type="person">T.</rs>; <rs type="person">Mann</rs>, <rs type="person">B.</rs>; <rs type="person">Ryder</rs>, <rs type="person">N.</rs>; <rs type="person">Subbiah</rs>, <rs type="person">M.</rs>; <rs type="person">Kaplan</rs>, <rs type="person">J. D.</rs>; <rs type="person">Dhariwal</rs>, <rs type="person">P.</rs>; <rs type="person">Neelakantan</rs>, <rs type="person">A.</rs>; <rs type="person">Shyam</rs>, <rs type="person">P.</rs>; <rs type="person">Sastry</rs>, G.; Askell, A.; et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33: 1877-1901. Chen, <rs type="person">M.</rs>; <rs type="person">Tworek</rs>, <rs type="person">J.</rs>; Jun, <rs type="person">H.</rs>; <rs type="person">Yuan</rs>, <rs type="person">Q.</rs>; <rs type="person">Pinto</rs>, <rs type="person">H. P. d. O.</rs>; <rs type="person">Kaplan</rs>, <rs type="person">J.</rs>; <rs type="person">Edwards</rs>, <rs type="person">H.</rs>; <rs type="person">Burda</rs>, <rs type="person">Y.</rs>; <rs type="person">Joseph</rs>, <rs type="person">N.</rs>; <rs type="person">Brockman</rs>, G.; et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374. Chen, <rs type="person">T.</rs>; <rs type="person">Kornblith</rs>, <rs type="person">S.</rs>; <rs type="person">Norouzi</rs>, M.; and <rs type="person">Hinton</rs>, G. 2020. A simple framework for contrastive learning of visual representations. In International conference on machine learning, 1597-1607. PMLR. Chen, Z.; Hu, L.; <rs type="person">Li</rs>, W.; <rs type="person">Shao</rs>, Y.; and <rs type="person">Nie</rs>, <rs type="person">L. 2023a</rs>. Causal intervention and counterfactual reasoning for multi-modal fake news detection. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 627-638. Chen, Z.; <rs type="person">Hu</rs>, L.; <rs type="person">Li</rs>, <rs type="person">W.</rs>; <rs type="person">Shao</rs>, Y.; and <rs type="person">Nie</rs>, <rs type="person">L. 2023b. Causal</rs> Intervention and <rs type="person">Counterfactual Reasoning</rs> for Multi-modal Fake News Detection. In Rogers, <rs type="person">A.</rs>; <rs type="person">Boyd-Graber</rs>, <rs type="person">J.</rs>; and <rs type="person">Okazaki, N.</rs>, eds., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 627-638. Toronto, Canada: Association for Computational Linguistics. <rs type="person">Chung</rs>, <rs type="person">H. W.</rs>; <rs type="person">Hou</rs>, <rs type="person">L.</rs>; <rs type="person">Longpre</rs>, <rs type="person">S.</rs>; <rs type="person">Zoph</rs>, <rs type="person">B.</rs>; <rs type="person">Tay</rs>, <rs type="person">Y.</rs>; Fedus, <rs type="person">W.</rs>; <rs type="person">Li</rs>, <rs type="person">Y.</rs>; <rs type="person">Wang</rs>, X.; <rs type="person">Dehghani</rs>, M.; Brahma, S.; et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416. Cobbe, <rs type="person">K.</rs>; <rs type="person">Kosaraju</rs>, <rs type="person">V.</rs>; <rs type="person">Bavarian</rs>, <rs type="person">M.</rs>; <rs type="person">Chen</rs>, <rs type="person">M.</rs>; Jun, <rs type="person">H.</rs>; <rs type="person">Kaiser</rs>, <rs type="person">L.</rs>; Plappert, <rs type="person">M.</rs>; <rs type="person">Tworek</rs>, <rs type="person">J.</rs>; Hilton, <rs type="person">J.</rs>; <rs type="person">Nakano</rs>, R.; et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168. Devlin, <rs type="person">J.</rs>; <rs type="person">Chang</rs>, M.-W.; Lee, K.; and Toutanova, K. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. Dong, Q.; Li, L.; Dai, D.; Zheng, C.; Wu, Z.; Chang, B.; Sun, X.; Xu, J.; and Sui, Z. 2022. A survey for in-context learning. arXiv preprint arXiv:2301.00234. Feder, A.; Keith, K. A.; Manzoor, E.; Pryzant, R.; Sridhar, D.; Wood-Doughty, Z.; Eisenstein, J.; Grimmer, J.; Reichart, R.; Roberts, M. E.; et al. 2022. Causal inference in natural language processing: Estimation, prediction, interpretation and beyond. Transactions of the Association for Computational Linguistics, 10: 1138-1158. Fei, Y.; Hou, Y.; Chen, Z.; and Bosselut, A. 2023. Mitigating Label Biases for In-context Learning. arXiv preprint arXiv:2305.19148. Gao, J.; Wang, W.; Yu, C.; Zhao, H.; Ng, W.; and Xu, R. 2022. Improving event representation via simultaneous weakly supervised contrastive learning and clustering. arXiv preprint arXiv:2203.07633. Guo, W.; Gong, Q.; and Lai, H. 2022. Counterfactual Multihop QA: A Cause-Effect Approach for Reducing Disconnected Reasoning. arXiv preprint arXiv:2210.07138. Guo, W.; Gong, Q.; Rao, Y.; and Lai, H. 2023. Counterfactual Multihop QA: A Cause-Effect Approach for Reducing Disconnected Reasoning. In Rogers, A.; Boyd-Graber, J.; and Okazaki, N., eds., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 4214-4226. Toronto, Canada: Association for Computational Linguistics. Har-Peled, S.; and Kushal, A. 2005. Smaller coresets for k-median and k-means clustering. In Proceedings of the twenty-first annual symposium on Computational geometry, 126-134. Hendrycks, D.; Burns, C.; Kadavath, S.; Arora, A.; Basart, S.; Tang, E.; Song, D.; and Steinhardt, J. 2021. Measuring Mathematical Problem Solving With the MATH Dataset. NeurIPS. Holtzman, A.; Buys, J.; Du, L.; Forbes, M.; and Choi, Y. 2019. The Curious Case of Neural Text Degeneration. In International Conference on Learning Representations. Jin, Z.; Chen, Y.; Leeb, F.; Gresele, L.; Kamal, O.; Lyu, Z.; Blin, K.; Gonzalez, F.; Kleiman-Weiner, M.; Sachan, M.; and Schölkopf, B. 2023a. CLadder: Assessing Causal Reasoning in Language Models. In NeurIPS. Jin, Z.; Liu, J.; Zhiheng, L.; Poff, S.; Sachan, M.; Mihalcea, R.; Diab, M. T.; and Schölkopf, B. 2023b. Can Large Language Models Infer Causation from Correlation? In The Twelfth International Conference on Learning Representations. Kojima, T.; Gu, S. S.; Reid, M.; Matsuo, Y.; and Iwasawa, Y. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35: 22199-22213. Kwon, W.; Li, Z.; Zhuang, S.; Sheng, Y.; Zheng, L.; Yu, C. H.; Gonzalez, J. E.; Zhang, H.; and Stoica, I. 2023. Efficient Memory Management for Large Language Model Serving with PagedAttention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Gt3YTzk">
					<idno type="grant-number">62176053</idno>
				</org>
				<org type="funding" xml:id="_We58wCx">
					<idno type="grant-number">EP/V020579/1</idno>
					<orgName type="grant-name">Turing AI Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_RXFqQ4B">
					<idno type="grant-number">EP/V020579/2</idno>
				</org>
				<org type="funding" xml:id="_Gc2NCkX">
					<idno type="grant-number">10093055</idno>
					<orgName type="program" subtype="full">Accelerating Trustworthy AI programme</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Prompt Templates</head><p>In this section, we introduce the prompt templates of Chain-of-thought prompting (detailed in Section 3.1), CoT Improvement based on NWGM approximation (detailed in Section 3.2), Samples generation for Contrastive Learning (detailed in Section 3.4) and Demonstration Construction (detailed in Appendix C.2), respectively. The blue texts in prompts are required for LLM completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.1 Chain-of-thought prompting</head><p>CoT Prompt template of Multi-hop Question Answering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform Multi-hop Question Answering. Based on the context, answer the question step by step and provide the final answer in the end. Demonstration Q:</p><p>The context is: <ref type="bibr">[paragraphs]</ref> The question is: <ref type="bibr">[question]</ref> Let us think step by step. A: Sure! Let us think step by step. <ref type="bibr">[cot]</ref> Therefore, the final answer is: <ref type="bibr">[answer]</ref> Test example: Q: The context is: <ref type="bibr">[paragraphs]</ref> The question is: <ref type="bibr">[question]</ref> Let us think step by step. A: Sure! Let us think step by step. <ref type="bibr">[cot]</ref> Therefore, the final answer is: <ref type="bibr">[answer]</ref> CoT Prompt template of GSM8K dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform Mathematical reasoning. Answer the question step by step and provide the final answer in the end. CoT Prompt template of Natural Language Inference (NLI) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform Natural language inference. Natural language inference is the task of determining whether a "hypothesis" is true (entailment), false (contradiction), or undetermined (neutral) given a "premise". Answer in a consistent style. Please write the reasoning process before giving the answer. Please provide your answer in the last sentence of your response. Your answer should be entailment, contradiction or neutral. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H.2 CoT Improvement based on NWGM approximation</head><p>We show the prompt templates of CoT Improvement based on NWGM approximation for the seven datasets listed below, including HotpotQA, MuSiQue, GSM8K, MATH, ABSA, NLI and FV. Among them, HotpotQA and MuSiQue datasets share the same template.</p><p>Prompt template of Multi-hop Question Answering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform Multi-hop Question Answering. Based on the context, answer the question step by step and provide the final answer in the end. I will provide a reasoning process, and please improve the reasoning process and make sure you get the correct answer. Give your final answer using the "The answer is:" format. The improved reasoning process is: [improved_cot] Therefore, the correct answer is: <ref type="bibr">[answer]</ref> Prompt template of Aspect-based Sentiment Analysis (ABSA) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demonstration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform sentiment classification. Please detect the sentiment polarity towards the target given the sentence. The sentiment polarities include positive, negative and neutral. Please focus on sentiment of the target itself. Detect the sentiment polarity step by step and provide the final answer in the end. I will provide a reasoning process, and please improve the reasoning process and make sure you get the correct answer. The improved reasoning process is: [improved_cot] Therefore, the correct answer is: <ref type="bibr">[answer]</ref> Prompt template of Natural Language Inference (NLI) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform Natural language inference. Natural language inference is the task of determining whether a "hypothesis" is true (entailment), false (contradiction), or undetermined (neutral) given a "premise". Answer in a consistent style. Please write the reasoning process before giving the answer. Please provide your answer in the last sentence of your response. Your answer should be entailment, contradiction or neutral. I will provide a reasoning process, and please improve the reasoning process and make sure you get the correct answer. The improved reasoning process is: [improved_cot] Therefore, the correct answer is: <ref type="bibr">[answer]</ref> Prompt template of Fact Verification (FV) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform fact verification. Please check the veracity of the claim according to the evidence, including SUPPORTS and REFUTES. Answer in a consistent style. Please write the reasoning process before giving the answer. Please provide your answer in the last sentence of your response. Your answer should be either SUPPORTS or REFUTES. I will provide a reasoning process, and please improve the reasoning process and make sure you get the correct answer. Prompt template of demos generation for Aspect-based Sentiment Analysis (ABSA) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform sentiment classification. Please detect the sentiment polarity towards the target given the sentence. The sentiment polarities include positive, negative and neutral. Please focus on sentiment of the target itself. Detect the sentiment polarity step by step and provide the final answer in the end. I will provide the correct answer and ask you to write your thought process based on the answer. Demonstration Q:</p><p>The sentence is: <ref type="bibr">[text]</ref> The target is: <ref type="bibr">[target]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform Natural language inference. Natural language inference is the task of determining whether a "hypothesis" is true (entailment), false (contradiction), or undetermined (neutral) given a "premise". Answer in a consistent style. Please write the reasoning process before giving the answer. Please provide your answer in the last sentence of your response. Your answer should be entailment, contradiction or neutral. I will provide the correct answer and ask you to write your thought process based on the answer. Prompt template of demos generation for Fact Verification (FV) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruction</head><p>You are a helpful assistant to perform fact verification. Please check the veracity of the claim according to the evidence, including SUPPORTS and REFUTES. Answer in a consistent style. Please write the reasoning process before giving the answer. Please provide your answer in the last sentence of your response. Your answer should be either SUPPORTS or REFUTES. I will provide the correct answer and ask you to write your thought process based on the answer. The correct reasoning process is: <ref type="bibr">[cot]</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Matthewson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Tessler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.02329</idno>
		<title level="m">Can language models learn from explanations in context?</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">CrossAug: A Contrastive Data Augmentation Method for Debiasing Fact Verification Models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-G</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2206.02336</idno>
		<title level="m">On the advance of making language models better reasoners</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Understanding and Patching Compositional Reasoning in LLMs</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.14328</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Lightman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cobbe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.20050</idno>
		<title level="m">Let&apos;s Verify Step by Step</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06804</idno>
		<title level="m">What Makes Good In-Context Examples for GPT-3?</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">What Makes Good In-Context Examples for GPT-3?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Apidianaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Vulić</surname></persName>
		</editor>
		<meeting>Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures<address><addrLine>Dublin, Ireland and Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="100" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08786</idno>
		<title level="m">Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neuro-Symbolic Procedural Planning with Commonsense Prompting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Faithful Chain-of-Thought Reasoning</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Havaldar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Apidianaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Park</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Arase</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Wijaya</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Purwarianti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Krisnadhi</surname></persName>
		</editor>
		<meeting>the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="305" to="329" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Nusa</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName><surname>Bali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">On the Causal Nature of Sentiment Analysis</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.11055</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-End Bias Mitigation by Modelling Biases in Corpora</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mahabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computation and Language</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mallen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</editor>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023. 9802-9822</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>: Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Active Learning Principles for In-Context Learning with Large Language Models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Margatina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dwivedi-Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.14264</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.12837</idno>
		<title level="m">Rethinking the role of demonstrations: What makes in-context learning work?</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Counterfactual vqa: A cause-effect look at language bias</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12700" to="12710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gur-Ari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lewkowycz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.00114</idno>
		<title level="m">Show your work: Scratchpads for intermediate computation with language models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/chatgpt" />
		<title level="m">Introducing ChatGPT</title>
		<imprint>
			<date type="published" when="2022">2022. 2024-02-06</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/o1/" />
		<title level="m">Introducing OpenAI o1</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The seven tools of causal inference, with reflections on machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="54" to="60" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Probabilistic and causal inference: the works of Judea Pearl</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="373" to="392" />
		</imprint>
	</monogr>
	<note>Direct and indirect effects</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Causal inference in statistics: A primer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Jewell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The book of why: the new science of cause and effect</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mackenzie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Basic books</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Models, reasoning and inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CambridgeUniversityPress</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2000">2000</date>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">LIVE: Learnable In-Context Vector for Visual Question Answering</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-eighth Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 5: Aspect based sentiment analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Smadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Ayyoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>De Clercq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ProWorkshop on Semantic Evaluation (SemEval-2016)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="19" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">PEARL: Input-Agnostic Prompt Enhancement with Negative Feedback Regulation for Class-Incremental Learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.10900</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Recursive Introspection: Teaching Language Model Agents How to Self-Improve</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.18219</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chadha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.07927</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Towards debiasing fact verification models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J S</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Filizzola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Santus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05267</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</title>
		<author>
			<persName><forename type="first">C</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.03314</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</editor>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="545" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.11914</idno>
		<title level="m">Towards causalgpt: A multi-agent approach for faithful knowledge reasoning via promoting causal consistency in llms</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">FEVER: a large-scale dataset for fact extraction and VERification</title>
		<author>
			<persName><forename type="first">J</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Debiasing NLU Models via Causal Intervention and Counterfactual Reasoning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11376" to="11384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Babaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bashlykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhosale</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.09288</idno>
		<title level="m">Llama 2: Open foundation and fine-tuned chat models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">MuSiQue: Multihop Questions via Single-hop Question Composition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Language models don&apos;t always say what they think: unfaithful explanations in chain-of-thought prompting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turpin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">a. A Causal View of Entity Bias in (Large) Language Models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Bouamor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Pino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Bali</surname></persName>
		</editor>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="15173" to="15184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.13259</idno>
		<title level="m">Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-intensive question answering</title>
		<imprint>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Textflint: Unified multilingual robustness evaluation toolkit for natural language processing</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="347" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Self-Consistency Improves Chain of Thought Reasoning in Language Models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsvetkov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.00935</idno>
		<title level="m">Resolving knowledge conflicts in large language models</title>
		<imprint>
			<date type="published" when="2023">2023d</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05426</idno>
		<title level="m">A broadcoverage challenge corpus for sentence understanding through inference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">L.-W</forename><surname>Ku</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Martins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</editor>
		<meeting>the 62nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="14073" to="14087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.01166</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.08182</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Number it: Temporal Grounding Videos like Flipping Manga</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.10332</idno>
		<imprint>
			<date type="published" when="2024">2024c</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Unlearning Concepts in Diffusion Model via Concept Domain Correction and Concept Preserving Gradient</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.15304</idno>
		<imprint>
			<date type="published" when="2024">2024d</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Video Repurposing from User Generated Content: A Large-scale Dataset and Benchmark</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.08879</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">An explanation of in-context learning as implicit bayesian inference</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.02080</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based Sentiment Analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3594" to="3605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Counterfactual Debiasing for Fact Verification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Okazaki</surname></persName>
		</editor>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6777" to="6789" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.09963</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Lever LM: configuring in-context sequence to lever large vision language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-eighth Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Deconfounded image captioning: A causal retrospect</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Causal attention for vision-language tasks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="9847" to="9857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Chiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</editor>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">React: Synergizing reasoning and acting in language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03629</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.10420</idno>
		<title level="m">A comprehensive capability analysis of gpt-3 and gpt-3.5 series models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12685</idno>
		<title level="m">Ground-truth labels matter: A deeper look into input-label demonstrations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Causal Walk: Debiasing Multi-Hop Fact Verification with Front-Door Adjustment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="19533" to="19541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Multi-Relational Probabilistic Event Representation Learning via Projected Gaussian Embedding</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="6162" to="6174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Mitigating language model hallucination with interactive question-knowledge alignment</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13669</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Calibrate before use: Improving few-shot performance of language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12697" to="12706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Least-to-most prompting enables complex reasoning in large language models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10625</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Causal Intervention for Mitigating Name Bias in Machine Reading Comprehension</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL 2023</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="12837" to="12852" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
