# Penghai Zhao 论文引用分析报告

## 作者信息

- 机构: 
- 总引用次数: 33
- h指数: 3
- 论文总数: 10

## 论文引用分析

### 1. Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?

- 发表年份: 2023
- 发表venue: arXiv.org
- 引用次数: 15

#### 引用论文分析

##### 1. 引用论文
DOI: 10.48550/arXiv.2405.15199

引用上下文:

- 上下文 1:
  - 章节: Introduction
  - 内容: Diffusion models have been used to synthesize training data and benefit downstream tasks including object detection  , image classification 34, , and semantic segmentation  .

##### 2. 引用论文
DOI: 10.48550/arXiv.2404.16637

引用上下文:

- 上下文 1:
  - 章节: Related Work
  - 内容: For text-to-image generation, diffusion models are commonly employed, particularly for knowledge distillation [19] .

- 上下文 2:
  - 章节: Conclusion
  - 内容: Cross-Entropy Diversify don't finetune   Accuracy Custom   Accuracy Cross-Entropy DM-KD [19] Accuracy * KD

- 上下文 3:
  - 章节: Conclusion
  - 内容: Cross-Entropy Diversify don't finetune   Accuracy Custom   Accuracy Cross-Entropy DM-KD [19] Accuracy * KD

##### 3. 引用论文
DOI: 10.48550/arXiv.2403.12003

引用上下文:

- 上下文 1:
  - 章节: Related Work
  - 内容: Recent research has explored generative models for data augmentation in various tasks, including classification 55, , segmentation  , and test-time optimization  .

##### 4. 引用论文
DOI: 10.48550/arXiv.2312.03048

引用上下文:

- 上下文 1:
  - 章节: Related Work
  - 内容: Recent techniques have utilized state-of-the-art DMs to create training data for downstream tasks such as image classification 36, , object detection  , semantic segmentation  .

##### 5. 引用论文
DOI: 10.48550/arXiv.2306.16064

引用上下文:

- 上下文 1:
  - 章节: Experimental Results
  - 内容: To investigate the impact of various generative models on the results, we followed the setting in [29] .

- 上下文 2:
  - 章节: Related Work
  - 内容: Li [29] demonstrate that synthetic data generated by conditional diffusion models can be used for knowledge distillation without original data.

##### 6. 引用论文
DOI: 10.48550/arXiv.2306.04542

引用上下文:

- 上下文 1:
  - 章节: FUTURE TRENDS
  - 内容: Data generated by diffusion models are also employed as the proxy for training new models when the original data are limited [269] ,  .

##### 7. 引用论文
DOI: 10.48550/arXiv.2306.01322

引用上下文:

- 上下文 1:
  - 章节: Introduction
  - 内容: Sharing trained generative models, in particular, can be useful  for fine-tuning in smaller datasets  , anomaly detection  , or even leveraging synthetic data for downstream tasks such as segmentation   or classification (Li et al., 2023; .

---

